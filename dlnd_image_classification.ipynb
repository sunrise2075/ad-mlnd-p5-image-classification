{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 图像分类\n",
    "\n",
    "在此项目中，你将对 [CIFAR-10 数据集](https://www.cs.toronto.edu/~kriz/cifar.html) 中的图片进行分类。该数据集包含飞机、猫狗和其他物体。你需要预处理这些图片，然后用所有样本训练一个卷积神经网络。图片需要标准化（normalized），标签需要采用 one-hot 编码。你需要应用所学的知识构建卷积的、最大池化（max pooling）、丢弃（dropout）和完全连接（fully connected）的层。最后，你需要在样本图片上看到神经网络的预测结果。\n",
    "\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "请运行以下单元，以下载 [CIFAR-10 数据集（Python版）](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 探索数据\n",
    "\n",
    "该数据集分成了几部分／批次（batches），以免你的机器在计算时内存不足。CIFAR-10 数据集包含 5 个部分，名称分别为 `data_batch_1`、`data_batch_2`，以此类推。每个部分都包含以下某个类别的标签和图片：\n",
    "\n",
    "* 飞机\n",
    "* 汽车\n",
    "* 鸟类\n",
    "* 猫\n",
    "* 鹿\n",
    "* 狗\n",
    "* 青蛙\n",
    "* 马\n",
    "* 船只\n",
    "* 卡车\n",
    "\n",
    "了解数据集也是对数据进行预测的必经步骤。你可以通过更改 `batch_id` 和 `sample_id` 探索下面的代码单元。`batch_id` 是数据集一个部分的 ID（1 到 5）。`sample_id` 是该部分中图片和标签对（label pair）的 ID。\n",
    "\n",
    "问问你自己：“可能的标签有哪些？”、“图片数据的值范围是多少？”、“标签是按顺序排列，还是随机排列的？”。思考类似的问题，有助于你预处理数据，并使预测结果更准确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f69543a6e10>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 标准化\n",
    "\n",
    "在下面的单元中，实现 `normalize` 函数，传入图片数据 `x`，并返回标准化 Numpy 数组。值应该在 0 到 1 的范围内（含 0 和 1）。返回对象应该和 `x` 的形状一样。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x = x.astype('float32')\n",
    "    if x.max()>1.0:\n",
    "        x /=255.0\n",
    "    return x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot 编码\n",
    "\n",
    "和之前的代码单元一样，你将为预处理实现一个函数。这次，你将实现 `one_hot_encode` 函数。输入，也就是 `x`，是一个标签列表。实现该函数，以返回为 one_hot 编码的 Numpy 数组的标签列表。标签的可能值为 0 到 9。每次调用 `one_hot_encode` 时，对于每个值，one_hot 编码函数应该返回相同的编码。确保将编码映射保存到该函数外面。\n",
    "\n",
    "提示：不要重复发明轮子。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    row = len(x)\n",
    "    col = 10\n",
    "    encoded_matrix = np.zeros((row, col))\n",
    "    for i in range(0, row):\n",
    "        label_value = x[i]\n",
    "        encoded_matrix[i][label_value] = 1\n",
    "    return encoded_matrix\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机化数据\n",
    "\n",
    "之前探索数据时，你已经了解到，样本的顺序是随机的。再随机化一次也不会有什么关系，但是对于这个数据集没有必要。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理所有数据并保存\n",
    "\n",
    "运行下方的代码单元，将预处理所有 CIFAR-10 数据，并保存到文件中。下面的代码还使用了 10% 的训练数据，用来验证。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，你可以从这里开始。预处理的数据已保存到本地。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n",
    "对于该神经网络，你需要将每层都构建为一个函数。你看到的大部分代码都位于函数外面。要更全面地测试你的代码，我们需要你将每层放入一个函数中。这样使我们能够提供更好的反馈，并使用我们的统一测试检测简单的错误，然后再提交项目。\n",
    "\n",
    ">**注意**：如果你觉得每周很难抽出足够的时间学习这门课程，我们为此项目提供了一个小捷径。对于接下来的几个问题，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 程序包中的类来构建每个层级，但是“卷积和最大池化层级”部分的层级除外。TF Layers 和 Keras 及 TFLearn 层级类似，因此很容易学会。\n",
    "\n",
    ">但是，如果你想充分利用这门课程，请尝试自己解决所有问题，不使用 TF Layers 程序包中的任何类。你依然可以使用其他程序包中的类，这些类和你在 TF Layers 中的类名称是一样的！例如，你可以使用 TF Neural Network 版本的 `conv2d` 类 [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d)，而不是 TF Layers 版本的 `conv2d` 类 [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d)。\n",
    "\n",
    "我们开始吧！\n",
    "\n",
    "\n",
    "### 输入\n",
    "\n",
    "神经网络需要读取图片数据、one-hot 编码标签和丢弃保留概率（dropout keep probability）。请实现以下函数：\n",
    "\n",
    "* 实现 `neural_net_image_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `image_shape` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"x\" 命名\n",
    "* 实现 `neural_net_label_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * 使用 `n_classes` 设置形状，部分大小设为 `None`\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"y\" 命名\n",
    "* 实现 `neural_net_keep_prob_input`\n",
    " * 返回 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)，用于丢弃保留概率\n",
    " * 使用 [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) 中的 TensorFlow `name` 参数对 TensorFlow 占位符 \"keep_prob\" 命名\n",
    "\n",
    "这些名称将在项目结束时，用于加载保存的模型。\n",
    "\n",
    "注意：TensorFlow 中的 `None` 表示形状可以是动态大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    input_shape = (None, ) + image_shape\n",
    "    input_placeholder = tf.placeholder(tf.float32, shape = input_shape, name=\"x\")\n",
    "    return input_placeholder\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    label_shape = (None, n_classes)\n",
    "    label_output = tf.placeholder(tf.float32, shape = label_shape, name=\"y\")\n",
    "    return label_output\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape = (None), name = \"keep_prob\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和最大池化层\n",
    "\n",
    "卷积层级适合处理图片。对于此代码单元，你应该实现函数 `conv2d_maxpool` 以便应用卷积然后进行最大池化：\n",
    "\n",
    "* 使用 `conv_ksize`、`conv_num_outputs` 和 `x_tensor` 的形状创建权重（weight）和偏置（bias）。\n",
    "* 使用权重和 `conv_strides` 对 `x_tensor` 应用卷积。\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "* 添加偏置\n",
    "* 向卷积中添加非线性激活（nonlinear activation）\n",
    "* 使用 `pool_ksize` 和 `pool_strides` 应用最大池化\n",
    " * 建议使用我们建议的间距（padding），当然也可以使用任何其他间距。\n",
    "\n",
    "**注意**：对于**此层**，**请勿使用** [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers)，但是仍然可以使用 TensorFlow 的 [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) 包。对于所有**其他层**，你依然可以使用快捷方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    # x_tensor.shape:(?, 32, 32, 5)\n",
    "    # conv_num_outputs: 10\n",
    "    # conv_ksize: (2,2)\n",
    "    # conv_strides: (4,4)\n",
    "    # pool_ksize: (2,2)\n",
    "    # pool_strides: (2,2)\n",
    "    height = pool_ksize[0]\n",
    "    width = pool_ksize[1]\n",
    "    input_shape_list = x_tensor.get_shape().as_list()\n",
    "    weight_shape = (height, width, input_shape_list[3], conv_num_outputs)\n",
    "    \n",
    "    filter_weights = tf.Variable(tf.truncated_normal(shape=weight_shape, stddev=0.01))\n",
    "    filter_bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    conv_layer = tf.nn.conv2d(x_tensor, filter_weights, strides= [1, conv_strides[0], conv_strides[1], 1], padding='SAME')\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, filter_bias)\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    conv_layer = tf.nn.max_pool(conv_layer, ksize=[1, pool_ksize[0], pool_ksize[1], 1], strides= [1,pool_strides[0], pool_strides[1],1] ,padding='SAME')\n",
    "    \n",
    "    return conv_layer \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扁平化层\n",
    "\n",
    "实现 `flatten` 函数，将 `x_tensor` 的维度从四维张量（4-D tensor）变成二维张量。输出应该是形状（*部分大小（Batch Size）*，*扁平化图片大小（Flattened Image Size）*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    flattened_x = tf.contrib.layers.flatten(x_tensor)\n",
    "#     print (flattened_x)\n",
    "    return flattened_x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层\n",
    "\n",
    "实现 `fully_conn` 函数，以向 `x_tensor` 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.layers import fully_connected\n",
    "\n",
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    coonected_layer = fully_connected(x_tensor, num_outputs)\n",
    "    return coonected_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出层\n",
    "\n",
    "实现 `output` 函数，向 x_tensor 应用完全连接的层级，形状为（*部分大小（Batch Size）*，*num_outputs*）。快捷方法：对于此层，你可以使用 [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) 或 [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) 包中的类。如果你想要更大挑战，可以仅使用其他 TensorFlow 程序包。\n",
    "\n",
    "**注意**：该层级不应应用 Activation、softmax 或交叉熵（cross entropy）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    output_layer = fully_connected(x_tensor, num_outputs, activation_fn=None)\n",
    "    return output_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建卷积模型\n",
    "\n",
    "实现函数 `conv_net`， 创建卷积神经网络模型。该函数传入一批图片 `x`，并输出对数（logits）。使用你在上方创建的层创建此模型：\n",
    "\n",
    "* 应用 1、2 或 3 个卷积和最大池化层（Convolution and Max Pool layers）\n",
    "* 应用一个扁平层（Flatten Layer）\n",
    "* 应用 1、2 或 3 个完全连接层（Fully Connected Layers）\n",
    "* 应用一个输出层（Output Layer）\n",
    "* 返回输出\n",
    "* 使用 `keep_prob` 向模型中的一个或多个层应用 [TensorFlow 的 Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-713216bbae79>:70: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    # x_tensor.shape:(?, 32, 32, 5)\n",
    "    # conv_num_outputs: 10\n",
    "    # conv_ksize: (2,2)\n",
    "    # conv_strides: (4,4)\n",
    "    # pool_ksize: (2,2)\n",
    "    # pool_strides: (2,2)\n",
    "    conv_num_outputs = 10\n",
    "    conv_ksize = (2, 2)\n",
    "    conv_strides = (4, 4)\n",
    "    pool_ksize = (2, 2)\n",
    "    pool_strides = (2, 2)\n",
    "    init_conv = conv2d_maxpool(x, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    flattened_conv = flatten(init_conv)\n",
    "    \n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    num_outputs = 10\n",
    "    fully_connected_conv = fully_conn(flattened_conv, num_outputs)\n",
    "    \n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    output_layer = output(fully_connected_conv, 10)\n",
    "    \n",
    "    \n",
    "    # TODO: return output\n",
    "    return output_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 单次优化\n",
    "\n",
    "实现函数 `train_neural_network` 以进行单次优化（single optimization）。该优化应该使用 `optimizer` 优化 `session`，其中 `feed_dict` 具有以下参数：\n",
    "\n",
    "* `x` 表示图片输入\n",
    "* `y` 表示标签\n",
    "* `keep_prob` 表示丢弃的保留率\n",
    "\n",
    "每个部分都会调用该函数，所以 `tf.global_variables_initializer()` 已经被调用。\n",
    "\n",
    "注意：不需要返回任何内容。该函数只是用来优化神经网络。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict = {\n",
    "        x: feature_batch,\n",
    "        y: label_batch,\n",
    "        keep_prob: keep_probability\n",
    "    })\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 显示数据\n",
    "\n",
    "实现函数 `print_stats` 以输出损失和验证准确率。使用全局变量 `valid_features` 和 `valid_labels` 计算验证准确率。使用保留率 `1.0` 计算损失和验证准确率（loss and validation accuracy）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss_result = session.run(cost, feed_dict = {\n",
    "        x: feature_batch,\n",
    "        y: label_batch,\n",
    "        keep_prob: 1.\n",
    "    })\n",
    "    \n",
    "    accuracy_result = session.run(accuracy, feed_dict = {\n",
    "        x: feature_batch,\n",
    "        y: label_batch,\n",
    "        keep_prob: 1.\n",
    "    })\n",
    "    \n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss_result, accuracy_result))\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数\n",
    "\n",
    "调试以下超参数：\n",
    "* 设置 `epochs` 表示神经网络停止学习或开始过拟合的迭代次数\n",
    "* 设置 `batch_size`，表示机器内存允许的部分最大体积。大部分人设为以下常见内存大小：\n",
    "\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* 设置 `keep_probability` 表示使用丢弃时保留节点的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 500\n",
    "batch_size = 256\n",
    "keep_probability = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在单个 CIFAR-10 部分上训练\n",
    "\n",
    "我们先用单个部分，而不是用所有的 CIFAR-10 批次训练神经网络。这样可以节省时间，并对模型进行迭代，以提高准确率。最终验证准确率达到 50% 或以上之后，在下一部分对所有数据运行模型。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.3198 Validation Accuracy: 0.125000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.3116 Validation Accuracy: 0.150000\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.2811 Validation Accuracy: 0.200000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     2.2640 Validation Accuracy: 0.175000\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     2.2431 Validation Accuracy: 0.225000\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     2.2288 Validation Accuracy: 0.200000\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     2.2229 Validation Accuracy: 0.250000\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     2.2136 Validation Accuracy: 0.275000\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     2.2156 Validation Accuracy: 0.275000\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     2.2147 Validation Accuracy: 0.275000\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     2.2177 Validation Accuracy: 0.250000\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     2.2214 Validation Accuracy: 0.250000\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     2.2221 Validation Accuracy: 0.200000\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     2.2211 Validation Accuracy: 0.200000\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     2.2211 Validation Accuracy: 0.200000\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     2.2185 Validation Accuracy: 0.225000\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     2.2246 Validation Accuracy: 0.225000\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     2.2226 Validation Accuracy: 0.275000\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     2.2198 Validation Accuracy: 0.250000\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     2.2192 Validation Accuracy: 0.250000\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     2.2117 Validation Accuracy: 0.250000\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     2.2025 Validation Accuracy: 0.225000\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     2.1946 Validation Accuracy: 0.275000\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     2.1935 Validation Accuracy: 0.250000\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     2.1799 Validation Accuracy: 0.250000\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     2.1471 Validation Accuracy: 0.300000\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     2.1384 Validation Accuracy: 0.300000\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     2.1101 Validation Accuracy: 0.275000\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     2.0619 Validation Accuracy: 0.300000\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     2.0286 Validation Accuracy: 0.275000\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     2.0082 Validation Accuracy: 0.275000\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     2.0024 Validation Accuracy: 0.300000\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     1.9902 Validation Accuracy: 0.300000\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     1.9757 Validation Accuracy: 0.375000\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     1.9714 Validation Accuracy: 0.375000\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     1.9651 Validation Accuracy: 0.375000\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     1.9597 Validation Accuracy: 0.350000\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     1.9601 Validation Accuracy: 0.350000\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     1.9571 Validation Accuracy: 0.350000\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     1.9511 Validation Accuracy: 0.350000\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     1.9500 Validation Accuracy: 0.325000\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     1.9490 Validation Accuracy: 0.325000\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     1.9451 Validation Accuracy: 0.325000\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     1.9424 Validation Accuracy: 0.300000\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     1.9386 Validation Accuracy: 0.300000\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     1.9354 Validation Accuracy: 0.300000\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     1.9332 Validation Accuracy: 0.300000\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     1.9307 Validation Accuracy: 0.300000\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     1.9283 Validation Accuracy: 0.300000\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     1.9234 Validation Accuracy: 0.300000\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     1.9199 Validation Accuracy: 0.275000\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     1.9157 Validation Accuracy: 0.275000\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     1.9108 Validation Accuracy: 0.300000\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     1.9067 Validation Accuracy: 0.325000\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     1.9030 Validation Accuracy: 0.325000\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     1.8981 Validation Accuracy: 0.325000\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     1.8940 Validation Accuracy: 0.325000\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     1.8892 Validation Accuracy: 0.325000\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     1.8841 Validation Accuracy: 0.325000\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     1.8782 Validation Accuracy: 0.325000\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     1.8726 Validation Accuracy: 0.325000\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     1.8673 Validation Accuracy: 0.325000\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     1.8613 Validation Accuracy: 0.325000\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     1.8552 Validation Accuracy: 0.325000\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     1.8498 Validation Accuracy: 0.325000\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     1.8439 Validation Accuracy: 0.325000\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     1.8381 Validation Accuracy: 0.325000\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     1.8332 Validation Accuracy: 0.325000\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     1.8269 Validation Accuracy: 0.325000\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     1.8211 Validation Accuracy: 0.325000\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     1.8180 Validation Accuracy: 0.325000\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     1.8117 Validation Accuracy: 0.325000\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     1.8047 Validation Accuracy: 0.325000\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     1.7993 Validation Accuracy: 0.325000\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     1.7929 Validation Accuracy: 0.350000\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     1.7869 Validation Accuracy: 0.350000\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     1.7811 Validation Accuracy: 0.350000\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     1.7754 Validation Accuracy: 0.350000\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     1.7724 Validation Accuracy: 0.350000\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     1.7648 Validation Accuracy: 0.350000\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     1.7607 Validation Accuracy: 0.350000\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     1.7559 Validation Accuracy: 0.350000\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     1.7502 Validation Accuracy: 0.350000\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     1.7445 Validation Accuracy: 0.375000\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     1.7379 Validation Accuracy: 0.400000\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     1.7319 Validation Accuracy: 0.400000\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     1.7267 Validation Accuracy: 0.400000\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     1.7167 Validation Accuracy: 0.400000\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     1.7046 Validation Accuracy: 0.425000\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     1.6968 Validation Accuracy: 0.425000\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     1.6904 Validation Accuracy: 0.425000\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     1.6845 Validation Accuracy: 0.425000\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     1.6781 Validation Accuracy: 0.425000\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     1.6720 Validation Accuracy: 0.425000\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     1.6670 Validation Accuracy: 0.425000\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     1.6618 Validation Accuracy: 0.425000\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     1.6569 Validation Accuracy: 0.425000\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     1.6513 Validation Accuracy: 0.450000\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     1.6417 Validation Accuracy: 0.450000\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     1.6349 Validation Accuracy: 0.450000\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss:     1.6265 Validation Accuracy: 0.450000\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss:     1.6217 Validation Accuracy: 0.450000\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss:     1.6159 Validation Accuracy: 0.450000\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss:     1.6102 Validation Accuracy: 0.425000\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss:     1.6047 Validation Accuracy: 0.425000\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss:     1.6020 Validation Accuracy: 0.425000\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss:     1.5975 Validation Accuracy: 0.425000\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss:     1.5904 Validation Accuracy: 0.400000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109, CIFAR-10 Batch 1:  Loss:     1.5841 Validation Accuracy: 0.400000\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss:     1.5767 Validation Accuracy: 0.425000\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss:     1.5683 Validation Accuracy: 0.475000\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss:     1.5604 Validation Accuracy: 0.425000\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss:     1.5493 Validation Accuracy: 0.450000\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss:     1.5397 Validation Accuracy: 0.425000\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss:     1.5289 Validation Accuracy: 0.425000\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss:     1.5166 Validation Accuracy: 0.425000\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss:     1.5136 Validation Accuracy: 0.425000\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss:     1.4995 Validation Accuracy: 0.425000\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss:     1.5019 Validation Accuracy: 0.450000\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss:     1.4883 Validation Accuracy: 0.450000\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss:     1.4880 Validation Accuracy: 0.450000\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss:     1.4799 Validation Accuracy: 0.450000\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss:     1.4684 Validation Accuracy: 0.450000\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss:     1.4621 Validation Accuracy: 0.475000\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss:     1.4588 Validation Accuracy: 0.475000\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss:     1.4538 Validation Accuracy: 0.475000\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss:     1.4530 Validation Accuracy: 0.475000\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss:     1.4569 Validation Accuracy: 0.475000\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss:     1.4383 Validation Accuracy: 0.475000\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss:     1.4461 Validation Accuracy: 0.500000\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss:     1.4387 Validation Accuracy: 0.500000\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss:     1.4298 Validation Accuracy: 0.500000\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss:     1.4295 Validation Accuracy: 0.500000\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss:     1.4235 Validation Accuracy: 0.500000\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss:     1.4251 Validation Accuracy: 0.500000\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss:     1.4174 Validation Accuracy: 0.525000\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss:     1.4261 Validation Accuracy: 0.525000\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss:     1.4183 Validation Accuracy: 0.525000\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss:     1.4170 Validation Accuracy: 0.525000\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss:     1.4119 Validation Accuracy: 0.525000\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss:     1.4084 Validation Accuracy: 0.525000\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss:     1.3978 Validation Accuracy: 0.525000\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss:     1.3965 Validation Accuracy: 0.525000\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss:     1.3916 Validation Accuracy: 0.525000\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss:     1.3863 Validation Accuracy: 0.500000\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss:     1.3811 Validation Accuracy: 0.500000\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss:     1.3790 Validation Accuracy: 0.500000\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss:     1.3769 Validation Accuracy: 0.525000\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss:     1.3699 Validation Accuracy: 0.525000\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss:     1.3639 Validation Accuracy: 0.525000\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss:     1.3590 Validation Accuracy: 0.525000\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss:     1.3543 Validation Accuracy: 0.525000\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss:     1.3518 Validation Accuracy: 0.525000\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss:     1.3467 Validation Accuracy: 0.525000\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss:     1.3438 Validation Accuracy: 0.525000\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss:     1.3381 Validation Accuracy: 0.525000\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss:     1.3350 Validation Accuracy: 0.525000\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss:     1.3329 Validation Accuracy: 0.525000\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss:     1.3318 Validation Accuracy: 0.525000\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss:     1.3355 Validation Accuracy: 0.525000\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss:     1.3302 Validation Accuracy: 0.525000\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss:     1.3277 Validation Accuracy: 0.525000\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss:     1.3274 Validation Accuracy: 0.525000\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss:     1.3228 Validation Accuracy: 0.525000\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss:     1.3202 Validation Accuracy: 0.525000\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss:     1.3176 Validation Accuracy: 0.525000\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss:     1.3090 Validation Accuracy: 0.550000\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss:     1.3043 Validation Accuracy: 0.550000\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss:     1.2999 Validation Accuracy: 0.550000\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss:     1.2990 Validation Accuracy: 0.550000\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss:     1.2981 Validation Accuracy: 0.550000\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss:     1.2936 Validation Accuracy: 0.550000\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss:     1.2942 Validation Accuracy: 0.550000\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss:     1.2906 Validation Accuracy: 0.550000\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss:     1.2880 Validation Accuracy: 0.550000\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss:     1.2871 Validation Accuracy: 0.550000\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss:     1.2850 Validation Accuracy: 0.550000\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss:     1.2852 Validation Accuracy: 0.550000\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss:     1.2807 Validation Accuracy: 0.550000\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss:     1.2793 Validation Accuracy: 0.550000\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss:     1.2795 Validation Accuracy: 0.550000\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss:     1.2763 Validation Accuracy: 0.550000\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss:     1.2763 Validation Accuracy: 0.550000\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss:     1.2744 Validation Accuracy: 0.550000\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss:     1.2726 Validation Accuracy: 0.550000\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss:     1.2661 Validation Accuracy: 0.550000\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss:     1.2650 Validation Accuracy: 0.550000\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss:     1.2620 Validation Accuracy: 0.550000\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss:     1.2594 Validation Accuracy: 0.550000\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss:     1.2562 Validation Accuracy: 0.550000\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss:     1.2563 Validation Accuracy: 0.550000\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss:     1.2518 Validation Accuracy: 0.575000\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss:     1.2527 Validation Accuracy: 0.575000\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss:     1.2477 Validation Accuracy: 0.575000\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss:     1.2436 Validation Accuracy: 0.575000\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss:     1.2397 Validation Accuracy: 0.575000\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss:     1.2386 Validation Accuracy: 0.575000\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss:     1.2344 Validation Accuracy: 0.575000\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss:     1.2342 Validation Accuracy: 0.575000\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss:     1.2300 Validation Accuracy: 0.575000\n",
      "Epoch 201, CIFAR-10 Batch 1:  Loss:     1.2302 Validation Accuracy: 0.575000\n",
      "Epoch 202, CIFAR-10 Batch 1:  Loss:     1.2261 Validation Accuracy: 0.575000\n",
      "Epoch 203, CIFAR-10 Batch 1:  Loss:     1.2261 Validation Accuracy: 0.575000\n",
      "Epoch 204, CIFAR-10 Batch 1:  Loss:     1.2228 Validation Accuracy: 0.575000\n",
      "Epoch 205, CIFAR-10 Batch 1:  Loss:     1.2197 Validation Accuracy: 0.575000\n",
      "Epoch 206, CIFAR-10 Batch 1:  Loss:     1.2185 Validation Accuracy: 0.575000\n",
      "Epoch 207, CIFAR-10 Batch 1:  Loss:     1.2165 Validation Accuracy: 0.575000\n",
      "Epoch 208, CIFAR-10 Batch 1:  Loss:     1.2151 Validation Accuracy: 0.575000\n",
      "Epoch 209, CIFAR-10 Batch 1:  Loss:     1.2130 Validation Accuracy: 0.575000\n",
      "Epoch 210, CIFAR-10 Batch 1:  Loss:     1.2070 Validation Accuracy: 0.575000\n",
      "Epoch 211, CIFAR-10 Batch 1:  Loss:     1.2029 Validation Accuracy: 0.575000\n",
      "Epoch 212, CIFAR-10 Batch 1:  Loss:     1.2018 Validation Accuracy: 0.575000\n",
      "Epoch 213, CIFAR-10 Batch 1:  Loss:     1.2009 Validation Accuracy: 0.575000\n",
      "Epoch 214, CIFAR-10 Batch 1:  Loss:     1.1982 Validation Accuracy: 0.575000\n",
      "Epoch 215, CIFAR-10 Batch 1:  Loss:     1.1945 Validation Accuracy: 0.575000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216, CIFAR-10 Batch 1:  Loss:     1.1908 Validation Accuracy: 0.575000\n",
      "Epoch 217, CIFAR-10 Batch 1:  Loss:     1.1893 Validation Accuracy: 0.575000\n",
      "Epoch 218, CIFAR-10 Batch 1:  Loss:     1.1862 Validation Accuracy: 0.575000\n",
      "Epoch 219, CIFAR-10 Batch 1:  Loss:     1.1885 Validation Accuracy: 0.575000\n",
      "Epoch 220, CIFAR-10 Batch 1:  Loss:     1.1846 Validation Accuracy: 0.575000\n",
      "Epoch 221, CIFAR-10 Batch 1:  Loss:     1.1835 Validation Accuracy: 0.575000\n",
      "Epoch 222, CIFAR-10 Batch 1:  Loss:     1.1872 Validation Accuracy: 0.575000\n",
      "Epoch 223, CIFAR-10 Batch 1:  Loss:     1.1845 Validation Accuracy: 0.575000\n",
      "Epoch 224, CIFAR-10 Batch 1:  Loss:     1.1823 Validation Accuracy: 0.575000\n",
      "Epoch 225, CIFAR-10 Batch 1:  Loss:     1.1837 Validation Accuracy: 0.575000\n",
      "Epoch 226, CIFAR-10 Batch 1:  Loss:     1.1819 Validation Accuracy: 0.575000\n",
      "Epoch 227, CIFAR-10 Batch 1:  Loss:     1.1794 Validation Accuracy: 0.575000\n",
      "Epoch 228, CIFAR-10 Batch 1:  Loss:     1.1807 Validation Accuracy: 0.575000\n",
      "Epoch 229, CIFAR-10 Batch 1:  Loss:     1.1768 Validation Accuracy: 0.575000\n",
      "Epoch 230, CIFAR-10 Batch 1:  Loss:     1.1754 Validation Accuracy: 0.575000\n",
      "Epoch 231, CIFAR-10 Batch 1:  Loss:     1.1726 Validation Accuracy: 0.575000\n",
      "Epoch 232, CIFAR-10 Batch 1:  Loss:     1.1757 Validation Accuracy: 0.575000\n",
      "Epoch 233, CIFAR-10 Batch 1:  Loss:     1.1718 Validation Accuracy: 0.575000\n",
      "Epoch 234, CIFAR-10 Batch 1:  Loss:     1.1735 Validation Accuracy: 0.575000\n",
      "Epoch 235, CIFAR-10 Batch 1:  Loss:     1.1693 Validation Accuracy: 0.575000\n",
      "Epoch 236, CIFAR-10 Batch 1:  Loss:     1.1696 Validation Accuracy: 0.575000\n",
      "Epoch 237, CIFAR-10 Batch 1:  Loss:     1.1677 Validation Accuracy: 0.575000\n",
      "Epoch 238, CIFAR-10 Batch 1:  Loss:     1.1637 Validation Accuracy: 0.575000\n",
      "Epoch 239, CIFAR-10 Batch 1:  Loss:     1.1628 Validation Accuracy: 0.575000\n",
      "Epoch 240, CIFAR-10 Batch 1:  Loss:     1.1591 Validation Accuracy: 0.575000\n",
      "Epoch 241, CIFAR-10 Batch 1:  Loss:     1.1571 Validation Accuracy: 0.575000\n",
      "Epoch 242, CIFAR-10 Batch 1:  Loss:     1.1569 Validation Accuracy: 0.575000\n",
      "Epoch 243, CIFAR-10 Batch 1:  Loss:     1.1560 Validation Accuracy: 0.600000\n",
      "Epoch 244, CIFAR-10 Batch 1:  Loss:     1.1548 Validation Accuracy: 0.600000\n",
      "Epoch 245, CIFAR-10 Batch 1:  Loss:     1.1501 Validation Accuracy: 0.600000\n",
      "Epoch 246, CIFAR-10 Batch 1:  Loss:     1.1487 Validation Accuracy: 0.600000\n",
      "Epoch 247, CIFAR-10 Batch 1:  Loss:     1.1469 Validation Accuracy: 0.600000\n",
      "Epoch 248, CIFAR-10 Batch 1:  Loss:     1.1436 Validation Accuracy: 0.600000\n",
      "Epoch 249, CIFAR-10 Batch 1:  Loss:     1.1396 Validation Accuracy: 0.600000\n",
      "Epoch 250, CIFAR-10 Batch 1:  Loss:     1.1393 Validation Accuracy: 0.600000\n",
      "Epoch 251, CIFAR-10 Batch 1:  Loss:     1.1390 Validation Accuracy: 0.600000\n",
      "Epoch 252, CIFAR-10 Batch 1:  Loss:     1.1359 Validation Accuracy: 0.600000\n",
      "Epoch 253, CIFAR-10 Batch 1:  Loss:     1.1348 Validation Accuracy: 0.575000\n",
      "Epoch 254, CIFAR-10 Batch 1:  Loss:     1.1345 Validation Accuracy: 0.575000\n",
      "Epoch 255, CIFAR-10 Batch 1:  Loss:     1.1333 Validation Accuracy: 0.575000\n",
      "Epoch 256, CIFAR-10 Batch 1:  Loss:     1.1319 Validation Accuracy: 0.575000\n",
      "Epoch 257, CIFAR-10 Batch 1:  Loss:     1.1317 Validation Accuracy: 0.575000\n",
      "Epoch 258, CIFAR-10 Batch 1:  Loss:     1.1322 Validation Accuracy: 0.575000\n",
      "Epoch 259, CIFAR-10 Batch 1:  Loss:     1.1305 Validation Accuracy: 0.575000\n",
      "Epoch 260, CIFAR-10 Batch 1:  Loss:     1.1307 Validation Accuracy: 0.575000\n",
      "Epoch 261, CIFAR-10 Batch 1:  Loss:     1.1317 Validation Accuracy: 0.575000\n",
      "Epoch 262, CIFAR-10 Batch 1:  Loss:     1.1299 Validation Accuracy: 0.575000\n",
      "Epoch 263, CIFAR-10 Batch 1:  Loss:     1.1268 Validation Accuracy: 0.575000\n",
      "Epoch 264, CIFAR-10 Batch 1:  Loss:     1.1271 Validation Accuracy: 0.575000\n",
      "Epoch 265, CIFAR-10 Batch 1:  Loss:     1.1261 Validation Accuracy: 0.575000\n",
      "Epoch 266, CIFAR-10 Batch 1:  Loss:     1.1267 Validation Accuracy: 0.575000\n",
      "Epoch 267, CIFAR-10 Batch 1:  Loss:     1.1223 Validation Accuracy: 0.575000\n",
      "Epoch 268, CIFAR-10 Batch 1:  Loss:     1.1266 Validation Accuracy: 0.575000\n",
      "Epoch 269, CIFAR-10 Batch 1:  Loss:     1.1230 Validation Accuracy: 0.575000\n",
      "Epoch 270, CIFAR-10 Batch 1:  Loss:     1.1243 Validation Accuracy: 0.575000\n",
      "Epoch 271, CIFAR-10 Batch 1:  Loss:     1.1257 Validation Accuracy: 0.575000\n",
      "Epoch 272, CIFAR-10 Batch 1:  Loss:     1.1226 Validation Accuracy: 0.575000\n",
      "Epoch 273, CIFAR-10 Batch 1:  Loss:     1.1230 Validation Accuracy: 0.575000\n",
      "Epoch 274, CIFAR-10 Batch 1:  Loss:     1.1177 Validation Accuracy: 0.575000\n",
      "Epoch 275, CIFAR-10 Batch 1:  Loss:     1.1162 Validation Accuracy: 0.575000\n",
      "Epoch 276, CIFAR-10 Batch 1:  Loss:     1.1140 Validation Accuracy: 0.575000\n",
      "Epoch 277, CIFAR-10 Batch 1:  Loss:     1.1125 Validation Accuracy: 0.575000\n",
      "Epoch 278, CIFAR-10 Batch 1:  Loss:     1.1102 Validation Accuracy: 0.575000\n",
      "Epoch 279, CIFAR-10 Batch 1:  Loss:     1.1091 Validation Accuracy: 0.575000\n",
      "Epoch 280, CIFAR-10 Batch 1:  Loss:     1.1080 Validation Accuracy: 0.575000\n",
      "Epoch 281, CIFAR-10 Batch 1:  Loss:     1.1082 Validation Accuracy: 0.575000\n",
      "Epoch 282, CIFAR-10 Batch 1:  Loss:     1.1049 Validation Accuracy: 0.575000\n",
      "Epoch 283, CIFAR-10 Batch 1:  Loss:     1.1042 Validation Accuracy: 0.575000\n",
      "Epoch 284, CIFAR-10 Batch 1:  Loss:     1.1042 Validation Accuracy: 0.575000\n",
      "Epoch 285, CIFAR-10 Batch 1:  Loss:     1.1044 Validation Accuracy: 0.575000\n",
      "Epoch 286, CIFAR-10 Batch 1:  Loss:     1.0998 Validation Accuracy: 0.600000\n",
      "Epoch 287, CIFAR-10 Batch 1:  Loss:     1.0993 Validation Accuracy: 0.575000\n",
      "Epoch 288, CIFAR-10 Batch 1:  Loss:     1.0973 Validation Accuracy: 0.575000\n",
      "Epoch 289, CIFAR-10 Batch 1:  Loss:     1.0966 Validation Accuracy: 0.600000\n",
      "Epoch 290, CIFAR-10 Batch 1:  Loss:     1.0958 Validation Accuracy: 0.600000\n",
      "Epoch 291, CIFAR-10 Batch 1:  Loss:     1.0940 Validation Accuracy: 0.600000\n",
      "Epoch 292, CIFAR-10 Batch 1:  Loss:     1.0930 Validation Accuracy: 0.600000\n",
      "Epoch 293, CIFAR-10 Batch 1:  Loss:     1.0900 Validation Accuracy: 0.600000\n",
      "Epoch 294, CIFAR-10 Batch 1:  Loss:     1.0903 Validation Accuracy: 0.600000\n",
      "Epoch 295, CIFAR-10 Batch 1:  Loss:     1.0892 Validation Accuracy: 0.600000\n",
      "Epoch 296, CIFAR-10 Batch 1:  Loss:     1.0895 Validation Accuracy: 0.600000\n",
      "Epoch 297, CIFAR-10 Batch 1:  Loss:     1.0874 Validation Accuracy: 0.600000\n",
      "Epoch 298, CIFAR-10 Batch 1:  Loss:     1.0870 Validation Accuracy: 0.600000\n",
      "Epoch 299, CIFAR-10 Batch 1:  Loss:     1.0847 Validation Accuracy: 0.600000\n",
      "Epoch 300, CIFAR-10 Batch 1:  Loss:     1.0856 Validation Accuracy: 0.600000\n",
      "Epoch 301, CIFAR-10 Batch 1:  Loss:     1.0863 Validation Accuracy: 0.600000\n",
      "Epoch 302, CIFAR-10 Batch 1:  Loss:     1.0867 Validation Accuracy: 0.600000\n",
      "Epoch 303, CIFAR-10 Batch 1:  Loss:     1.0848 Validation Accuracy: 0.600000\n",
      "Epoch 304, CIFAR-10 Batch 1:  Loss:     1.0828 Validation Accuracy: 0.600000\n",
      "Epoch 305, CIFAR-10 Batch 1:  Loss:     1.0825 Validation Accuracy: 0.600000\n",
      "Epoch 306, CIFAR-10 Batch 1:  Loss:     1.0804 Validation Accuracy: 0.600000\n",
      "Epoch 307, CIFAR-10 Batch 1:  Loss:     1.0810 Validation Accuracy: 0.600000\n",
      "Epoch 308, CIFAR-10 Batch 1:  Loss:     1.0769 Validation Accuracy: 0.600000\n",
      "Epoch 309, CIFAR-10 Batch 1:  Loss:     1.0791 Validation Accuracy: 0.600000\n",
      "Epoch 310, CIFAR-10 Batch 1:  Loss:     1.0775 Validation Accuracy: 0.600000\n",
      "Epoch 311, CIFAR-10 Batch 1:  Loss:     1.0766 Validation Accuracy: 0.600000\n",
      "Epoch 312, CIFAR-10 Batch 1:  Loss:     1.0771 Validation Accuracy: 0.625000\n",
      "Epoch 313, CIFAR-10 Batch 1:  Loss:     1.0748 Validation Accuracy: 0.625000\n",
      "Epoch 314, CIFAR-10 Batch 1:  Loss:     1.0742 Validation Accuracy: 0.625000\n",
      "Epoch 315, CIFAR-10 Batch 1:  Loss:     1.0750 Validation Accuracy: 0.625000\n",
      "Epoch 316, CIFAR-10 Batch 1:  Loss:     1.0731 Validation Accuracy: 0.625000\n",
      "Epoch 317, CIFAR-10 Batch 1:  Loss:     1.0738 Validation Accuracy: 0.625000\n",
      "Epoch 318, CIFAR-10 Batch 1:  Loss:     1.0729 Validation Accuracy: 0.625000\n",
      "Epoch 319, CIFAR-10 Batch 1:  Loss:     1.0729 Validation Accuracy: 0.625000\n",
      "Epoch 320, CIFAR-10 Batch 1:  Loss:     1.0711 Validation Accuracy: 0.625000\n",
      "Epoch 321, CIFAR-10 Batch 1:  Loss:     1.0721 Validation Accuracy: 0.625000\n",
      "Epoch 322, CIFAR-10 Batch 1:  Loss:     1.0705 Validation Accuracy: 0.625000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 323, CIFAR-10 Batch 1:  Loss:     1.0693 Validation Accuracy: 0.625000\n",
      "Epoch 324, CIFAR-10 Batch 1:  Loss:     1.0711 Validation Accuracy: 0.625000\n",
      "Epoch 325, CIFAR-10 Batch 1:  Loss:     1.0704 Validation Accuracy: 0.625000\n",
      "Epoch 326, CIFAR-10 Batch 1:  Loss:     1.0690 Validation Accuracy: 0.625000\n",
      "Epoch 327, CIFAR-10 Batch 1:  Loss:     1.0691 Validation Accuracy: 0.625000\n",
      "Epoch 328, CIFAR-10 Batch 1:  Loss:     1.0652 Validation Accuracy: 0.625000\n",
      "Epoch 329, CIFAR-10 Batch 1:  Loss:     1.0670 Validation Accuracy: 0.600000\n",
      "Epoch 330, CIFAR-10 Batch 1:  Loss:     1.0642 Validation Accuracy: 0.600000\n",
      "Epoch 331, CIFAR-10 Batch 1:  Loss:     1.0642 Validation Accuracy: 0.600000\n",
      "Epoch 332, CIFAR-10 Batch 1:  Loss:     1.0641 Validation Accuracy: 0.600000\n",
      "Epoch 333, CIFAR-10 Batch 1:  Loss:     1.0633 Validation Accuracy: 0.600000\n",
      "Epoch 334, CIFAR-10 Batch 1:  Loss:     1.0630 Validation Accuracy: 0.600000\n",
      "Epoch 335, CIFAR-10 Batch 1:  Loss:     1.0607 Validation Accuracy: 0.600000\n",
      "Epoch 336, CIFAR-10 Batch 1:  Loss:     1.0608 Validation Accuracy: 0.600000\n",
      "Epoch 337, CIFAR-10 Batch 1:  Loss:     1.0606 Validation Accuracy: 0.600000\n",
      "Epoch 338, CIFAR-10 Batch 1:  Loss:     1.0587 Validation Accuracy: 0.600000\n",
      "Epoch 339, CIFAR-10 Batch 1:  Loss:     1.0598 Validation Accuracy: 0.625000\n",
      "Epoch 340, CIFAR-10 Batch 1:  Loss:     1.0583 Validation Accuracy: 0.625000\n",
      "Epoch 341, CIFAR-10 Batch 1:  Loss:     1.0588 Validation Accuracy: 0.625000\n",
      "Epoch 342, CIFAR-10 Batch 1:  Loss:     1.0582 Validation Accuracy: 0.625000\n",
      "Epoch 343, CIFAR-10 Batch 1:  Loss:     1.0582 Validation Accuracy: 0.625000\n",
      "Epoch 344, CIFAR-10 Batch 1:  Loss:     1.0564 Validation Accuracy: 0.625000\n",
      "Epoch 345, CIFAR-10 Batch 1:  Loss:     1.0558 Validation Accuracy: 0.625000\n",
      "Epoch 346, CIFAR-10 Batch 1:  Loss:     1.0543 Validation Accuracy: 0.625000\n",
      "Epoch 347, CIFAR-10 Batch 1:  Loss:     1.0542 Validation Accuracy: 0.625000\n",
      "Epoch 348, CIFAR-10 Batch 1:  Loss:     1.0527 Validation Accuracy: 0.625000\n",
      "Epoch 349, CIFAR-10 Batch 1:  Loss:     1.0546 Validation Accuracy: 0.625000\n",
      "Epoch 350, CIFAR-10 Batch 1:  Loss:     1.0523 Validation Accuracy: 0.625000\n",
      "Epoch 351, CIFAR-10 Batch 1:  Loss:     1.0522 Validation Accuracy: 0.625000\n",
      "Epoch 352, CIFAR-10 Batch 1:  Loss:     1.0502 Validation Accuracy: 0.625000\n",
      "Epoch 353, CIFAR-10 Batch 1:  Loss:     1.0501 Validation Accuracy: 0.625000\n",
      "Epoch 354, CIFAR-10 Batch 1:  Loss:     1.0504 Validation Accuracy: 0.625000\n",
      "Epoch 355, CIFAR-10 Batch 1:  Loss:     1.0478 Validation Accuracy: 0.625000\n",
      "Epoch 356, CIFAR-10 Batch 1:  Loss:     1.0473 Validation Accuracy: 0.625000\n",
      "Epoch 357, CIFAR-10 Batch 1:  Loss:     1.0461 Validation Accuracy: 0.625000\n",
      "Epoch 358, CIFAR-10 Batch 1:  Loss:     1.0467 Validation Accuracy: 0.625000\n",
      "Epoch 359, CIFAR-10 Batch 1:  Loss:     1.0470 Validation Accuracy: 0.625000\n",
      "Epoch 360, CIFAR-10 Batch 1:  Loss:     1.0464 Validation Accuracy: 0.625000\n",
      "Epoch 361, CIFAR-10 Batch 1:  Loss:     1.0451 Validation Accuracy: 0.625000\n",
      "Epoch 362, CIFAR-10 Batch 1:  Loss:     1.0452 Validation Accuracy: 0.625000\n",
      "Epoch 363, CIFAR-10 Batch 1:  Loss:     1.0452 Validation Accuracy: 0.625000\n",
      "Epoch 364, CIFAR-10 Batch 1:  Loss:     1.0415 Validation Accuracy: 0.625000\n",
      "Epoch 365, CIFAR-10 Batch 1:  Loss:     1.0403 Validation Accuracy: 0.625000\n",
      "Epoch 366, CIFAR-10 Batch 1:  Loss:     1.0404 Validation Accuracy: 0.625000\n",
      "Epoch 367, CIFAR-10 Batch 1:  Loss:     1.0402 Validation Accuracy: 0.625000\n",
      "Epoch 368, CIFAR-10 Batch 1:  Loss:     1.0398 Validation Accuracy: 0.625000\n",
      "Epoch 369, CIFAR-10 Batch 1:  Loss:     1.0388 Validation Accuracy: 0.625000\n",
      "Epoch 370, CIFAR-10 Batch 1:  Loss:     1.0376 Validation Accuracy: 0.625000\n",
      "Epoch 371, CIFAR-10 Batch 1:  Loss:     1.0378 Validation Accuracy: 0.625000\n",
      "Epoch 372, CIFAR-10 Batch 1:  Loss:     1.0362 Validation Accuracy: 0.625000\n",
      "Epoch 373, CIFAR-10 Batch 1:  Loss:     1.0367 Validation Accuracy: 0.625000\n",
      "Epoch 374, CIFAR-10 Batch 1:  Loss:     1.0359 Validation Accuracy: 0.625000\n",
      "Epoch 375, CIFAR-10 Batch 1:  Loss:     1.0341 Validation Accuracy: 0.625000\n",
      "Epoch 376, CIFAR-10 Batch 1:  Loss:     1.0324 Validation Accuracy: 0.625000\n",
      "Epoch 377, CIFAR-10 Batch 1:  Loss:     1.0320 Validation Accuracy: 0.625000\n",
      "Epoch 378, CIFAR-10 Batch 1:  Loss:     1.0326 Validation Accuracy: 0.600000\n",
      "Epoch 379, CIFAR-10 Batch 1:  Loss:     1.0317 Validation Accuracy: 0.600000\n",
      "Epoch 380, CIFAR-10 Batch 1:  Loss:     1.0310 Validation Accuracy: 0.600000\n",
      "Epoch 381, CIFAR-10 Batch 1:  Loss:     1.0313 Validation Accuracy: 0.600000\n",
      "Epoch 382, CIFAR-10 Batch 1:  Loss:     1.0305 Validation Accuracy: 0.600000\n",
      "Epoch 383, CIFAR-10 Batch 1:  Loss:     1.0279 Validation Accuracy: 0.600000\n",
      "Epoch 384, CIFAR-10 Batch 1:  Loss:     1.0291 Validation Accuracy: 0.600000\n",
      "Epoch 385, CIFAR-10 Batch 1:  Loss:     1.0274 Validation Accuracy: 0.600000\n",
      "Epoch 386, CIFAR-10 Batch 1:  Loss:     1.0282 Validation Accuracy: 0.600000\n",
      "Epoch 387, CIFAR-10 Batch 1:  Loss:     1.0273 Validation Accuracy: 0.600000\n",
      "Epoch 388, CIFAR-10 Batch 1:  Loss:     1.0289 Validation Accuracy: 0.600000\n",
      "Epoch 389, CIFAR-10 Batch 1:  Loss:     1.0279 Validation Accuracy: 0.600000\n",
      "Epoch 390, CIFAR-10 Batch 1:  Loss:     1.0274 Validation Accuracy: 0.600000\n",
      "Epoch 391, CIFAR-10 Batch 1:  Loss:     1.0275 Validation Accuracy: 0.600000\n",
      "Epoch 392, CIFAR-10 Batch 1:  Loss:     1.0257 Validation Accuracy: 0.600000\n",
      "Epoch 393, CIFAR-10 Batch 1:  Loss:     1.0260 Validation Accuracy: 0.600000\n",
      "Epoch 394, CIFAR-10 Batch 1:  Loss:     1.0246 Validation Accuracy: 0.600000\n",
      "Epoch 395, CIFAR-10 Batch 1:  Loss:     1.0236 Validation Accuracy: 0.600000\n",
      "Epoch 396, CIFAR-10 Batch 1:  Loss:     1.0221 Validation Accuracy: 0.600000\n",
      "Epoch 397, CIFAR-10 Batch 1:  Loss:     1.0210 Validation Accuracy: 0.600000\n",
      "Epoch 398, CIFAR-10 Batch 1:  Loss:     1.0210 Validation Accuracy: 0.625000\n",
      "Epoch 399, CIFAR-10 Batch 1:  Loss:     1.0195 Validation Accuracy: 0.625000\n",
      "Epoch 400, CIFAR-10 Batch 1:  Loss:     1.0188 Validation Accuracy: 0.625000\n",
      "Epoch 401, CIFAR-10 Batch 1:  Loss:     1.0194 Validation Accuracy: 0.625000\n",
      "Epoch 402, CIFAR-10 Batch 1:  Loss:     1.0168 Validation Accuracy: 0.625000\n",
      "Epoch 403, CIFAR-10 Batch 1:  Loss:     1.0172 Validation Accuracy: 0.625000\n",
      "Epoch 404, CIFAR-10 Batch 1:  Loss:     1.0158 Validation Accuracy: 0.625000\n",
      "Epoch 405, CIFAR-10 Batch 1:  Loss:     1.0148 Validation Accuracy: 0.625000\n",
      "Epoch 406, CIFAR-10 Batch 1:  Loss:     1.0145 Validation Accuracy: 0.625000\n",
      "Epoch 407, CIFAR-10 Batch 1:  Loss:     1.0139 Validation Accuracy: 0.625000\n",
      "Epoch 408, CIFAR-10 Batch 1:  Loss:     1.0126 Validation Accuracy: 0.625000\n",
      "Epoch 409, CIFAR-10 Batch 1:  Loss:     1.0120 Validation Accuracy: 0.625000\n",
      "Epoch 410, CIFAR-10 Batch 1:  Loss:     1.0109 Validation Accuracy: 0.625000\n",
      "Epoch 411, CIFAR-10 Batch 1:  Loss:     1.0114 Validation Accuracy: 0.625000\n",
      "Epoch 412, CIFAR-10 Batch 1:  Loss:     1.0112 Validation Accuracy: 0.625000\n",
      "Epoch 413, CIFAR-10 Batch 1:  Loss:     1.0095 Validation Accuracy: 0.625000\n",
      "Epoch 414, CIFAR-10 Batch 1:  Loss:     1.0079 Validation Accuracy: 0.625000\n",
      "Epoch 415, CIFAR-10 Batch 1:  Loss:     1.0079 Validation Accuracy: 0.625000\n",
      "Epoch 416, CIFAR-10 Batch 1:  Loss:     1.0060 Validation Accuracy: 0.625000\n",
      "Epoch 417, CIFAR-10 Batch 1:  Loss:     1.0065 Validation Accuracy: 0.625000\n",
      "Epoch 418, CIFAR-10 Batch 1:  Loss:     1.0062 Validation Accuracy: 0.625000\n",
      "Epoch 419, CIFAR-10 Batch 1:  Loss:     1.0053 Validation Accuracy: 0.625000\n",
      "Epoch 420, CIFAR-10 Batch 1:  Loss:     1.0048 Validation Accuracy: 0.625000\n",
      "Epoch 421, CIFAR-10 Batch 1:  Loss:     1.0050 Validation Accuracy: 0.625000\n",
      "Epoch 422, CIFAR-10 Batch 1:  Loss:     1.0034 Validation Accuracy: 0.625000\n",
      "Epoch 423, CIFAR-10 Batch 1:  Loss:     1.0023 Validation Accuracy: 0.625000\n",
      "Epoch 424, CIFAR-10 Batch 1:  Loss:     1.0021 Validation Accuracy: 0.625000\n",
      "Epoch 425, CIFAR-10 Batch 1:  Loss:     1.0024 Validation Accuracy: 0.625000\n",
      "Epoch 426, CIFAR-10 Batch 1:  Loss:     1.0025 Validation Accuracy: 0.625000\n",
      "Epoch 427, CIFAR-10 Batch 1:  Loss:     1.0021 Validation Accuracy: 0.625000\n",
      "Epoch 428, CIFAR-10 Batch 1:  Loss:     0.9998 Validation Accuracy: 0.625000\n",
      "Epoch 429, CIFAR-10 Batch 1:  Loss:     0.9981 Validation Accuracy: 0.625000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 430, CIFAR-10 Batch 1:  Loss:     0.9973 Validation Accuracy: 0.625000\n",
      "Epoch 431, CIFAR-10 Batch 1:  Loss:     0.9984 Validation Accuracy: 0.625000\n",
      "Epoch 432, CIFAR-10 Batch 1:  Loss:     0.9958 Validation Accuracy: 0.625000\n",
      "Epoch 433, CIFAR-10 Batch 1:  Loss:     0.9960 Validation Accuracy: 0.625000\n",
      "Epoch 434, CIFAR-10 Batch 1:  Loss:     0.9961 Validation Accuracy: 0.625000\n",
      "Epoch 435, CIFAR-10 Batch 1:  Loss:     0.9968 Validation Accuracy: 0.625000\n",
      "Epoch 436, CIFAR-10 Batch 1:  Loss:     0.9929 Validation Accuracy: 0.625000\n",
      "Epoch 437, CIFAR-10 Batch 1:  Loss:     0.9918 Validation Accuracy: 0.625000\n",
      "Epoch 438, CIFAR-10 Batch 1:  Loss:     0.9912 Validation Accuracy: 0.625000\n",
      "Epoch 439, CIFAR-10 Batch 1:  Loss:     0.9919 Validation Accuracy: 0.625000\n",
      "Epoch 440, CIFAR-10 Batch 1:  Loss:     0.9901 Validation Accuracy: 0.625000\n",
      "Epoch 441, CIFAR-10 Batch 1:  Loss:     0.9894 Validation Accuracy: 0.625000\n",
      "Epoch 442, CIFAR-10 Batch 1:  Loss:     0.9888 Validation Accuracy: 0.625000\n",
      "Epoch 443, CIFAR-10 Batch 1:  Loss:     0.9866 Validation Accuracy: 0.625000\n",
      "Epoch 444, CIFAR-10 Batch 1:  Loss:     0.9880 Validation Accuracy: 0.625000\n",
      "Epoch 445, CIFAR-10 Batch 1:  Loss:     0.9861 Validation Accuracy: 0.625000\n",
      "Epoch 446, CIFAR-10 Batch 1:  Loss:     0.9864 Validation Accuracy: 0.625000\n",
      "Epoch 447, CIFAR-10 Batch 1:  Loss:     0.9860 Validation Accuracy: 0.625000\n",
      "Epoch 448, CIFAR-10 Batch 1:  Loss:     0.9839 Validation Accuracy: 0.625000\n",
      "Epoch 449, CIFAR-10 Batch 1:  Loss:     0.9839 Validation Accuracy: 0.625000\n",
      "Epoch 450, CIFAR-10 Batch 1:  Loss:     0.9817 Validation Accuracy: 0.625000\n",
      "Epoch 451, CIFAR-10 Batch 1:  Loss:     0.9821 Validation Accuracy: 0.625000\n",
      "Epoch 452, CIFAR-10 Batch 1:  Loss:     0.9820 Validation Accuracy: 0.625000\n",
      "Epoch 453, CIFAR-10 Batch 1:  Loss:     0.9810 Validation Accuracy: 0.625000\n",
      "Epoch 454, CIFAR-10 Batch 1:  Loss:     0.9791 Validation Accuracy: 0.625000\n",
      "Epoch 455, CIFAR-10 Batch 1:  Loss:     0.9799 Validation Accuracy: 0.625000\n",
      "Epoch 456, CIFAR-10 Batch 1:  Loss:     0.9782 Validation Accuracy: 0.625000\n",
      "Epoch 457, CIFAR-10 Batch 1:  Loss:     0.9781 Validation Accuracy: 0.625000\n",
      "Epoch 458, CIFAR-10 Batch 1:  Loss:     0.9778 Validation Accuracy: 0.625000\n",
      "Epoch 459, CIFAR-10 Batch 1:  Loss:     0.9757 Validation Accuracy: 0.625000\n",
      "Epoch 460, CIFAR-10 Batch 1:  Loss:     0.9759 Validation Accuracy: 0.625000\n",
      "Epoch 461, CIFAR-10 Batch 1:  Loss:     0.9764 Validation Accuracy: 0.625000\n",
      "Epoch 462, CIFAR-10 Batch 1:  Loss:     0.9746 Validation Accuracy: 0.625000\n",
      "Epoch 463, CIFAR-10 Batch 1:  Loss:     0.9749 Validation Accuracy: 0.625000\n",
      "Epoch 464, CIFAR-10 Batch 1:  Loss:     0.9739 Validation Accuracy: 0.625000\n",
      "Epoch 465, CIFAR-10 Batch 1:  Loss:     0.9745 Validation Accuracy: 0.625000\n",
      "Epoch 466, CIFAR-10 Batch 1:  Loss:     0.9720 Validation Accuracy: 0.625000\n",
      "Epoch 467, CIFAR-10 Batch 1:  Loss:     0.9728 Validation Accuracy: 0.625000\n",
      "Epoch 468, CIFAR-10 Batch 1:  Loss:     0.9718 Validation Accuracy: 0.625000\n",
      "Epoch 469, CIFAR-10 Batch 1:  Loss:     0.9706 Validation Accuracy: 0.625000\n",
      "Epoch 470, CIFAR-10 Batch 1:  Loss:     0.9705 Validation Accuracy: 0.625000\n",
      "Epoch 471, CIFAR-10 Batch 1:  Loss:     0.9698 Validation Accuracy: 0.625000\n",
      "Epoch 472, CIFAR-10 Batch 1:  Loss:     0.9682 Validation Accuracy: 0.650000\n",
      "Epoch 473, CIFAR-10 Batch 1:  Loss:     0.9684 Validation Accuracy: 0.625000\n",
      "Epoch 474, CIFAR-10 Batch 1:  Loss:     0.9678 Validation Accuracy: 0.650000\n",
      "Epoch 475, CIFAR-10 Batch 1:  Loss:     0.9664 Validation Accuracy: 0.650000\n",
      "Epoch 476, CIFAR-10 Batch 1:  Loss:     0.9666 Validation Accuracy: 0.625000\n",
      "Epoch 477, CIFAR-10 Batch 1:  Loss:     0.9652 Validation Accuracy: 0.650000\n",
      "Epoch 478, CIFAR-10 Batch 1:  Loss:     0.9669 Validation Accuracy: 0.625000\n",
      "Epoch 479, CIFAR-10 Batch 1:  Loss:     0.9655 Validation Accuracy: 0.625000\n",
      "Epoch 480, CIFAR-10 Batch 1:  Loss:     0.9649 Validation Accuracy: 0.625000\n",
      "Epoch 481, CIFAR-10 Batch 1:  Loss:     0.9632 Validation Accuracy: 0.625000\n",
      "Epoch 482, CIFAR-10 Batch 1:  Loss:     0.9656 Validation Accuracy: 0.625000\n",
      "Epoch 483, CIFAR-10 Batch 1:  Loss:     0.9631 Validation Accuracy: 0.625000\n",
      "Epoch 484, CIFAR-10 Batch 1:  Loss:     0.9624 Validation Accuracy: 0.650000\n",
      "Epoch 485, CIFAR-10 Batch 1:  Loss:     0.9637 Validation Accuracy: 0.650000\n",
      "Epoch 486, CIFAR-10 Batch 1:  Loss:     0.9624 Validation Accuracy: 0.650000\n",
      "Epoch 487, CIFAR-10 Batch 1:  Loss:     0.9604 Validation Accuracy: 0.650000\n",
      "Epoch 488, CIFAR-10 Batch 1:  Loss:     0.9608 Validation Accuracy: 0.650000\n",
      "Epoch 489, CIFAR-10 Batch 1:  Loss:     0.9622 Validation Accuracy: 0.625000\n",
      "Epoch 490, CIFAR-10 Batch 1:  Loss:     0.9595 Validation Accuracy: 0.650000\n",
      "Epoch 491, CIFAR-10 Batch 1:  Loss:     0.9611 Validation Accuracy: 0.625000\n",
      "Epoch 492, CIFAR-10 Batch 1:  Loss:     0.9608 Validation Accuracy: 0.625000\n",
      "Epoch 493, CIFAR-10 Batch 1:  Loss:     0.9586 Validation Accuracy: 0.625000\n",
      "Epoch 494, CIFAR-10 Batch 1:  Loss:     0.9587 Validation Accuracy: 0.625000\n",
      "Epoch 495, CIFAR-10 Batch 1:  Loss:     0.9583 Validation Accuracy: 0.625000\n",
      "Epoch 496, CIFAR-10 Batch 1:  Loss:     0.9592 Validation Accuracy: 0.625000\n",
      "Epoch 497, CIFAR-10 Batch 1:  Loss:     0.9585 Validation Accuracy: 0.650000\n",
      "Epoch 498, CIFAR-10 Batch 1:  Loss:     0.9596 Validation Accuracy: 0.625000\n",
      "Epoch 499, CIFAR-10 Batch 1:  Loss:     0.9585 Validation Accuracy: 0.625000\n",
      "Epoch 500, CIFAR-10 Batch 1:  Loss:     0.9575 Validation Accuracy: 0.625000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完全训练模型\n",
    "\n",
    "现在，单个 CIFAR-10 部分的准确率已经不错了，试试所有五个部分吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.3363 Validation Accuracy: 0.100000\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     2.2723 Validation Accuracy: 0.175000\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     2.1773 Validation Accuracy: 0.200000\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     2.0626 Validation Accuracy: 0.325000\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     2.1905 Validation Accuracy: 0.175000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.1960 Validation Accuracy: 0.150000\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     2.1386 Validation Accuracy: 0.200000\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     1.9175 Validation Accuracy: 0.275000\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     1.8883 Validation Accuracy: 0.350000\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     2.1108 Validation Accuracy: 0.225000\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.1289 Validation Accuracy: 0.275000\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     2.0560 Validation Accuracy: 0.125000\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     1.7582 Validation Accuracy: 0.325000\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     1.7607 Validation Accuracy: 0.450000\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     2.0073 Validation Accuracy: 0.225000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.9920 Validation Accuracy: 0.375000\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     1.9541 Validation Accuracy: 0.300000\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     1.7626 Validation Accuracy: 0.400000\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     1.7175 Validation Accuracy: 0.450000\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     1.9762 Validation Accuracy: 0.300000\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.9179 Validation Accuracy: 0.400000\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     1.8635 Validation Accuracy: 0.350000\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     1.7503 Validation Accuracy: 0.375000\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     1.6909 Validation Accuracy: 0.425000\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     1.9418 Validation Accuracy: 0.275000\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.8701 Validation Accuracy: 0.400000\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     1.7955 Validation Accuracy: 0.325000\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     1.7315 Validation Accuracy: 0.425000\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     1.6714 Validation Accuracy: 0.400000\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     1.9018 Validation Accuracy: 0.250000\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.8432 Validation Accuracy: 0.450000\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     1.7476 Validation Accuracy: 0.350000\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     1.7113 Validation Accuracy: 0.350000\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     1.6490 Validation Accuracy: 0.400000\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     1.8681 Validation Accuracy: 0.350000\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.8257 Validation Accuracy: 0.400000\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     1.7154 Validation Accuracy: 0.350000\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     1.6954 Validation Accuracy: 0.350000\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     1.6305 Validation Accuracy: 0.400000\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     1.8400 Validation Accuracy: 0.375000\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.8048 Validation Accuracy: 0.425000\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     1.6894 Validation Accuracy: 0.400000\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     1.6792 Validation Accuracy: 0.375000\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     1.6130 Validation Accuracy: 0.425000\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     1.8211 Validation Accuracy: 0.375000\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.7904 Validation Accuracy: 0.450000\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     1.6723 Validation Accuracy: 0.425000\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     1.6641 Validation Accuracy: 0.375000\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     1.5989 Validation Accuracy: 0.425000\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     1.8033 Validation Accuracy: 0.375000\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     1.7751 Validation Accuracy: 0.425000\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:     1.6617 Validation Accuracy: 0.400000\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:     1.6528 Validation Accuracy: 0.375000\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:     1.5851 Validation Accuracy: 0.425000\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:     1.7901 Validation Accuracy: 0.375000\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.7612 Validation Accuracy: 0.425000\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:     1.6523 Validation Accuracy: 0.375000\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:     1.6418 Validation Accuracy: 0.375000\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:     1.5743 Validation Accuracy: 0.425000\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:     1.7833 Validation Accuracy: 0.400000\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.7522 Validation Accuracy: 0.425000\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:     1.6448 Validation Accuracy: 0.375000\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:     1.6314 Validation Accuracy: 0.375000\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:     1.5649 Validation Accuracy: 0.450000\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:     1.7755 Validation Accuracy: 0.400000\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     1.7422 Validation Accuracy: 0.425000\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:     1.6393 Validation Accuracy: 0.375000\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:     1.6186 Validation Accuracy: 0.375000\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:     1.5550 Validation Accuracy: 0.450000\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:     1.7697 Validation Accuracy: 0.400000\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     1.7304 Validation Accuracy: 0.425000\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:     1.6354 Validation Accuracy: 0.375000\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:     1.6047 Validation Accuracy: 0.425000\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:     1.5498 Validation Accuracy: 0.450000\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:     1.7632 Validation Accuracy: 0.400000\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     1.7230 Validation Accuracy: 0.425000\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:     1.6287 Validation Accuracy: 0.375000\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:     1.5950 Validation Accuracy: 0.425000\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:     1.5422 Validation Accuracy: 0.425000\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:     1.7596 Validation Accuracy: 0.400000\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     1.7147 Validation Accuracy: 0.425000\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:     1.6222 Validation Accuracy: 0.375000\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:     1.5853 Validation Accuracy: 0.425000\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:     1.5349 Validation Accuracy: 0.425000\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:     1.7556 Validation Accuracy: 0.400000\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     1.6943 Validation Accuracy: 0.425000\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:     1.6162 Validation Accuracy: 0.375000\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:     1.5765 Validation Accuracy: 0.425000\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:     1.5256 Validation Accuracy: 0.450000\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:     1.7533 Validation Accuracy: 0.400000\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     1.6859 Validation Accuracy: 0.425000\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:     1.6111 Validation Accuracy: 0.375000\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:     1.5680 Validation Accuracy: 0.425000\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:     1.5152 Validation Accuracy: 0.450000\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:     1.7530 Validation Accuracy: 0.400000\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     1.6761 Validation Accuracy: 0.425000\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:     1.6048 Validation Accuracy: 0.400000\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:     1.5649 Validation Accuracy: 0.425000\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:     1.5056 Validation Accuracy: 0.450000\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:     1.7468 Validation Accuracy: 0.375000\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     1.6673 Validation Accuracy: 0.425000\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:     1.5995 Validation Accuracy: 0.425000\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:     1.5539 Validation Accuracy: 0.425000\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:     1.4985 Validation Accuracy: 0.450000\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:     1.7366 Validation Accuracy: 0.375000\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     1.6608 Validation Accuracy: 0.475000\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:     1.5823 Validation Accuracy: 0.450000\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:     1.5435 Validation Accuracy: 0.450000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, CIFAR-10 Batch 4:  Loss:     1.4987 Validation Accuracy: 0.475000\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:     1.7203 Validation Accuracy: 0.400000\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     1.6466 Validation Accuracy: 0.475000\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:     1.5723 Validation Accuracy: 0.450000\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:     1.5396 Validation Accuracy: 0.425000\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:     1.4838 Validation Accuracy: 0.475000\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:     1.7091 Validation Accuracy: 0.400000\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     1.6488 Validation Accuracy: 0.475000\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:     1.5547 Validation Accuracy: 0.475000\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:     1.5330 Validation Accuracy: 0.450000\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:     1.4871 Validation Accuracy: 0.450000\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:     1.7001 Validation Accuracy: 0.450000\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     1.6506 Validation Accuracy: 0.500000\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:     1.5455 Validation Accuracy: 0.475000\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:     1.5210 Validation Accuracy: 0.450000\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:     1.4795 Validation Accuracy: 0.450000\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:     1.6966 Validation Accuracy: 0.450000\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     1.6542 Validation Accuracy: 0.425000\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:     1.5421 Validation Accuracy: 0.500000\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:     1.5115 Validation Accuracy: 0.450000\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:     1.4670 Validation Accuracy: 0.450000\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:     1.6932 Validation Accuracy: 0.450000\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     1.6474 Validation Accuracy: 0.500000\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:     1.5222 Validation Accuracy: 0.500000\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:     1.5049 Validation Accuracy: 0.450000\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:     1.4562 Validation Accuracy: 0.475000\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:     1.6914 Validation Accuracy: 0.450000\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     1.6452 Validation Accuracy: 0.475000\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:     1.5129 Validation Accuracy: 0.500000\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:     1.4957 Validation Accuracy: 0.450000\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:     1.4456 Validation Accuracy: 0.500000\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:     1.6889 Validation Accuracy: 0.425000\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     1.6411 Validation Accuracy: 0.450000\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:     1.5042 Validation Accuracy: 0.500000\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:     1.4891 Validation Accuracy: 0.450000\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:     1.4369 Validation Accuracy: 0.500000\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:     1.6844 Validation Accuracy: 0.425000\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     1.6363 Validation Accuracy: 0.425000\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:     1.4999 Validation Accuracy: 0.500000\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:     1.4857 Validation Accuracy: 0.450000\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:     1.4324 Validation Accuracy: 0.525000\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:     1.6831 Validation Accuracy: 0.425000\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     1.6352 Validation Accuracy: 0.475000\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:     1.4955 Validation Accuracy: 0.500000\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:     1.4813 Validation Accuracy: 0.450000\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:     1.4247 Validation Accuracy: 0.525000\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:     1.6808 Validation Accuracy: 0.425000\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     1.6309 Validation Accuracy: 0.475000\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:     1.4873 Validation Accuracy: 0.500000\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:     1.4740 Validation Accuracy: 0.450000\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:     1.4182 Validation Accuracy: 0.525000\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:     1.6788 Validation Accuracy: 0.425000\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     1.6267 Validation Accuracy: 0.450000\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:     1.4782 Validation Accuracy: 0.500000\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:     1.4678 Validation Accuracy: 0.450000\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:     1.4137 Validation Accuracy: 0.525000\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:     1.6777 Validation Accuracy: 0.425000\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     1.6228 Validation Accuracy: 0.525000\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:     1.4709 Validation Accuracy: 0.500000\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:     1.4594 Validation Accuracy: 0.450000\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:     1.4069 Validation Accuracy: 0.525000\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:     1.6738 Validation Accuracy: 0.425000\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     1.6210 Validation Accuracy: 0.525000\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:     1.4641 Validation Accuracy: 0.500000\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:     1.4482 Validation Accuracy: 0.450000\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:     1.4032 Validation Accuracy: 0.525000\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:     1.6721 Validation Accuracy: 0.400000\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     1.6191 Validation Accuracy: 0.525000\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:     1.4592 Validation Accuracy: 0.500000\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:     1.4382 Validation Accuracy: 0.450000\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:     1.3980 Validation Accuracy: 0.550000\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:     1.6678 Validation Accuracy: 0.400000\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     1.6146 Validation Accuracy: 0.500000\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:     1.4547 Validation Accuracy: 0.500000\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:     1.4353 Validation Accuracy: 0.450000\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:     1.3935 Validation Accuracy: 0.550000\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:     1.6650 Validation Accuracy: 0.400000\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     1.6114 Validation Accuracy: 0.525000\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:     1.4502 Validation Accuracy: 0.500000\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:     1.4286 Validation Accuracy: 0.475000\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:     1.3879 Validation Accuracy: 0.550000\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:     1.6620 Validation Accuracy: 0.375000\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     1.6068 Validation Accuracy: 0.500000\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:     1.4455 Validation Accuracy: 0.500000\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:     1.4250 Validation Accuracy: 0.475000\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:     1.3833 Validation Accuracy: 0.550000\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:     1.6591 Validation Accuracy: 0.375000\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     1.6030 Validation Accuracy: 0.500000\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:     1.4414 Validation Accuracy: 0.475000\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:     1.4180 Validation Accuracy: 0.475000\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:     1.3777 Validation Accuracy: 0.550000\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:     1.6578 Validation Accuracy: 0.375000\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     1.5996 Validation Accuracy: 0.500000\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:     1.4384 Validation Accuracy: 0.500000\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:     1.4117 Validation Accuracy: 0.475000\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:     1.3719 Validation Accuracy: 0.575000\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:     1.6556 Validation Accuracy: 0.375000\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     1.5972 Validation Accuracy: 0.450000\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:     1.4328 Validation Accuracy: 0.500000\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:     1.4039 Validation Accuracy: 0.475000\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:     1.3667 Validation Accuracy: 0.575000\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:     1.6534 Validation Accuracy: 0.375000\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     1.5915 Validation Accuracy: 0.475000\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:     1.4298 Validation Accuracy: 0.500000\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:     1.3984 Validation Accuracy: 0.500000\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:     1.3619 Validation Accuracy: 0.575000\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss:     1.6504 Validation Accuracy: 0.375000\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     1.5884 Validation Accuracy: 0.450000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, CIFAR-10 Batch 2:  Loss:     1.4260 Validation Accuracy: 0.475000\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:     1.3934 Validation Accuracy: 0.500000\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:     1.3576 Validation Accuracy: 0.575000\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:     1.6497 Validation Accuracy: 0.375000\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     1.5865 Validation Accuracy: 0.475000\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:     1.4222 Validation Accuracy: 0.500000\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:     1.3871 Validation Accuracy: 0.500000\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:     1.3525 Validation Accuracy: 0.575000\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:     1.6465 Validation Accuracy: 0.350000\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     1.5830 Validation Accuracy: 0.450000\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:     1.4193 Validation Accuracy: 0.500000\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:     1.3806 Validation Accuracy: 0.500000\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:     1.3480 Validation Accuracy: 0.600000\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:     1.6442 Validation Accuracy: 0.375000\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     1.5801 Validation Accuracy: 0.450000\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:     1.4164 Validation Accuracy: 0.500000\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:     1.3766 Validation Accuracy: 0.525000\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:     1.3424 Validation Accuracy: 0.600000\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:     1.6418 Validation Accuracy: 0.375000\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     1.5764 Validation Accuracy: 0.475000\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:     1.4113 Validation Accuracy: 0.500000\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:     1.3691 Validation Accuracy: 0.525000\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:     1.3384 Validation Accuracy: 0.600000\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:     1.6397 Validation Accuracy: 0.375000\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     1.5742 Validation Accuracy: 0.475000\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:     1.4084 Validation Accuracy: 0.500000\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:     1.3629 Validation Accuracy: 0.525000\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:     1.3338 Validation Accuracy: 0.600000\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:     1.6366 Validation Accuracy: 0.375000\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     1.5706 Validation Accuracy: 0.450000\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:     1.4050 Validation Accuracy: 0.500000\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:     1.3570 Validation Accuracy: 0.525000\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:     1.3289 Validation Accuracy: 0.600000\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:     1.6349 Validation Accuracy: 0.375000\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     1.5672 Validation Accuracy: 0.450000\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:     1.4006 Validation Accuracy: 0.500000\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:     1.3504 Validation Accuracy: 0.525000\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:     1.3243 Validation Accuracy: 0.600000\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:     1.6327 Validation Accuracy: 0.400000\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     1.5667 Validation Accuracy: 0.450000\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:     1.3979 Validation Accuracy: 0.500000\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:     1.3439 Validation Accuracy: 0.525000\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:     1.3202 Validation Accuracy: 0.600000\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:     1.6322 Validation Accuracy: 0.400000\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     1.5624 Validation Accuracy: 0.425000\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:     1.3938 Validation Accuracy: 0.500000\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:     1.3395 Validation Accuracy: 0.525000\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:     1.3168 Validation Accuracy: 0.600000\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:     1.6309 Validation Accuracy: 0.425000\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     1.5600 Validation Accuracy: 0.450000\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:     1.3902 Validation Accuracy: 0.500000\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:     1.3345 Validation Accuracy: 0.500000\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:     1.3131 Validation Accuracy: 0.600000\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:     1.6288 Validation Accuracy: 0.425000\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     1.5553 Validation Accuracy: 0.450000\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:     1.3867 Validation Accuracy: 0.500000\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:     1.3291 Validation Accuracy: 0.500000\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:     1.3108 Validation Accuracy: 0.575000\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:     1.6273 Validation Accuracy: 0.425000\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     1.5534 Validation Accuracy: 0.450000\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:     1.3837 Validation Accuracy: 0.500000\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:     1.3240 Validation Accuracy: 0.500000\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:     1.3075 Validation Accuracy: 0.575000\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:     1.6248 Validation Accuracy: 0.425000\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     1.5521 Validation Accuracy: 0.450000\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:     1.3816 Validation Accuracy: 0.500000\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:     1.3198 Validation Accuracy: 0.500000\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:     1.3045 Validation Accuracy: 0.575000\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:     1.6236 Validation Accuracy: 0.425000\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     1.5471 Validation Accuracy: 0.450000\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:     1.3794 Validation Accuracy: 0.500000\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:     1.3138 Validation Accuracy: 0.500000\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:     1.3015 Validation Accuracy: 0.575000\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:     1.6222 Validation Accuracy: 0.425000\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     1.5444 Validation Accuracy: 0.475000\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:     1.3757 Validation Accuracy: 0.500000\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:     1.3099 Validation Accuracy: 0.500000\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:     1.2989 Validation Accuracy: 0.575000\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:     1.6206 Validation Accuracy: 0.425000\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     1.5440 Validation Accuracy: 0.475000\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:     1.3728 Validation Accuracy: 0.500000\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:     1.3050 Validation Accuracy: 0.500000\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:     1.2964 Validation Accuracy: 0.575000\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:     1.6191 Validation Accuracy: 0.425000\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     1.5396 Validation Accuracy: 0.475000\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:     1.3698 Validation Accuracy: 0.500000\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:     1.3008 Validation Accuracy: 0.500000\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:     1.2951 Validation Accuracy: 0.575000\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:     1.6175 Validation Accuracy: 0.425000\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     1.5353 Validation Accuracy: 0.475000\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:     1.3659 Validation Accuracy: 0.500000\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:     1.2956 Validation Accuracy: 0.525000\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:     1.2936 Validation Accuracy: 0.575000\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:     1.6144 Validation Accuracy: 0.425000\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     1.5346 Validation Accuracy: 0.475000\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:     1.3641 Validation Accuracy: 0.500000\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:     1.2897 Validation Accuracy: 0.525000\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:     1.2915 Validation Accuracy: 0.575000\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:     1.6129 Validation Accuracy: 0.400000\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     1.5302 Validation Accuracy: 0.475000\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:     1.3622 Validation Accuracy: 0.500000\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:     1.2833 Validation Accuracy: 0.525000\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:     1.2900 Validation Accuracy: 0.575000\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:     1.6101 Validation Accuracy: 0.400000\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     1.5303 Validation Accuracy: 0.475000\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:     1.3611 Validation Accuracy: 0.500000\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:     1.2789 Validation Accuracy: 0.525000\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:     1.2883 Validation Accuracy: 0.575000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65, CIFAR-10 Batch 5:  Loss:     1.6078 Validation Accuracy: 0.400000\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     1.5289 Validation Accuracy: 0.475000\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:     1.3587 Validation Accuracy: 0.500000\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:     1.2747 Validation Accuracy: 0.525000\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:     1.2878 Validation Accuracy: 0.575000\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:     1.6055 Validation Accuracy: 0.400000\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     1.5256 Validation Accuracy: 0.475000\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:     1.3558 Validation Accuracy: 0.500000\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:     1.2698 Validation Accuracy: 0.525000\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:     1.2865 Validation Accuracy: 0.575000\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:     1.6038 Validation Accuracy: 0.400000\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     1.5258 Validation Accuracy: 0.475000\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:     1.3543 Validation Accuracy: 0.500000\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:     1.2656 Validation Accuracy: 0.525000\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:     1.2845 Validation Accuracy: 0.575000\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:     1.6042 Validation Accuracy: 0.400000\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     1.5235 Validation Accuracy: 0.475000\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:     1.3526 Validation Accuracy: 0.500000\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:     1.2603 Validation Accuracy: 0.500000\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:     1.2826 Validation Accuracy: 0.575000\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:     1.6035 Validation Accuracy: 0.400000\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     1.5190 Validation Accuracy: 0.475000\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:     1.3484 Validation Accuracy: 0.500000\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:     1.2557 Validation Accuracy: 0.525000\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:     1.2799 Validation Accuracy: 0.575000\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:     1.6023 Validation Accuracy: 0.400000\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     1.5172 Validation Accuracy: 0.475000\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:     1.3461 Validation Accuracy: 0.500000\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:     1.2539 Validation Accuracy: 0.525000\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:     1.2781 Validation Accuracy: 0.575000\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:     1.6013 Validation Accuracy: 0.400000\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     1.5152 Validation Accuracy: 0.475000\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:     1.3447 Validation Accuracy: 0.500000\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:     1.2505 Validation Accuracy: 0.525000\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:     1.2764 Validation Accuracy: 0.575000\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:     1.5998 Validation Accuracy: 0.400000\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     1.5123 Validation Accuracy: 0.475000\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:     1.3427 Validation Accuracy: 0.500000\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:     1.2467 Validation Accuracy: 0.525000\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:     1.2741 Validation Accuracy: 0.575000\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:     1.5980 Validation Accuracy: 0.400000\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     1.5118 Validation Accuracy: 0.475000\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:     1.3410 Validation Accuracy: 0.500000\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:     1.2452 Validation Accuracy: 0.525000\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:     1.2717 Validation Accuracy: 0.575000\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:     1.5969 Validation Accuracy: 0.400000\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     1.5129 Validation Accuracy: 0.475000\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:     1.3387 Validation Accuracy: 0.500000\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:     1.2425 Validation Accuracy: 0.525000\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:     1.2696 Validation Accuracy: 0.575000\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:     1.5948 Validation Accuracy: 0.400000\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     1.5136 Validation Accuracy: 0.475000\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss:     1.3389 Validation Accuracy: 0.500000\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss:     1.2400 Validation Accuracy: 0.525000\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss:     1.2684 Validation Accuracy: 0.575000\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss:     1.5917 Validation Accuracy: 0.400000\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     1.5101 Validation Accuracy: 0.475000\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss:     1.3360 Validation Accuracy: 0.500000\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss:     1.2383 Validation Accuracy: 0.525000\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss:     1.2675 Validation Accuracy: 0.575000\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss:     1.5893 Validation Accuracy: 0.400000\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     1.5104 Validation Accuracy: 0.475000\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss:     1.3349 Validation Accuracy: 0.500000\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss:     1.2367 Validation Accuracy: 0.525000\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss:     1.2655 Validation Accuracy: 0.600000\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss:     1.5874 Validation Accuracy: 0.400000\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     1.5078 Validation Accuracy: 0.475000\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss:     1.3323 Validation Accuracy: 0.500000\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss:     1.2351 Validation Accuracy: 0.525000\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss:     1.2634 Validation Accuracy: 0.600000\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss:     1.5849 Validation Accuracy: 0.400000\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     1.5102 Validation Accuracy: 0.475000\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss:     1.3303 Validation Accuracy: 0.475000\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss:     1.2327 Validation Accuracy: 0.525000\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss:     1.2632 Validation Accuracy: 0.600000\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss:     1.5828 Validation Accuracy: 0.400000\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     1.5044 Validation Accuracy: 0.475000\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss:     1.3275 Validation Accuracy: 0.475000\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss:     1.2311 Validation Accuracy: 0.525000\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss:     1.2614 Validation Accuracy: 0.600000\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss:     1.5803 Validation Accuracy: 0.400000\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     1.5019 Validation Accuracy: 0.475000\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss:     1.3244 Validation Accuracy: 0.475000\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss:     1.2298 Validation Accuracy: 0.525000\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss:     1.2606 Validation Accuracy: 0.600000\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss:     1.5773 Validation Accuracy: 0.425000\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     1.5017 Validation Accuracy: 0.475000\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss:     1.3233 Validation Accuracy: 0.475000\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss:     1.2261 Validation Accuracy: 0.525000\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss:     1.2594 Validation Accuracy: 0.600000\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss:     1.5741 Validation Accuracy: 0.425000\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     1.4993 Validation Accuracy: 0.475000\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss:     1.3211 Validation Accuracy: 0.475000\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss:     1.2239 Validation Accuracy: 0.525000\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss:     1.2582 Validation Accuracy: 0.600000\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss:     1.5716 Validation Accuracy: 0.425000\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     1.4953 Validation Accuracy: 0.475000\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss:     1.3195 Validation Accuracy: 0.475000\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss:     1.2222 Validation Accuracy: 0.525000\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss:     1.2574 Validation Accuracy: 0.625000\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss:     1.5691 Validation Accuracy: 0.425000\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     1.4936 Validation Accuracy: 0.475000\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss:     1.3173 Validation Accuracy: 0.475000\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss:     1.2194 Validation Accuracy: 0.525000\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss:     1.2560 Validation Accuracy: 0.625000\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss:     1.5671 Validation Accuracy: 0.425000\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     1.4923 Validation Accuracy: 0.475000\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss:     1.3149 Validation Accuracy: 0.475000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87, CIFAR-10 Batch 3:  Loss:     1.2166 Validation Accuracy: 0.525000\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss:     1.2552 Validation Accuracy: 0.625000\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss:     1.5649 Validation Accuracy: 0.425000\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     1.4880 Validation Accuracy: 0.500000\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss:     1.3136 Validation Accuracy: 0.450000\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss:     1.2165 Validation Accuracy: 0.525000\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss:     1.2544 Validation Accuracy: 0.625000\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss:     1.5616 Validation Accuracy: 0.425000\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     1.4831 Validation Accuracy: 0.475000\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss:     1.3097 Validation Accuracy: 0.525000\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss:     1.2132 Validation Accuracy: 0.525000\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss:     1.2536 Validation Accuracy: 0.625000\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss:     1.5566 Validation Accuracy: 0.425000\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     1.4796 Validation Accuracy: 0.525000\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss:     1.3049 Validation Accuracy: 0.525000\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss:     1.2105 Validation Accuracy: 0.525000\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss:     1.2516 Validation Accuracy: 0.625000\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss:     1.5578 Validation Accuracy: 0.400000\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     1.4786 Validation Accuracy: 0.475000\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss:     1.2998 Validation Accuracy: 0.525000\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss:     1.2043 Validation Accuracy: 0.525000\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss:     1.2483 Validation Accuracy: 0.625000\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss:     1.5529 Validation Accuracy: 0.425000\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     1.4732 Validation Accuracy: 0.475000\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss:     1.2966 Validation Accuracy: 0.550000\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss:     1.2005 Validation Accuracy: 0.525000\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss:     1.2459 Validation Accuracy: 0.625000\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss:     1.5373 Validation Accuracy: 0.425000\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     1.4751 Validation Accuracy: 0.500000\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss:     1.2924 Validation Accuracy: 0.550000\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss:     1.2026 Validation Accuracy: 0.550000\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss:     1.2408 Validation Accuracy: 0.650000\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss:     1.5250 Validation Accuracy: 0.425000\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     1.4731 Validation Accuracy: 0.475000\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss:     1.2863 Validation Accuracy: 0.525000\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss:     1.1991 Validation Accuracy: 0.550000\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss:     1.2381 Validation Accuracy: 0.650000\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss:     1.5182 Validation Accuracy: 0.425000\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     1.4715 Validation Accuracy: 0.475000\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss:     1.2815 Validation Accuracy: 0.525000\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss:     1.1963 Validation Accuracy: 0.550000\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss:     1.2353 Validation Accuracy: 0.650000\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss:     1.5120 Validation Accuracy: 0.400000\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     1.4671 Validation Accuracy: 0.475000\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss:     1.2778 Validation Accuracy: 0.525000\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss:     1.1929 Validation Accuracy: 0.550000\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss:     1.2326 Validation Accuracy: 0.650000\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss:     1.5068 Validation Accuracy: 0.425000\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     1.4612 Validation Accuracy: 0.450000\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss:     1.2751 Validation Accuracy: 0.525000\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss:     1.1906 Validation Accuracy: 0.550000\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss:     1.2301 Validation Accuracy: 0.650000\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss:     1.5004 Validation Accuracy: 0.425000\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     1.4589 Validation Accuracy: 0.450000\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss:     1.2732 Validation Accuracy: 0.525000\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss:     1.1887 Validation Accuracy: 0.550000\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss:     1.2273 Validation Accuracy: 0.650000\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss:     1.4953 Validation Accuracy: 0.425000\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     1.4539 Validation Accuracy: 0.500000\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss:     1.2685 Validation Accuracy: 0.525000\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss:     1.1833 Validation Accuracy: 0.550000\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss:     1.2235 Validation Accuracy: 0.650000\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss:     1.4897 Validation Accuracy: 0.425000\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     1.4478 Validation Accuracy: 0.525000\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss:     1.2648 Validation Accuracy: 0.525000\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss:     1.1793 Validation Accuracy: 0.550000\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss:     1.2210 Validation Accuracy: 0.650000\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss:     1.4844 Validation Accuracy: 0.425000\n",
      "Epoch 101, CIFAR-10 Batch 1:  Loss:     1.4427 Validation Accuracy: 0.525000\n",
      "Epoch 101, CIFAR-10 Batch 2:  Loss:     1.2621 Validation Accuracy: 0.525000\n",
      "Epoch 101, CIFAR-10 Batch 3:  Loss:     1.1771 Validation Accuracy: 0.575000\n",
      "Epoch 101, CIFAR-10 Batch 4:  Loss:     1.2187 Validation Accuracy: 0.625000\n",
      "Epoch 101, CIFAR-10 Batch 5:  Loss:     1.4802 Validation Accuracy: 0.425000\n",
      "Epoch 102, CIFAR-10 Batch 1:  Loss:     1.4379 Validation Accuracy: 0.525000\n",
      "Epoch 102, CIFAR-10 Batch 2:  Loss:     1.2591 Validation Accuracy: 0.525000\n",
      "Epoch 102, CIFAR-10 Batch 3:  Loss:     1.1761 Validation Accuracy: 0.575000\n",
      "Epoch 102, CIFAR-10 Batch 4:  Loss:     1.2144 Validation Accuracy: 0.625000\n",
      "Epoch 102, CIFAR-10 Batch 5:  Loss:     1.4751 Validation Accuracy: 0.425000\n",
      "Epoch 103, CIFAR-10 Batch 1:  Loss:     1.4339 Validation Accuracy: 0.500000\n",
      "Epoch 103, CIFAR-10 Batch 2:  Loss:     1.2559 Validation Accuracy: 0.525000\n",
      "Epoch 103, CIFAR-10 Batch 3:  Loss:     1.1743 Validation Accuracy: 0.575000\n",
      "Epoch 103, CIFAR-10 Batch 4:  Loss:     1.2131 Validation Accuracy: 0.625000\n",
      "Epoch 103, CIFAR-10 Batch 5:  Loss:     1.4722 Validation Accuracy: 0.400000\n",
      "Epoch 104, CIFAR-10 Batch 1:  Loss:     1.4304 Validation Accuracy: 0.500000\n",
      "Epoch 104, CIFAR-10 Batch 2:  Loss:     1.2528 Validation Accuracy: 0.525000\n",
      "Epoch 104, CIFAR-10 Batch 3:  Loss:     1.1718 Validation Accuracy: 0.575000\n",
      "Epoch 104, CIFAR-10 Batch 4:  Loss:     1.2110 Validation Accuracy: 0.625000\n",
      "Epoch 104, CIFAR-10 Batch 5:  Loss:     1.4692 Validation Accuracy: 0.400000\n",
      "Epoch 105, CIFAR-10 Batch 1:  Loss:     1.4251 Validation Accuracy: 0.525000\n",
      "Epoch 105, CIFAR-10 Batch 2:  Loss:     1.2507 Validation Accuracy: 0.525000\n",
      "Epoch 105, CIFAR-10 Batch 3:  Loss:     1.1693 Validation Accuracy: 0.575000\n",
      "Epoch 105, CIFAR-10 Batch 4:  Loss:     1.2078 Validation Accuracy: 0.625000\n",
      "Epoch 105, CIFAR-10 Batch 5:  Loss:     1.4653 Validation Accuracy: 0.400000\n",
      "Epoch 106, CIFAR-10 Batch 1:  Loss:     1.4192 Validation Accuracy: 0.525000\n",
      "Epoch 106, CIFAR-10 Batch 2:  Loss:     1.2466 Validation Accuracy: 0.525000\n",
      "Epoch 106, CIFAR-10 Batch 3:  Loss:     1.1717 Validation Accuracy: 0.575000\n",
      "Epoch 106, CIFAR-10 Batch 4:  Loss:     1.2061 Validation Accuracy: 0.625000\n",
      "Epoch 106, CIFAR-10 Batch 5:  Loss:     1.4627 Validation Accuracy: 0.400000\n",
      "Epoch 107, CIFAR-10 Batch 1:  Loss:     1.4214 Validation Accuracy: 0.500000\n",
      "Epoch 107, CIFAR-10 Batch 2:  Loss:     1.2440 Validation Accuracy: 0.525000\n",
      "Epoch 107, CIFAR-10 Batch 3:  Loss:     1.1681 Validation Accuracy: 0.575000\n",
      "Epoch 107, CIFAR-10 Batch 4:  Loss:     1.2039 Validation Accuracy: 0.625000\n",
      "Epoch 107, CIFAR-10 Batch 5:  Loss:     1.4604 Validation Accuracy: 0.400000\n",
      "Epoch 108, CIFAR-10 Batch 1:  Loss:     1.4198 Validation Accuracy: 0.500000\n",
      "Epoch 108, CIFAR-10 Batch 2:  Loss:     1.2413 Validation Accuracy: 0.525000\n",
      "Epoch 108, CIFAR-10 Batch 3:  Loss:     1.1654 Validation Accuracy: 0.575000\n",
      "Epoch 108, CIFAR-10 Batch 4:  Loss:     1.1989 Validation Accuracy: 0.625000\n",
      "Epoch 108, CIFAR-10 Batch 5:  Loss:     1.4585 Validation Accuracy: 0.425000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109, CIFAR-10 Batch 1:  Loss:     1.4190 Validation Accuracy: 0.475000\n",
      "Epoch 109, CIFAR-10 Batch 2:  Loss:     1.2384 Validation Accuracy: 0.525000\n",
      "Epoch 109, CIFAR-10 Batch 3:  Loss:     1.1647 Validation Accuracy: 0.575000\n",
      "Epoch 109, CIFAR-10 Batch 4:  Loss:     1.1971 Validation Accuracy: 0.600000\n",
      "Epoch 109, CIFAR-10 Batch 5:  Loss:     1.4563 Validation Accuracy: 0.400000\n",
      "Epoch 110, CIFAR-10 Batch 1:  Loss:     1.4161 Validation Accuracy: 0.500000\n",
      "Epoch 110, CIFAR-10 Batch 2:  Loss:     1.2349 Validation Accuracy: 0.525000\n",
      "Epoch 110, CIFAR-10 Batch 3:  Loss:     1.1629 Validation Accuracy: 0.575000\n",
      "Epoch 110, CIFAR-10 Batch 4:  Loss:     1.1957 Validation Accuracy: 0.600000\n",
      "Epoch 110, CIFAR-10 Batch 5:  Loss:     1.4542 Validation Accuracy: 0.375000\n",
      "Epoch 111, CIFAR-10 Batch 1:  Loss:     1.4144 Validation Accuracy: 0.500000\n",
      "Epoch 111, CIFAR-10 Batch 2:  Loss:     1.2314 Validation Accuracy: 0.525000\n",
      "Epoch 111, CIFAR-10 Batch 3:  Loss:     1.1624 Validation Accuracy: 0.575000\n",
      "Epoch 111, CIFAR-10 Batch 4:  Loss:     1.1938 Validation Accuracy: 0.600000\n",
      "Epoch 111, CIFAR-10 Batch 5:  Loss:     1.4534 Validation Accuracy: 0.375000\n",
      "Epoch 112, CIFAR-10 Batch 1:  Loss:     1.4126 Validation Accuracy: 0.475000\n",
      "Epoch 112, CIFAR-10 Batch 2:  Loss:     1.2278 Validation Accuracy: 0.525000\n",
      "Epoch 112, CIFAR-10 Batch 3:  Loss:     1.1607 Validation Accuracy: 0.575000\n",
      "Epoch 112, CIFAR-10 Batch 4:  Loss:     1.1914 Validation Accuracy: 0.600000\n",
      "Epoch 112, CIFAR-10 Batch 5:  Loss:     1.4509 Validation Accuracy: 0.375000\n",
      "Epoch 113, CIFAR-10 Batch 1:  Loss:     1.4111 Validation Accuracy: 0.475000\n",
      "Epoch 113, CIFAR-10 Batch 2:  Loss:     1.2235 Validation Accuracy: 0.525000\n",
      "Epoch 113, CIFAR-10 Batch 3:  Loss:     1.1601 Validation Accuracy: 0.575000\n",
      "Epoch 113, CIFAR-10 Batch 4:  Loss:     1.1891 Validation Accuracy: 0.600000\n",
      "Epoch 113, CIFAR-10 Batch 5:  Loss:     1.4495 Validation Accuracy: 0.375000\n",
      "Epoch 114, CIFAR-10 Batch 1:  Loss:     1.4094 Validation Accuracy: 0.475000\n",
      "Epoch 114, CIFAR-10 Batch 2:  Loss:     1.2199 Validation Accuracy: 0.525000\n",
      "Epoch 114, CIFAR-10 Batch 3:  Loss:     1.1614 Validation Accuracy: 0.575000\n",
      "Epoch 114, CIFAR-10 Batch 4:  Loss:     1.1867 Validation Accuracy: 0.600000\n",
      "Epoch 114, CIFAR-10 Batch 5:  Loss:     1.4479 Validation Accuracy: 0.375000\n",
      "Epoch 115, CIFAR-10 Batch 1:  Loss:     1.4077 Validation Accuracy: 0.475000\n",
      "Epoch 115, CIFAR-10 Batch 2:  Loss:     1.2171 Validation Accuracy: 0.525000\n",
      "Epoch 115, CIFAR-10 Batch 3:  Loss:     1.1594 Validation Accuracy: 0.575000\n",
      "Epoch 115, CIFAR-10 Batch 4:  Loss:     1.1845 Validation Accuracy: 0.600000\n",
      "Epoch 115, CIFAR-10 Batch 5:  Loss:     1.4475 Validation Accuracy: 0.375000\n",
      "Epoch 116, CIFAR-10 Batch 1:  Loss:     1.4078 Validation Accuracy: 0.450000\n",
      "Epoch 116, CIFAR-10 Batch 2:  Loss:     1.2144 Validation Accuracy: 0.525000\n",
      "Epoch 116, CIFAR-10 Batch 3:  Loss:     1.1563 Validation Accuracy: 0.575000\n",
      "Epoch 116, CIFAR-10 Batch 4:  Loss:     1.1818 Validation Accuracy: 0.600000\n",
      "Epoch 116, CIFAR-10 Batch 5:  Loss:     1.4459 Validation Accuracy: 0.400000\n",
      "Epoch 117, CIFAR-10 Batch 1:  Loss:     1.4063 Validation Accuracy: 0.450000\n",
      "Epoch 117, CIFAR-10 Batch 2:  Loss:     1.2125 Validation Accuracy: 0.525000\n",
      "Epoch 117, CIFAR-10 Batch 3:  Loss:     1.1541 Validation Accuracy: 0.575000\n",
      "Epoch 117, CIFAR-10 Batch 4:  Loss:     1.1776 Validation Accuracy: 0.600000\n",
      "Epoch 117, CIFAR-10 Batch 5:  Loss:     1.4436 Validation Accuracy: 0.425000\n",
      "Epoch 118, CIFAR-10 Batch 1:  Loss:     1.4040 Validation Accuracy: 0.450000\n",
      "Epoch 118, CIFAR-10 Batch 2:  Loss:     1.2106 Validation Accuracy: 0.525000\n",
      "Epoch 118, CIFAR-10 Batch 3:  Loss:     1.1527 Validation Accuracy: 0.575000\n",
      "Epoch 118, CIFAR-10 Batch 4:  Loss:     1.1749 Validation Accuracy: 0.600000\n",
      "Epoch 118, CIFAR-10 Batch 5:  Loss:     1.4421 Validation Accuracy: 0.425000\n",
      "Epoch 119, CIFAR-10 Batch 1:  Loss:     1.4017 Validation Accuracy: 0.450000\n",
      "Epoch 119, CIFAR-10 Batch 2:  Loss:     1.2081 Validation Accuracy: 0.550000\n",
      "Epoch 119, CIFAR-10 Batch 3:  Loss:     1.1519 Validation Accuracy: 0.575000\n",
      "Epoch 119, CIFAR-10 Batch 4:  Loss:     1.1728 Validation Accuracy: 0.600000\n",
      "Epoch 119, CIFAR-10 Batch 5:  Loss:     1.4379 Validation Accuracy: 0.425000\n",
      "Epoch 120, CIFAR-10 Batch 1:  Loss:     1.3997 Validation Accuracy: 0.450000\n",
      "Epoch 120, CIFAR-10 Batch 2:  Loss:     1.2047 Validation Accuracy: 0.550000\n",
      "Epoch 120, CIFAR-10 Batch 3:  Loss:     1.1521 Validation Accuracy: 0.575000\n",
      "Epoch 120, CIFAR-10 Batch 4:  Loss:     1.1710 Validation Accuracy: 0.600000\n",
      "Epoch 120, CIFAR-10 Batch 5:  Loss:     1.4379 Validation Accuracy: 0.425000\n",
      "Epoch 121, CIFAR-10 Batch 1:  Loss:     1.3979 Validation Accuracy: 0.450000\n",
      "Epoch 121, CIFAR-10 Batch 2:  Loss:     1.2032 Validation Accuracy: 0.525000\n",
      "Epoch 121, CIFAR-10 Batch 3:  Loss:     1.1519 Validation Accuracy: 0.575000\n",
      "Epoch 121, CIFAR-10 Batch 4:  Loss:     1.1686 Validation Accuracy: 0.600000\n",
      "Epoch 121, CIFAR-10 Batch 5:  Loss:     1.4368 Validation Accuracy: 0.425000\n",
      "Epoch 122, CIFAR-10 Batch 1:  Loss:     1.3968 Validation Accuracy: 0.450000\n",
      "Epoch 122, CIFAR-10 Batch 2:  Loss:     1.2001 Validation Accuracy: 0.525000\n",
      "Epoch 122, CIFAR-10 Batch 3:  Loss:     1.1509 Validation Accuracy: 0.575000\n",
      "Epoch 122, CIFAR-10 Batch 4:  Loss:     1.1672 Validation Accuracy: 0.600000\n",
      "Epoch 122, CIFAR-10 Batch 5:  Loss:     1.4359 Validation Accuracy: 0.425000\n",
      "Epoch 123, CIFAR-10 Batch 1:  Loss:     1.3948 Validation Accuracy: 0.450000\n",
      "Epoch 123, CIFAR-10 Batch 2:  Loss:     1.1971 Validation Accuracy: 0.525000\n",
      "Epoch 123, CIFAR-10 Batch 3:  Loss:     1.1504 Validation Accuracy: 0.575000\n",
      "Epoch 123, CIFAR-10 Batch 4:  Loss:     1.1656 Validation Accuracy: 0.600000\n",
      "Epoch 123, CIFAR-10 Batch 5:  Loss:     1.4352 Validation Accuracy: 0.425000\n",
      "Epoch 124, CIFAR-10 Batch 1:  Loss:     1.3944 Validation Accuracy: 0.450000\n",
      "Epoch 124, CIFAR-10 Batch 2:  Loss:     1.1941 Validation Accuracy: 0.525000\n",
      "Epoch 124, CIFAR-10 Batch 3:  Loss:     1.1482 Validation Accuracy: 0.575000\n",
      "Epoch 124, CIFAR-10 Batch 4:  Loss:     1.1639 Validation Accuracy: 0.600000\n",
      "Epoch 124, CIFAR-10 Batch 5:  Loss:     1.4349 Validation Accuracy: 0.425000\n",
      "Epoch 125, CIFAR-10 Batch 1:  Loss:     1.3924 Validation Accuracy: 0.450000\n",
      "Epoch 125, CIFAR-10 Batch 2:  Loss:     1.1924 Validation Accuracy: 0.525000\n",
      "Epoch 125, CIFAR-10 Batch 3:  Loss:     1.1470 Validation Accuracy: 0.575000\n",
      "Epoch 125, CIFAR-10 Batch 4:  Loss:     1.1628 Validation Accuracy: 0.600000\n",
      "Epoch 125, CIFAR-10 Batch 5:  Loss:     1.4352 Validation Accuracy: 0.425000\n",
      "Epoch 126, CIFAR-10 Batch 1:  Loss:     1.3907 Validation Accuracy: 0.450000\n",
      "Epoch 126, CIFAR-10 Batch 2:  Loss:     1.1901 Validation Accuracy: 0.525000\n",
      "Epoch 126, CIFAR-10 Batch 3:  Loss:     1.1460 Validation Accuracy: 0.575000\n",
      "Epoch 126, CIFAR-10 Batch 4:  Loss:     1.1619 Validation Accuracy: 0.600000\n",
      "Epoch 126, CIFAR-10 Batch 5:  Loss:     1.4329 Validation Accuracy: 0.425000\n",
      "Epoch 127, CIFAR-10 Batch 1:  Loss:     1.3894 Validation Accuracy: 0.450000\n",
      "Epoch 127, CIFAR-10 Batch 2:  Loss:     1.1880 Validation Accuracy: 0.525000\n",
      "Epoch 127, CIFAR-10 Batch 3:  Loss:     1.1445 Validation Accuracy: 0.575000\n",
      "Epoch 127, CIFAR-10 Batch 4:  Loss:     1.1611 Validation Accuracy: 0.600000\n",
      "Epoch 127, CIFAR-10 Batch 5:  Loss:     1.4322 Validation Accuracy: 0.425000\n",
      "Epoch 128, CIFAR-10 Batch 1:  Loss:     1.3883 Validation Accuracy: 0.450000\n",
      "Epoch 128, CIFAR-10 Batch 2:  Loss:     1.1859 Validation Accuracy: 0.525000\n",
      "Epoch 128, CIFAR-10 Batch 3:  Loss:     1.1426 Validation Accuracy: 0.575000\n",
      "Epoch 128, CIFAR-10 Batch 4:  Loss:     1.1605 Validation Accuracy: 0.600000\n",
      "Epoch 128, CIFAR-10 Batch 5:  Loss:     1.4310 Validation Accuracy: 0.425000\n",
      "Epoch 129, CIFAR-10 Batch 1:  Loss:     1.3868 Validation Accuracy: 0.450000\n",
      "Epoch 129, CIFAR-10 Batch 2:  Loss:     1.1831 Validation Accuracy: 0.525000\n",
      "Epoch 129, CIFAR-10 Batch 3:  Loss:     1.1411 Validation Accuracy: 0.575000\n",
      "Epoch 129, CIFAR-10 Batch 4:  Loss:     1.1600 Validation Accuracy: 0.600000\n",
      "Epoch 129, CIFAR-10 Batch 5:  Loss:     1.4287 Validation Accuracy: 0.425000\n",
      "Epoch 130, CIFAR-10 Batch 1:  Loss:     1.3866 Validation Accuracy: 0.450000\n",
      "Epoch 130, CIFAR-10 Batch 2:  Loss:     1.1821 Validation Accuracy: 0.525000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130, CIFAR-10 Batch 3:  Loss:     1.1390 Validation Accuracy: 0.600000\n",
      "Epoch 130, CIFAR-10 Batch 4:  Loss:     1.1593 Validation Accuracy: 0.600000\n",
      "Epoch 130, CIFAR-10 Batch 5:  Loss:     1.4254 Validation Accuracy: 0.425000\n",
      "Epoch 131, CIFAR-10 Batch 1:  Loss:     1.3858 Validation Accuracy: 0.450000\n",
      "Epoch 131, CIFAR-10 Batch 2:  Loss:     1.1794 Validation Accuracy: 0.525000\n",
      "Epoch 131, CIFAR-10 Batch 3:  Loss:     1.1371 Validation Accuracy: 0.600000\n",
      "Epoch 131, CIFAR-10 Batch 4:  Loss:     1.1586 Validation Accuracy: 0.600000\n",
      "Epoch 131, CIFAR-10 Batch 5:  Loss:     1.4212 Validation Accuracy: 0.375000\n",
      "Epoch 132, CIFAR-10 Batch 1:  Loss:     1.3841 Validation Accuracy: 0.450000\n",
      "Epoch 132, CIFAR-10 Batch 2:  Loss:     1.1770 Validation Accuracy: 0.525000\n",
      "Epoch 132, CIFAR-10 Batch 3:  Loss:     1.1362 Validation Accuracy: 0.575000\n",
      "Epoch 132, CIFAR-10 Batch 4:  Loss:     1.1582 Validation Accuracy: 0.600000\n",
      "Epoch 132, CIFAR-10 Batch 5:  Loss:     1.4182 Validation Accuracy: 0.375000\n",
      "Epoch 133, CIFAR-10 Batch 1:  Loss:     1.3851 Validation Accuracy: 0.475000\n",
      "Epoch 133, CIFAR-10 Batch 2:  Loss:     1.1759 Validation Accuracy: 0.525000\n",
      "Epoch 133, CIFAR-10 Batch 3:  Loss:     1.1343 Validation Accuracy: 0.575000\n",
      "Epoch 133, CIFAR-10 Batch 4:  Loss:     1.1585 Validation Accuracy: 0.600000\n",
      "Epoch 133, CIFAR-10 Batch 5:  Loss:     1.4137 Validation Accuracy: 0.375000\n",
      "Epoch 134, CIFAR-10 Batch 1:  Loss:     1.3834 Validation Accuracy: 0.475000\n",
      "Epoch 134, CIFAR-10 Batch 2:  Loss:     1.1740 Validation Accuracy: 0.525000\n",
      "Epoch 134, CIFAR-10 Batch 3:  Loss:     1.1332 Validation Accuracy: 0.575000\n",
      "Epoch 134, CIFAR-10 Batch 4:  Loss:     1.1581 Validation Accuracy: 0.600000\n",
      "Epoch 134, CIFAR-10 Batch 5:  Loss:     1.4104 Validation Accuracy: 0.400000\n",
      "Epoch 135, CIFAR-10 Batch 1:  Loss:     1.3841 Validation Accuracy: 0.475000\n",
      "Epoch 135, CIFAR-10 Batch 2:  Loss:     1.1727 Validation Accuracy: 0.550000\n",
      "Epoch 135, CIFAR-10 Batch 3:  Loss:     1.1312 Validation Accuracy: 0.575000\n",
      "Epoch 135, CIFAR-10 Batch 4:  Loss:     1.1584 Validation Accuracy: 0.625000\n",
      "Epoch 135, CIFAR-10 Batch 5:  Loss:     1.4079 Validation Accuracy: 0.400000\n",
      "Epoch 136, CIFAR-10 Batch 1:  Loss:     1.3836 Validation Accuracy: 0.475000\n",
      "Epoch 136, CIFAR-10 Batch 2:  Loss:     1.1707 Validation Accuracy: 0.550000\n",
      "Epoch 136, CIFAR-10 Batch 3:  Loss:     1.1297 Validation Accuracy: 0.575000\n",
      "Epoch 136, CIFAR-10 Batch 4:  Loss:     1.1582 Validation Accuracy: 0.625000\n",
      "Epoch 136, CIFAR-10 Batch 5:  Loss:     1.4050 Validation Accuracy: 0.400000\n",
      "Epoch 137, CIFAR-10 Batch 1:  Loss:     1.3835 Validation Accuracy: 0.475000\n",
      "Epoch 137, CIFAR-10 Batch 2:  Loss:     1.1683 Validation Accuracy: 0.550000\n",
      "Epoch 137, CIFAR-10 Batch 3:  Loss:     1.1279 Validation Accuracy: 0.575000\n",
      "Epoch 137, CIFAR-10 Batch 4:  Loss:     1.1582 Validation Accuracy: 0.625000\n",
      "Epoch 137, CIFAR-10 Batch 5:  Loss:     1.4042 Validation Accuracy: 0.425000\n",
      "Epoch 138, CIFAR-10 Batch 1:  Loss:     1.3845 Validation Accuracy: 0.475000\n",
      "Epoch 138, CIFAR-10 Batch 2:  Loss:     1.1672 Validation Accuracy: 0.550000\n",
      "Epoch 138, CIFAR-10 Batch 3:  Loss:     1.1262 Validation Accuracy: 0.575000\n",
      "Epoch 138, CIFAR-10 Batch 4:  Loss:     1.1574 Validation Accuracy: 0.625000\n",
      "Epoch 138, CIFAR-10 Batch 5:  Loss:     1.4018 Validation Accuracy: 0.425000\n",
      "Epoch 139, CIFAR-10 Batch 1:  Loss:     1.3848 Validation Accuracy: 0.475000\n",
      "Epoch 139, CIFAR-10 Batch 2:  Loss:     1.1661 Validation Accuracy: 0.550000\n",
      "Epoch 139, CIFAR-10 Batch 3:  Loss:     1.1256 Validation Accuracy: 0.575000\n",
      "Epoch 139, CIFAR-10 Batch 4:  Loss:     1.1568 Validation Accuracy: 0.600000\n",
      "Epoch 139, CIFAR-10 Batch 5:  Loss:     1.3996 Validation Accuracy: 0.425000\n",
      "Epoch 140, CIFAR-10 Batch 1:  Loss:     1.3836 Validation Accuracy: 0.475000\n",
      "Epoch 140, CIFAR-10 Batch 2:  Loss:     1.1636 Validation Accuracy: 0.550000\n",
      "Epoch 140, CIFAR-10 Batch 3:  Loss:     1.1246 Validation Accuracy: 0.550000\n",
      "Epoch 140, CIFAR-10 Batch 4:  Loss:     1.1561 Validation Accuracy: 0.600000\n",
      "Epoch 140, CIFAR-10 Batch 5:  Loss:     1.3977 Validation Accuracy: 0.425000\n",
      "Epoch 141, CIFAR-10 Batch 1:  Loss:     1.3834 Validation Accuracy: 0.475000\n",
      "Epoch 141, CIFAR-10 Batch 2:  Loss:     1.1611 Validation Accuracy: 0.550000\n",
      "Epoch 141, CIFAR-10 Batch 3:  Loss:     1.1232 Validation Accuracy: 0.550000\n",
      "Epoch 141, CIFAR-10 Batch 4:  Loss:     1.1561 Validation Accuracy: 0.600000\n",
      "Epoch 141, CIFAR-10 Batch 5:  Loss:     1.3951 Validation Accuracy: 0.400000\n",
      "Epoch 142, CIFAR-10 Batch 1:  Loss:     1.3830 Validation Accuracy: 0.475000\n",
      "Epoch 142, CIFAR-10 Batch 2:  Loss:     1.1602 Validation Accuracy: 0.550000\n",
      "Epoch 142, CIFAR-10 Batch 3:  Loss:     1.1222 Validation Accuracy: 0.550000\n",
      "Epoch 142, CIFAR-10 Batch 4:  Loss:     1.1558 Validation Accuracy: 0.600000\n",
      "Epoch 142, CIFAR-10 Batch 5:  Loss:     1.3928 Validation Accuracy: 0.425000\n",
      "Epoch 143, CIFAR-10 Batch 1:  Loss:     1.3822 Validation Accuracy: 0.475000\n",
      "Epoch 143, CIFAR-10 Batch 2:  Loss:     1.1591 Validation Accuracy: 0.550000\n",
      "Epoch 143, CIFAR-10 Batch 3:  Loss:     1.1218 Validation Accuracy: 0.550000\n",
      "Epoch 143, CIFAR-10 Batch 4:  Loss:     1.1556 Validation Accuracy: 0.600000\n",
      "Epoch 143, CIFAR-10 Batch 5:  Loss:     1.3899 Validation Accuracy: 0.450000\n",
      "Epoch 144, CIFAR-10 Batch 1:  Loss:     1.3826 Validation Accuracy: 0.475000\n",
      "Epoch 144, CIFAR-10 Batch 2:  Loss:     1.1585 Validation Accuracy: 0.550000\n",
      "Epoch 144, CIFAR-10 Batch 3:  Loss:     1.1215 Validation Accuracy: 0.575000\n",
      "Epoch 144, CIFAR-10 Batch 4:  Loss:     1.1554 Validation Accuracy: 0.600000\n",
      "Epoch 144, CIFAR-10 Batch 5:  Loss:     1.3871 Validation Accuracy: 0.450000\n",
      "Epoch 145, CIFAR-10 Batch 1:  Loss:     1.3811 Validation Accuracy: 0.475000\n",
      "Epoch 145, CIFAR-10 Batch 2:  Loss:     1.1570 Validation Accuracy: 0.550000\n",
      "Epoch 145, CIFAR-10 Batch 3:  Loss:     1.1208 Validation Accuracy: 0.575000\n",
      "Epoch 145, CIFAR-10 Batch 4:  Loss:     1.1558 Validation Accuracy: 0.600000\n",
      "Epoch 145, CIFAR-10 Batch 5:  Loss:     1.3846 Validation Accuracy: 0.450000\n",
      "Epoch 146, CIFAR-10 Batch 1:  Loss:     1.3814 Validation Accuracy: 0.475000\n",
      "Epoch 146, CIFAR-10 Batch 2:  Loss:     1.1546 Validation Accuracy: 0.525000\n",
      "Epoch 146, CIFAR-10 Batch 3:  Loss:     1.1213 Validation Accuracy: 0.575000\n",
      "Epoch 146, CIFAR-10 Batch 4:  Loss:     1.1557 Validation Accuracy: 0.600000\n",
      "Epoch 146, CIFAR-10 Batch 5:  Loss:     1.3806 Validation Accuracy: 0.450000\n",
      "Epoch 147, CIFAR-10 Batch 1:  Loss:     1.3813 Validation Accuracy: 0.475000\n",
      "Epoch 147, CIFAR-10 Batch 2:  Loss:     1.1523 Validation Accuracy: 0.525000\n",
      "Epoch 147, CIFAR-10 Batch 3:  Loss:     1.1198 Validation Accuracy: 0.575000\n",
      "Epoch 147, CIFAR-10 Batch 4:  Loss:     1.1558 Validation Accuracy: 0.600000\n",
      "Epoch 147, CIFAR-10 Batch 5:  Loss:     1.3778 Validation Accuracy: 0.450000\n",
      "Epoch 148, CIFAR-10 Batch 1:  Loss:     1.3816 Validation Accuracy: 0.500000\n",
      "Epoch 148, CIFAR-10 Batch 2:  Loss:     1.1508 Validation Accuracy: 0.525000\n",
      "Epoch 148, CIFAR-10 Batch 3:  Loss:     1.1200 Validation Accuracy: 0.575000\n",
      "Epoch 148, CIFAR-10 Batch 4:  Loss:     1.1559 Validation Accuracy: 0.600000\n",
      "Epoch 148, CIFAR-10 Batch 5:  Loss:     1.3760 Validation Accuracy: 0.450000\n",
      "Epoch 149, CIFAR-10 Batch 1:  Loss:     1.3814 Validation Accuracy: 0.500000\n",
      "Epoch 149, CIFAR-10 Batch 2:  Loss:     1.1481 Validation Accuracy: 0.525000\n",
      "Epoch 149, CIFAR-10 Batch 3:  Loss:     1.1200 Validation Accuracy: 0.575000\n",
      "Epoch 149, CIFAR-10 Batch 4:  Loss:     1.1558 Validation Accuracy: 0.575000\n",
      "Epoch 149, CIFAR-10 Batch 5:  Loss:     1.3732 Validation Accuracy: 0.450000\n",
      "Epoch 150, CIFAR-10 Batch 1:  Loss:     1.3798 Validation Accuracy: 0.500000\n",
      "Epoch 150, CIFAR-10 Batch 2:  Loss:     1.1469 Validation Accuracy: 0.525000\n",
      "Epoch 150, CIFAR-10 Batch 3:  Loss:     1.1194 Validation Accuracy: 0.575000\n",
      "Epoch 150, CIFAR-10 Batch 4:  Loss:     1.1547 Validation Accuracy: 0.575000\n",
      "Epoch 150, CIFAR-10 Batch 5:  Loss:     1.3717 Validation Accuracy: 0.450000\n",
      "Epoch 151, CIFAR-10 Batch 1:  Loss:     1.3801 Validation Accuracy: 0.500000\n",
      "Epoch 151, CIFAR-10 Batch 2:  Loss:     1.1434 Validation Accuracy: 0.525000\n",
      "Epoch 151, CIFAR-10 Batch 3:  Loss:     1.1197 Validation Accuracy: 0.575000\n",
      "Epoch 151, CIFAR-10 Batch 4:  Loss:     1.1548 Validation Accuracy: 0.575000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151, CIFAR-10 Batch 5:  Loss:     1.3708 Validation Accuracy: 0.450000\n",
      "Epoch 152, CIFAR-10 Batch 1:  Loss:     1.3805 Validation Accuracy: 0.500000\n",
      "Epoch 152, CIFAR-10 Batch 2:  Loss:     1.1422 Validation Accuracy: 0.525000\n",
      "Epoch 152, CIFAR-10 Batch 3:  Loss:     1.1190 Validation Accuracy: 0.575000\n",
      "Epoch 152, CIFAR-10 Batch 4:  Loss:     1.1547 Validation Accuracy: 0.575000\n",
      "Epoch 152, CIFAR-10 Batch 5:  Loss:     1.3692 Validation Accuracy: 0.450000\n",
      "Epoch 153, CIFAR-10 Batch 1:  Loss:     1.3810 Validation Accuracy: 0.500000\n",
      "Epoch 153, CIFAR-10 Batch 2:  Loss:     1.1412 Validation Accuracy: 0.525000\n",
      "Epoch 153, CIFAR-10 Batch 3:  Loss:     1.1182 Validation Accuracy: 0.575000\n",
      "Epoch 153, CIFAR-10 Batch 4:  Loss:     1.1541 Validation Accuracy: 0.575000\n",
      "Epoch 153, CIFAR-10 Batch 5:  Loss:     1.3682 Validation Accuracy: 0.450000\n",
      "Epoch 154, CIFAR-10 Batch 1:  Loss:     1.3801 Validation Accuracy: 0.500000\n",
      "Epoch 154, CIFAR-10 Batch 2:  Loss:     1.1406 Validation Accuracy: 0.525000\n",
      "Epoch 154, CIFAR-10 Batch 3:  Loss:     1.1174 Validation Accuracy: 0.575000\n",
      "Epoch 154, CIFAR-10 Batch 4:  Loss:     1.1537 Validation Accuracy: 0.575000\n",
      "Epoch 154, CIFAR-10 Batch 5:  Loss:     1.3657 Validation Accuracy: 0.450000\n",
      "Epoch 155, CIFAR-10 Batch 1:  Loss:     1.3810 Validation Accuracy: 0.500000\n",
      "Epoch 155, CIFAR-10 Batch 2:  Loss:     1.1388 Validation Accuracy: 0.525000\n",
      "Epoch 155, CIFAR-10 Batch 3:  Loss:     1.1175 Validation Accuracy: 0.575000\n",
      "Epoch 155, CIFAR-10 Batch 4:  Loss:     1.1532 Validation Accuracy: 0.575000\n",
      "Epoch 155, CIFAR-10 Batch 5:  Loss:     1.3649 Validation Accuracy: 0.450000\n",
      "Epoch 156, CIFAR-10 Batch 1:  Loss:     1.3799 Validation Accuracy: 0.500000\n",
      "Epoch 156, CIFAR-10 Batch 2:  Loss:     1.1367 Validation Accuracy: 0.525000\n",
      "Epoch 156, CIFAR-10 Batch 3:  Loss:     1.1170 Validation Accuracy: 0.575000\n",
      "Epoch 156, CIFAR-10 Batch 4:  Loss:     1.1525 Validation Accuracy: 0.575000\n",
      "Epoch 156, CIFAR-10 Batch 5:  Loss:     1.3627 Validation Accuracy: 0.450000\n",
      "Epoch 157, CIFAR-10 Batch 1:  Loss:     1.3813 Validation Accuracy: 0.500000\n",
      "Epoch 157, CIFAR-10 Batch 2:  Loss:     1.1354 Validation Accuracy: 0.525000\n",
      "Epoch 157, CIFAR-10 Batch 3:  Loss:     1.1162 Validation Accuracy: 0.575000\n",
      "Epoch 157, CIFAR-10 Batch 4:  Loss:     1.1519 Validation Accuracy: 0.575000\n",
      "Epoch 157, CIFAR-10 Batch 5:  Loss:     1.3615 Validation Accuracy: 0.450000\n",
      "Epoch 158, CIFAR-10 Batch 1:  Loss:     1.3815 Validation Accuracy: 0.500000\n",
      "Epoch 158, CIFAR-10 Batch 2:  Loss:     1.1332 Validation Accuracy: 0.525000\n",
      "Epoch 158, CIFAR-10 Batch 3:  Loss:     1.1159 Validation Accuracy: 0.575000\n",
      "Epoch 158, CIFAR-10 Batch 4:  Loss:     1.1515 Validation Accuracy: 0.550000\n",
      "Epoch 158, CIFAR-10 Batch 5:  Loss:     1.3589 Validation Accuracy: 0.450000\n",
      "Epoch 159, CIFAR-10 Batch 1:  Loss:     1.3830 Validation Accuracy: 0.500000\n",
      "Epoch 159, CIFAR-10 Batch 2:  Loss:     1.1325 Validation Accuracy: 0.550000\n",
      "Epoch 159, CIFAR-10 Batch 3:  Loss:     1.1155 Validation Accuracy: 0.575000\n",
      "Epoch 159, CIFAR-10 Batch 4:  Loss:     1.1507 Validation Accuracy: 0.550000\n",
      "Epoch 159, CIFAR-10 Batch 5:  Loss:     1.3580 Validation Accuracy: 0.450000\n",
      "Epoch 160, CIFAR-10 Batch 1:  Loss:     1.3822 Validation Accuracy: 0.500000\n",
      "Epoch 160, CIFAR-10 Batch 2:  Loss:     1.1306 Validation Accuracy: 0.550000\n",
      "Epoch 160, CIFAR-10 Batch 3:  Loss:     1.1152 Validation Accuracy: 0.575000\n",
      "Epoch 160, CIFAR-10 Batch 4:  Loss:     1.1493 Validation Accuracy: 0.550000\n",
      "Epoch 160, CIFAR-10 Batch 5:  Loss:     1.3573 Validation Accuracy: 0.450000\n",
      "Epoch 161, CIFAR-10 Batch 1:  Loss:     1.3812 Validation Accuracy: 0.500000\n",
      "Epoch 161, CIFAR-10 Batch 2:  Loss:     1.1284 Validation Accuracy: 0.550000\n",
      "Epoch 161, CIFAR-10 Batch 3:  Loss:     1.1152 Validation Accuracy: 0.575000\n",
      "Epoch 161, CIFAR-10 Batch 4:  Loss:     1.1489 Validation Accuracy: 0.550000\n",
      "Epoch 161, CIFAR-10 Batch 5:  Loss:     1.3569 Validation Accuracy: 0.475000\n",
      "Epoch 162, CIFAR-10 Batch 1:  Loss:     1.3818 Validation Accuracy: 0.500000\n",
      "Epoch 162, CIFAR-10 Batch 2:  Loss:     1.1267 Validation Accuracy: 0.525000\n",
      "Epoch 162, CIFAR-10 Batch 3:  Loss:     1.1148 Validation Accuracy: 0.575000\n",
      "Epoch 162, CIFAR-10 Batch 4:  Loss:     1.1479 Validation Accuracy: 0.550000\n",
      "Epoch 162, CIFAR-10 Batch 5:  Loss:     1.3573 Validation Accuracy: 0.475000\n",
      "Epoch 163, CIFAR-10 Batch 1:  Loss:     1.3803 Validation Accuracy: 0.500000\n",
      "Epoch 163, CIFAR-10 Batch 2:  Loss:     1.1257 Validation Accuracy: 0.525000\n",
      "Epoch 163, CIFAR-10 Batch 3:  Loss:     1.1131 Validation Accuracy: 0.575000\n",
      "Epoch 163, CIFAR-10 Batch 4:  Loss:     1.1476 Validation Accuracy: 0.550000\n",
      "Epoch 163, CIFAR-10 Batch 5:  Loss:     1.3571 Validation Accuracy: 0.475000\n",
      "Epoch 164, CIFAR-10 Batch 1:  Loss:     1.3817 Validation Accuracy: 0.500000\n",
      "Epoch 164, CIFAR-10 Batch 2:  Loss:     1.1250 Validation Accuracy: 0.525000\n",
      "Epoch 164, CIFAR-10 Batch 3:  Loss:     1.1110 Validation Accuracy: 0.600000\n",
      "Epoch 164, CIFAR-10 Batch 4:  Loss:     1.1467 Validation Accuracy: 0.550000\n",
      "Epoch 164, CIFAR-10 Batch 5:  Loss:     1.3572 Validation Accuracy: 0.475000\n",
      "Epoch 165, CIFAR-10 Batch 1:  Loss:     1.3812 Validation Accuracy: 0.500000\n",
      "Epoch 165, CIFAR-10 Batch 2:  Loss:     1.1238 Validation Accuracy: 0.525000\n",
      "Epoch 165, CIFAR-10 Batch 3:  Loss:     1.1106 Validation Accuracy: 0.600000\n",
      "Epoch 165, CIFAR-10 Batch 4:  Loss:     1.1462 Validation Accuracy: 0.550000\n",
      "Epoch 165, CIFAR-10 Batch 5:  Loss:     1.3570 Validation Accuracy: 0.475000\n",
      "Epoch 166, CIFAR-10 Batch 1:  Loss:     1.3817 Validation Accuracy: 0.500000\n",
      "Epoch 166, CIFAR-10 Batch 2:  Loss:     1.1237 Validation Accuracy: 0.525000\n",
      "Epoch 166, CIFAR-10 Batch 3:  Loss:     1.1094 Validation Accuracy: 0.600000\n",
      "Epoch 166, CIFAR-10 Batch 4:  Loss:     1.1459 Validation Accuracy: 0.550000\n",
      "Epoch 166, CIFAR-10 Batch 5:  Loss:     1.3566 Validation Accuracy: 0.475000\n",
      "Epoch 167, CIFAR-10 Batch 1:  Loss:     1.3808 Validation Accuracy: 0.500000\n",
      "Epoch 167, CIFAR-10 Batch 2:  Loss:     1.1217 Validation Accuracy: 0.525000\n",
      "Epoch 167, CIFAR-10 Batch 3:  Loss:     1.1086 Validation Accuracy: 0.600000\n",
      "Epoch 167, CIFAR-10 Batch 4:  Loss:     1.1453 Validation Accuracy: 0.550000\n",
      "Epoch 167, CIFAR-10 Batch 5:  Loss:     1.3563 Validation Accuracy: 0.475000\n",
      "Epoch 168, CIFAR-10 Batch 1:  Loss:     1.3810 Validation Accuracy: 0.500000\n",
      "Epoch 168, CIFAR-10 Batch 2:  Loss:     1.1205 Validation Accuracy: 0.525000\n",
      "Epoch 168, CIFAR-10 Batch 3:  Loss:     1.1090 Validation Accuracy: 0.600000\n",
      "Epoch 168, CIFAR-10 Batch 4:  Loss:     1.1448 Validation Accuracy: 0.550000\n",
      "Epoch 168, CIFAR-10 Batch 5:  Loss:     1.3553 Validation Accuracy: 0.475000\n",
      "Epoch 169, CIFAR-10 Batch 1:  Loss:     1.3807 Validation Accuracy: 0.500000\n",
      "Epoch 169, CIFAR-10 Batch 2:  Loss:     1.1191 Validation Accuracy: 0.525000\n",
      "Epoch 169, CIFAR-10 Batch 3:  Loss:     1.1083 Validation Accuracy: 0.600000\n",
      "Epoch 169, CIFAR-10 Batch 4:  Loss:     1.1451 Validation Accuracy: 0.550000\n",
      "Epoch 169, CIFAR-10 Batch 5:  Loss:     1.3529 Validation Accuracy: 0.475000\n",
      "Epoch 170, CIFAR-10 Batch 1:  Loss:     1.3800 Validation Accuracy: 0.500000\n",
      "Epoch 170, CIFAR-10 Batch 2:  Loss:     1.1176 Validation Accuracy: 0.525000\n",
      "Epoch 170, CIFAR-10 Batch 3:  Loss:     1.1080 Validation Accuracy: 0.600000\n",
      "Epoch 170, CIFAR-10 Batch 4:  Loss:     1.1458 Validation Accuracy: 0.550000\n",
      "Epoch 170, CIFAR-10 Batch 5:  Loss:     1.3512 Validation Accuracy: 0.475000\n",
      "Epoch 171, CIFAR-10 Batch 1:  Loss:     1.3791 Validation Accuracy: 0.500000\n",
      "Epoch 171, CIFAR-10 Batch 2:  Loss:     1.1170 Validation Accuracy: 0.525000\n",
      "Epoch 171, CIFAR-10 Batch 3:  Loss:     1.1071 Validation Accuracy: 0.600000\n",
      "Epoch 171, CIFAR-10 Batch 4:  Loss:     1.1456 Validation Accuracy: 0.550000\n",
      "Epoch 171, CIFAR-10 Batch 5:  Loss:     1.3503 Validation Accuracy: 0.475000\n",
      "Epoch 172, CIFAR-10 Batch 1:  Loss:     1.3779 Validation Accuracy: 0.500000\n",
      "Epoch 172, CIFAR-10 Batch 2:  Loss:     1.1160 Validation Accuracy: 0.525000\n",
      "Epoch 172, CIFAR-10 Batch 3:  Loss:     1.1081 Validation Accuracy: 0.600000\n",
      "Epoch 172, CIFAR-10 Batch 4:  Loss:     1.1465 Validation Accuracy: 0.550000\n",
      "Epoch 172, CIFAR-10 Batch 5:  Loss:     1.3485 Validation Accuracy: 0.475000\n",
      "Epoch 173, CIFAR-10 Batch 1:  Loss:     1.3770 Validation Accuracy: 0.500000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173, CIFAR-10 Batch 2:  Loss:     1.1152 Validation Accuracy: 0.525000\n",
      "Epoch 173, CIFAR-10 Batch 3:  Loss:     1.1073 Validation Accuracy: 0.600000\n",
      "Epoch 173, CIFAR-10 Batch 4:  Loss:     1.1453 Validation Accuracy: 0.550000\n",
      "Epoch 173, CIFAR-10 Batch 5:  Loss:     1.3479 Validation Accuracy: 0.475000\n",
      "Epoch 174, CIFAR-10 Batch 1:  Loss:     1.3775 Validation Accuracy: 0.525000\n",
      "Epoch 174, CIFAR-10 Batch 2:  Loss:     1.1144 Validation Accuracy: 0.525000\n",
      "Epoch 174, CIFAR-10 Batch 3:  Loss:     1.1069 Validation Accuracy: 0.600000\n",
      "Epoch 174, CIFAR-10 Batch 4:  Loss:     1.1450 Validation Accuracy: 0.550000\n",
      "Epoch 174, CIFAR-10 Batch 5:  Loss:     1.3466 Validation Accuracy: 0.475000\n",
      "Epoch 175, CIFAR-10 Batch 1:  Loss:     1.3769 Validation Accuracy: 0.525000\n",
      "Epoch 175, CIFAR-10 Batch 2:  Loss:     1.1129 Validation Accuracy: 0.525000\n",
      "Epoch 175, CIFAR-10 Batch 3:  Loss:     1.1059 Validation Accuracy: 0.600000\n",
      "Epoch 175, CIFAR-10 Batch 4:  Loss:     1.1440 Validation Accuracy: 0.550000\n",
      "Epoch 175, CIFAR-10 Batch 5:  Loss:     1.3454 Validation Accuracy: 0.500000\n",
      "Epoch 176, CIFAR-10 Batch 1:  Loss:     1.3758 Validation Accuracy: 0.525000\n",
      "Epoch 176, CIFAR-10 Batch 2:  Loss:     1.1123 Validation Accuracy: 0.525000\n",
      "Epoch 176, CIFAR-10 Batch 3:  Loss:     1.1056 Validation Accuracy: 0.600000\n",
      "Epoch 176, CIFAR-10 Batch 4:  Loss:     1.1431 Validation Accuracy: 0.550000\n",
      "Epoch 176, CIFAR-10 Batch 5:  Loss:     1.3445 Validation Accuracy: 0.500000\n",
      "Epoch 177, CIFAR-10 Batch 1:  Loss:     1.3760 Validation Accuracy: 0.525000\n",
      "Epoch 177, CIFAR-10 Batch 2:  Loss:     1.1120 Validation Accuracy: 0.525000\n",
      "Epoch 177, CIFAR-10 Batch 3:  Loss:     1.1052 Validation Accuracy: 0.600000\n",
      "Epoch 177, CIFAR-10 Batch 4:  Loss:     1.1424 Validation Accuracy: 0.550000\n",
      "Epoch 177, CIFAR-10 Batch 5:  Loss:     1.3429 Validation Accuracy: 0.500000\n",
      "Epoch 178, CIFAR-10 Batch 1:  Loss:     1.3744 Validation Accuracy: 0.525000\n",
      "Epoch 178, CIFAR-10 Batch 2:  Loss:     1.1104 Validation Accuracy: 0.525000\n",
      "Epoch 178, CIFAR-10 Batch 3:  Loss:     1.1050 Validation Accuracy: 0.600000\n",
      "Epoch 178, CIFAR-10 Batch 4:  Loss:     1.1400 Validation Accuracy: 0.550000\n",
      "Epoch 178, CIFAR-10 Batch 5:  Loss:     1.3421 Validation Accuracy: 0.500000\n",
      "Epoch 179, CIFAR-10 Batch 1:  Loss:     1.3730 Validation Accuracy: 0.525000\n",
      "Epoch 179, CIFAR-10 Batch 2:  Loss:     1.1099 Validation Accuracy: 0.550000\n",
      "Epoch 179, CIFAR-10 Batch 3:  Loss:     1.1044 Validation Accuracy: 0.600000\n",
      "Epoch 179, CIFAR-10 Batch 4:  Loss:     1.1379 Validation Accuracy: 0.550000\n",
      "Epoch 179, CIFAR-10 Batch 5:  Loss:     1.3409 Validation Accuracy: 0.500000\n",
      "Epoch 180, CIFAR-10 Batch 1:  Loss:     1.3725 Validation Accuracy: 0.525000\n",
      "Epoch 180, CIFAR-10 Batch 2:  Loss:     1.1086 Validation Accuracy: 0.550000\n",
      "Epoch 180, CIFAR-10 Batch 3:  Loss:     1.1036 Validation Accuracy: 0.600000\n",
      "Epoch 180, CIFAR-10 Batch 4:  Loss:     1.1376 Validation Accuracy: 0.550000\n",
      "Epoch 180, CIFAR-10 Batch 5:  Loss:     1.3396 Validation Accuracy: 0.500000\n",
      "Epoch 181, CIFAR-10 Batch 1:  Loss:     1.3708 Validation Accuracy: 0.525000\n",
      "Epoch 181, CIFAR-10 Batch 2:  Loss:     1.1073 Validation Accuracy: 0.550000\n",
      "Epoch 181, CIFAR-10 Batch 3:  Loss:     1.1029 Validation Accuracy: 0.600000\n",
      "Epoch 181, CIFAR-10 Batch 4:  Loss:     1.1367 Validation Accuracy: 0.550000\n",
      "Epoch 181, CIFAR-10 Batch 5:  Loss:     1.3394 Validation Accuracy: 0.500000\n",
      "Epoch 182, CIFAR-10 Batch 1:  Loss:     1.3696 Validation Accuracy: 0.525000\n",
      "Epoch 182, CIFAR-10 Batch 2:  Loss:     1.1057 Validation Accuracy: 0.550000\n",
      "Epoch 182, CIFAR-10 Batch 3:  Loss:     1.1023 Validation Accuracy: 0.600000\n",
      "Epoch 182, CIFAR-10 Batch 4:  Loss:     1.1372 Validation Accuracy: 0.550000\n",
      "Epoch 182, CIFAR-10 Batch 5:  Loss:     1.3380 Validation Accuracy: 0.500000\n",
      "Epoch 183, CIFAR-10 Batch 1:  Loss:     1.3685 Validation Accuracy: 0.525000\n",
      "Epoch 183, CIFAR-10 Batch 2:  Loss:     1.1039 Validation Accuracy: 0.550000\n",
      "Epoch 183, CIFAR-10 Batch 3:  Loss:     1.1018 Validation Accuracy: 0.600000\n",
      "Epoch 183, CIFAR-10 Batch 4:  Loss:     1.1370 Validation Accuracy: 0.550000\n",
      "Epoch 183, CIFAR-10 Batch 5:  Loss:     1.3362 Validation Accuracy: 0.500000\n",
      "Epoch 184, CIFAR-10 Batch 1:  Loss:     1.3671 Validation Accuracy: 0.525000\n",
      "Epoch 184, CIFAR-10 Batch 2:  Loss:     1.1033 Validation Accuracy: 0.550000\n",
      "Epoch 184, CIFAR-10 Batch 3:  Loss:     1.1009 Validation Accuracy: 0.600000\n",
      "Epoch 184, CIFAR-10 Batch 4:  Loss:     1.1371 Validation Accuracy: 0.550000\n",
      "Epoch 184, CIFAR-10 Batch 5:  Loss:     1.3343 Validation Accuracy: 0.500000\n",
      "Epoch 185, CIFAR-10 Batch 1:  Loss:     1.3670 Validation Accuracy: 0.525000\n",
      "Epoch 185, CIFAR-10 Batch 2:  Loss:     1.1018 Validation Accuracy: 0.550000\n",
      "Epoch 185, CIFAR-10 Batch 3:  Loss:     1.1003 Validation Accuracy: 0.600000\n",
      "Epoch 185, CIFAR-10 Batch 4:  Loss:     1.1363 Validation Accuracy: 0.550000\n",
      "Epoch 185, CIFAR-10 Batch 5:  Loss:     1.3325 Validation Accuracy: 0.500000\n",
      "Epoch 186, CIFAR-10 Batch 1:  Loss:     1.3667 Validation Accuracy: 0.525000\n",
      "Epoch 186, CIFAR-10 Batch 2:  Loss:     1.0998 Validation Accuracy: 0.550000\n",
      "Epoch 186, CIFAR-10 Batch 3:  Loss:     1.0996 Validation Accuracy: 0.600000\n",
      "Epoch 186, CIFAR-10 Batch 4:  Loss:     1.1357 Validation Accuracy: 0.550000\n",
      "Epoch 186, CIFAR-10 Batch 5:  Loss:     1.3308 Validation Accuracy: 0.500000\n",
      "Epoch 187, CIFAR-10 Batch 1:  Loss:     1.3678 Validation Accuracy: 0.525000\n",
      "Epoch 187, CIFAR-10 Batch 2:  Loss:     1.0985 Validation Accuracy: 0.550000\n",
      "Epoch 187, CIFAR-10 Batch 3:  Loss:     1.0993 Validation Accuracy: 0.600000\n",
      "Epoch 187, CIFAR-10 Batch 4:  Loss:     1.1363 Validation Accuracy: 0.550000\n",
      "Epoch 187, CIFAR-10 Batch 5:  Loss:     1.3295 Validation Accuracy: 0.500000\n",
      "Epoch 188, CIFAR-10 Batch 1:  Loss:     1.3677 Validation Accuracy: 0.525000\n",
      "Epoch 188, CIFAR-10 Batch 2:  Loss:     1.0960 Validation Accuracy: 0.550000\n",
      "Epoch 188, CIFAR-10 Batch 3:  Loss:     1.0976 Validation Accuracy: 0.575000\n",
      "Epoch 188, CIFAR-10 Batch 4:  Loss:     1.1347 Validation Accuracy: 0.550000\n",
      "Epoch 188, CIFAR-10 Batch 5:  Loss:     1.3273 Validation Accuracy: 0.500000\n",
      "Epoch 189, CIFAR-10 Batch 1:  Loss:     1.3682 Validation Accuracy: 0.525000\n",
      "Epoch 189, CIFAR-10 Batch 2:  Loss:     1.0946 Validation Accuracy: 0.550000\n",
      "Epoch 189, CIFAR-10 Batch 3:  Loss:     1.0973 Validation Accuracy: 0.575000\n",
      "Epoch 189, CIFAR-10 Batch 4:  Loss:     1.1353 Validation Accuracy: 0.550000\n",
      "Epoch 189, CIFAR-10 Batch 5:  Loss:     1.3261 Validation Accuracy: 0.500000\n",
      "Epoch 190, CIFAR-10 Batch 1:  Loss:     1.3673 Validation Accuracy: 0.525000\n",
      "Epoch 190, CIFAR-10 Batch 2:  Loss:     1.0940 Validation Accuracy: 0.550000\n",
      "Epoch 190, CIFAR-10 Batch 3:  Loss:     1.0969 Validation Accuracy: 0.575000\n",
      "Epoch 190, CIFAR-10 Batch 4:  Loss:     1.1356 Validation Accuracy: 0.550000\n",
      "Epoch 190, CIFAR-10 Batch 5:  Loss:     1.3248 Validation Accuracy: 0.500000\n",
      "Epoch 191, CIFAR-10 Batch 1:  Loss:     1.3670 Validation Accuracy: 0.525000\n",
      "Epoch 191, CIFAR-10 Batch 2:  Loss:     1.0935 Validation Accuracy: 0.550000\n",
      "Epoch 191, CIFAR-10 Batch 3:  Loss:     1.0964 Validation Accuracy: 0.575000\n",
      "Epoch 191, CIFAR-10 Batch 4:  Loss:     1.1356 Validation Accuracy: 0.550000\n",
      "Epoch 191, CIFAR-10 Batch 5:  Loss:     1.3237 Validation Accuracy: 0.500000\n",
      "Epoch 192, CIFAR-10 Batch 1:  Loss:     1.3662 Validation Accuracy: 0.525000\n",
      "Epoch 192, CIFAR-10 Batch 2:  Loss:     1.0924 Validation Accuracy: 0.550000\n",
      "Epoch 192, CIFAR-10 Batch 3:  Loss:     1.0959 Validation Accuracy: 0.575000\n",
      "Epoch 192, CIFAR-10 Batch 4:  Loss:     1.1353 Validation Accuracy: 0.550000\n",
      "Epoch 192, CIFAR-10 Batch 5:  Loss:     1.3229 Validation Accuracy: 0.500000\n",
      "Epoch 193, CIFAR-10 Batch 1:  Loss:     1.3667 Validation Accuracy: 0.525000\n",
      "Epoch 193, CIFAR-10 Batch 2:  Loss:     1.0908 Validation Accuracy: 0.550000\n",
      "Epoch 193, CIFAR-10 Batch 3:  Loss:     1.0954 Validation Accuracy: 0.575000\n",
      "Epoch 193, CIFAR-10 Batch 4:  Loss:     1.1352 Validation Accuracy: 0.550000\n",
      "Epoch 193, CIFAR-10 Batch 5:  Loss:     1.3224 Validation Accuracy: 0.500000\n",
      "Epoch 194, CIFAR-10 Batch 1:  Loss:     1.3651 Validation Accuracy: 0.525000\n",
      "Epoch 194, CIFAR-10 Batch 2:  Loss:     1.0902 Validation Accuracy: 0.550000\n",
      "Epoch 194, CIFAR-10 Batch 3:  Loss:     1.0945 Validation Accuracy: 0.575000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194, CIFAR-10 Batch 4:  Loss:     1.1356 Validation Accuracy: 0.550000\n",
      "Epoch 194, CIFAR-10 Batch 5:  Loss:     1.3219 Validation Accuracy: 0.500000\n",
      "Epoch 195, CIFAR-10 Batch 1:  Loss:     1.3651 Validation Accuracy: 0.525000\n",
      "Epoch 195, CIFAR-10 Batch 2:  Loss:     1.0903 Validation Accuracy: 0.550000\n",
      "Epoch 195, CIFAR-10 Batch 3:  Loss:     1.0934 Validation Accuracy: 0.575000\n",
      "Epoch 195, CIFAR-10 Batch 4:  Loss:     1.1357 Validation Accuracy: 0.550000\n",
      "Epoch 195, CIFAR-10 Batch 5:  Loss:     1.3209 Validation Accuracy: 0.500000\n",
      "Epoch 196, CIFAR-10 Batch 1:  Loss:     1.3646 Validation Accuracy: 0.525000\n",
      "Epoch 196, CIFAR-10 Batch 2:  Loss:     1.0888 Validation Accuracy: 0.550000\n",
      "Epoch 196, CIFAR-10 Batch 3:  Loss:     1.0933 Validation Accuracy: 0.575000\n",
      "Epoch 196, CIFAR-10 Batch 4:  Loss:     1.1361 Validation Accuracy: 0.550000\n",
      "Epoch 196, CIFAR-10 Batch 5:  Loss:     1.3204 Validation Accuracy: 0.500000\n",
      "Epoch 197, CIFAR-10 Batch 1:  Loss:     1.3673 Validation Accuracy: 0.525000\n",
      "Epoch 197, CIFAR-10 Batch 2:  Loss:     1.0880 Validation Accuracy: 0.550000\n",
      "Epoch 197, CIFAR-10 Batch 3:  Loss:     1.0919 Validation Accuracy: 0.575000\n",
      "Epoch 197, CIFAR-10 Batch 4:  Loss:     1.1354 Validation Accuracy: 0.550000\n",
      "Epoch 197, CIFAR-10 Batch 5:  Loss:     1.3184 Validation Accuracy: 0.500000\n",
      "Epoch 198, CIFAR-10 Batch 1:  Loss:     1.3677 Validation Accuracy: 0.525000\n",
      "Epoch 198, CIFAR-10 Batch 2:  Loss:     1.0876 Validation Accuracy: 0.550000\n",
      "Epoch 198, CIFAR-10 Batch 3:  Loss:     1.0918 Validation Accuracy: 0.575000\n",
      "Epoch 198, CIFAR-10 Batch 4:  Loss:     1.1350 Validation Accuracy: 0.550000\n",
      "Epoch 198, CIFAR-10 Batch 5:  Loss:     1.3173 Validation Accuracy: 0.500000\n",
      "Epoch 199, CIFAR-10 Batch 1:  Loss:     1.3666 Validation Accuracy: 0.525000\n",
      "Epoch 199, CIFAR-10 Batch 2:  Loss:     1.0861 Validation Accuracy: 0.550000\n",
      "Epoch 199, CIFAR-10 Batch 3:  Loss:     1.0909 Validation Accuracy: 0.575000\n",
      "Epoch 199, CIFAR-10 Batch 4:  Loss:     1.1346 Validation Accuracy: 0.550000\n",
      "Epoch 199, CIFAR-10 Batch 5:  Loss:     1.3151 Validation Accuracy: 0.500000\n",
      "Epoch 200, CIFAR-10 Batch 1:  Loss:     1.3671 Validation Accuracy: 0.525000\n",
      "Epoch 200, CIFAR-10 Batch 2:  Loss:     1.0855 Validation Accuracy: 0.550000\n",
      "Epoch 200, CIFAR-10 Batch 3:  Loss:     1.0901 Validation Accuracy: 0.575000\n",
      "Epoch 200, CIFAR-10 Batch 4:  Loss:     1.1347 Validation Accuracy: 0.550000\n",
      "Epoch 200, CIFAR-10 Batch 5:  Loss:     1.3142 Validation Accuracy: 0.500000\n",
      "Epoch 201, CIFAR-10 Batch 1:  Loss:     1.3675 Validation Accuracy: 0.525000\n",
      "Epoch 201, CIFAR-10 Batch 2:  Loss:     1.0846 Validation Accuracy: 0.550000\n",
      "Epoch 201, CIFAR-10 Batch 3:  Loss:     1.0902 Validation Accuracy: 0.575000\n",
      "Epoch 201, CIFAR-10 Batch 4:  Loss:     1.1360 Validation Accuracy: 0.550000\n",
      "Epoch 201, CIFAR-10 Batch 5:  Loss:     1.3126 Validation Accuracy: 0.500000\n",
      "Epoch 202, CIFAR-10 Batch 1:  Loss:     1.3671 Validation Accuracy: 0.525000\n",
      "Epoch 202, CIFAR-10 Batch 2:  Loss:     1.0826 Validation Accuracy: 0.550000\n",
      "Epoch 202, CIFAR-10 Batch 3:  Loss:     1.0899 Validation Accuracy: 0.575000\n",
      "Epoch 202, CIFAR-10 Batch 4:  Loss:     1.1349 Validation Accuracy: 0.550000\n",
      "Epoch 202, CIFAR-10 Batch 5:  Loss:     1.3110 Validation Accuracy: 0.500000\n",
      "Epoch 203, CIFAR-10 Batch 1:  Loss:     1.3674 Validation Accuracy: 0.525000\n",
      "Epoch 203, CIFAR-10 Batch 2:  Loss:     1.0817 Validation Accuracy: 0.550000\n",
      "Epoch 203, CIFAR-10 Batch 3:  Loss:     1.0891 Validation Accuracy: 0.575000\n",
      "Epoch 203, CIFAR-10 Batch 4:  Loss:     1.1340 Validation Accuracy: 0.550000\n",
      "Epoch 203, CIFAR-10 Batch 5:  Loss:     1.3090 Validation Accuracy: 0.500000\n",
      "Epoch 204, CIFAR-10 Batch 1:  Loss:     1.3668 Validation Accuracy: 0.525000\n",
      "Epoch 204, CIFAR-10 Batch 2:  Loss:     1.0805 Validation Accuracy: 0.550000\n",
      "Epoch 204, CIFAR-10 Batch 3:  Loss:     1.0892 Validation Accuracy: 0.575000\n",
      "Epoch 204, CIFAR-10 Batch 4:  Loss:     1.1339 Validation Accuracy: 0.550000\n",
      "Epoch 204, CIFAR-10 Batch 5:  Loss:     1.3078 Validation Accuracy: 0.500000\n",
      "Epoch 205, CIFAR-10 Batch 1:  Loss:     1.3669 Validation Accuracy: 0.525000\n",
      "Epoch 205, CIFAR-10 Batch 2:  Loss:     1.0789 Validation Accuracy: 0.550000\n",
      "Epoch 205, CIFAR-10 Batch 3:  Loss:     1.0891 Validation Accuracy: 0.575000\n",
      "Epoch 205, CIFAR-10 Batch 4:  Loss:     1.1337 Validation Accuracy: 0.550000\n",
      "Epoch 205, CIFAR-10 Batch 5:  Loss:     1.3071 Validation Accuracy: 0.500000\n",
      "Epoch 206, CIFAR-10 Batch 1:  Loss:     1.3669 Validation Accuracy: 0.525000\n",
      "Epoch 206, CIFAR-10 Batch 2:  Loss:     1.0782 Validation Accuracy: 0.550000\n",
      "Epoch 206, CIFAR-10 Batch 3:  Loss:     1.0875 Validation Accuracy: 0.575000\n",
      "Epoch 206, CIFAR-10 Batch 4:  Loss:     1.1335 Validation Accuracy: 0.550000\n",
      "Epoch 206, CIFAR-10 Batch 5:  Loss:     1.3057 Validation Accuracy: 0.500000\n",
      "Epoch 207, CIFAR-10 Batch 1:  Loss:     1.3670 Validation Accuracy: 0.525000\n",
      "Epoch 207, CIFAR-10 Batch 2:  Loss:     1.0771 Validation Accuracy: 0.550000\n",
      "Epoch 207, CIFAR-10 Batch 3:  Loss:     1.0877 Validation Accuracy: 0.575000\n",
      "Epoch 207, CIFAR-10 Batch 4:  Loss:     1.1322 Validation Accuracy: 0.550000\n",
      "Epoch 207, CIFAR-10 Batch 5:  Loss:     1.3039 Validation Accuracy: 0.500000\n",
      "Epoch 208, CIFAR-10 Batch 1:  Loss:     1.3667 Validation Accuracy: 0.525000\n",
      "Epoch 208, CIFAR-10 Batch 2:  Loss:     1.0765 Validation Accuracy: 0.550000\n",
      "Epoch 208, CIFAR-10 Batch 3:  Loss:     1.0879 Validation Accuracy: 0.575000\n",
      "Epoch 208, CIFAR-10 Batch 4:  Loss:     1.1316 Validation Accuracy: 0.550000\n",
      "Epoch 208, CIFAR-10 Batch 5:  Loss:     1.3022 Validation Accuracy: 0.500000\n",
      "Epoch 209, CIFAR-10 Batch 1:  Loss:     1.3674 Validation Accuracy: 0.525000\n",
      "Epoch 209, CIFAR-10 Batch 2:  Loss:     1.0756 Validation Accuracy: 0.550000\n",
      "Epoch 209, CIFAR-10 Batch 3:  Loss:     1.0869 Validation Accuracy: 0.575000\n",
      "Epoch 209, CIFAR-10 Batch 4:  Loss:     1.1306 Validation Accuracy: 0.550000\n",
      "Epoch 209, CIFAR-10 Batch 5:  Loss:     1.3003 Validation Accuracy: 0.500000\n",
      "Epoch 210, CIFAR-10 Batch 1:  Loss:     1.3671 Validation Accuracy: 0.525000\n",
      "Epoch 210, CIFAR-10 Batch 2:  Loss:     1.0744 Validation Accuracy: 0.550000\n",
      "Epoch 210, CIFAR-10 Batch 3:  Loss:     1.0871 Validation Accuracy: 0.575000\n",
      "Epoch 210, CIFAR-10 Batch 4:  Loss:     1.1306 Validation Accuracy: 0.550000\n",
      "Epoch 210, CIFAR-10 Batch 5:  Loss:     1.2978 Validation Accuracy: 0.500000\n",
      "Epoch 211, CIFAR-10 Batch 1:  Loss:     1.3682 Validation Accuracy: 0.525000\n",
      "Epoch 211, CIFAR-10 Batch 2:  Loss:     1.0728 Validation Accuracy: 0.550000\n",
      "Epoch 211, CIFAR-10 Batch 3:  Loss:     1.0852 Validation Accuracy: 0.575000\n",
      "Epoch 211, CIFAR-10 Batch 4:  Loss:     1.1318 Validation Accuracy: 0.550000\n",
      "Epoch 211, CIFAR-10 Batch 5:  Loss:     1.2955 Validation Accuracy: 0.500000\n",
      "Epoch 212, CIFAR-10 Batch 1:  Loss:     1.3680 Validation Accuracy: 0.525000\n",
      "Epoch 212, CIFAR-10 Batch 2:  Loss:     1.0718 Validation Accuracy: 0.550000\n",
      "Epoch 212, CIFAR-10 Batch 3:  Loss:     1.0846 Validation Accuracy: 0.575000\n",
      "Epoch 212, CIFAR-10 Batch 4:  Loss:     1.1312 Validation Accuracy: 0.550000\n",
      "Epoch 212, CIFAR-10 Batch 5:  Loss:     1.2943 Validation Accuracy: 0.500000\n",
      "Epoch 213, CIFAR-10 Batch 1:  Loss:     1.3688 Validation Accuracy: 0.525000\n",
      "Epoch 213, CIFAR-10 Batch 2:  Loss:     1.0709 Validation Accuracy: 0.550000\n",
      "Epoch 213, CIFAR-10 Batch 3:  Loss:     1.0829 Validation Accuracy: 0.575000\n",
      "Epoch 213, CIFAR-10 Batch 4:  Loss:     1.1329 Validation Accuracy: 0.550000\n",
      "Epoch 213, CIFAR-10 Batch 5:  Loss:     1.2931 Validation Accuracy: 0.500000\n",
      "Epoch 214, CIFAR-10 Batch 1:  Loss:     1.3685 Validation Accuracy: 0.525000\n",
      "Epoch 214, CIFAR-10 Batch 2:  Loss:     1.0700 Validation Accuracy: 0.550000\n",
      "Epoch 214, CIFAR-10 Batch 3:  Loss:     1.0836 Validation Accuracy: 0.600000\n",
      "Epoch 214, CIFAR-10 Batch 4:  Loss:     1.1336 Validation Accuracy: 0.550000\n",
      "Epoch 214, CIFAR-10 Batch 5:  Loss:     1.2923 Validation Accuracy: 0.500000\n",
      "Epoch 215, CIFAR-10 Batch 1:  Loss:     1.3694 Validation Accuracy: 0.525000\n",
      "Epoch 215, CIFAR-10 Batch 2:  Loss:     1.0691 Validation Accuracy: 0.550000\n",
      "Epoch 215, CIFAR-10 Batch 3:  Loss:     1.0822 Validation Accuracy: 0.600000\n",
      "Epoch 215, CIFAR-10 Batch 4:  Loss:     1.1349 Validation Accuracy: 0.550000\n",
      "Epoch 215, CIFAR-10 Batch 5:  Loss:     1.2914 Validation Accuracy: 0.500000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216, CIFAR-10 Batch 1:  Loss:     1.3693 Validation Accuracy: 0.525000\n",
      "Epoch 216, CIFAR-10 Batch 2:  Loss:     1.0679 Validation Accuracy: 0.550000\n",
      "Epoch 216, CIFAR-10 Batch 3:  Loss:     1.0833 Validation Accuracy: 0.600000\n",
      "Epoch 216, CIFAR-10 Batch 4:  Loss:     1.1346 Validation Accuracy: 0.550000\n",
      "Epoch 216, CIFAR-10 Batch 5:  Loss:     1.2898 Validation Accuracy: 0.500000\n",
      "Epoch 217, CIFAR-10 Batch 1:  Loss:     1.3704 Validation Accuracy: 0.525000\n",
      "Epoch 217, CIFAR-10 Batch 2:  Loss:     1.0671 Validation Accuracy: 0.550000\n",
      "Epoch 217, CIFAR-10 Batch 3:  Loss:     1.0819 Validation Accuracy: 0.600000\n",
      "Epoch 217, CIFAR-10 Batch 4:  Loss:     1.1345 Validation Accuracy: 0.550000\n",
      "Epoch 217, CIFAR-10 Batch 5:  Loss:     1.2897 Validation Accuracy: 0.525000\n",
      "Epoch 218, CIFAR-10 Batch 1:  Loss:     1.3696 Validation Accuracy: 0.525000\n",
      "Epoch 218, CIFAR-10 Batch 2:  Loss:     1.0657 Validation Accuracy: 0.525000\n",
      "Epoch 218, CIFAR-10 Batch 3:  Loss:     1.0817 Validation Accuracy: 0.600000\n",
      "Epoch 218, CIFAR-10 Batch 4:  Loss:     1.1348 Validation Accuracy: 0.575000\n",
      "Epoch 218, CIFAR-10 Batch 5:  Loss:     1.2885 Validation Accuracy: 0.525000\n",
      "Epoch 219, CIFAR-10 Batch 1:  Loss:     1.3689 Validation Accuracy: 0.525000\n",
      "Epoch 219, CIFAR-10 Batch 2:  Loss:     1.0646 Validation Accuracy: 0.525000\n",
      "Epoch 219, CIFAR-10 Batch 3:  Loss:     1.0811 Validation Accuracy: 0.600000\n",
      "Epoch 219, CIFAR-10 Batch 4:  Loss:     1.1350 Validation Accuracy: 0.575000\n",
      "Epoch 219, CIFAR-10 Batch 5:  Loss:     1.2873 Validation Accuracy: 0.525000\n",
      "Epoch 220, CIFAR-10 Batch 1:  Loss:     1.3697 Validation Accuracy: 0.525000\n",
      "Epoch 220, CIFAR-10 Batch 2:  Loss:     1.0636 Validation Accuracy: 0.525000\n",
      "Epoch 220, CIFAR-10 Batch 3:  Loss:     1.0811 Validation Accuracy: 0.600000\n",
      "Epoch 220, CIFAR-10 Batch 4:  Loss:     1.1348 Validation Accuracy: 0.575000\n",
      "Epoch 220, CIFAR-10 Batch 5:  Loss:     1.2870 Validation Accuracy: 0.525000\n",
      "Epoch 221, CIFAR-10 Batch 1:  Loss:     1.3703 Validation Accuracy: 0.525000\n",
      "Epoch 221, CIFAR-10 Batch 2:  Loss:     1.0625 Validation Accuracy: 0.525000\n",
      "Epoch 221, CIFAR-10 Batch 3:  Loss:     1.0804 Validation Accuracy: 0.600000\n",
      "Epoch 221, CIFAR-10 Batch 4:  Loss:     1.1348 Validation Accuracy: 0.575000\n",
      "Epoch 221, CIFAR-10 Batch 5:  Loss:     1.2866 Validation Accuracy: 0.525000\n",
      "Epoch 222, CIFAR-10 Batch 1:  Loss:     1.3706 Validation Accuracy: 0.525000\n",
      "Epoch 222, CIFAR-10 Batch 2:  Loss:     1.0611 Validation Accuracy: 0.525000\n",
      "Epoch 222, CIFAR-10 Batch 3:  Loss:     1.0793 Validation Accuracy: 0.600000\n",
      "Epoch 222, CIFAR-10 Batch 4:  Loss:     1.1338 Validation Accuracy: 0.600000\n",
      "Epoch 222, CIFAR-10 Batch 5:  Loss:     1.2859 Validation Accuracy: 0.525000\n",
      "Epoch 223, CIFAR-10 Batch 1:  Loss:     1.3698 Validation Accuracy: 0.525000\n",
      "Epoch 223, CIFAR-10 Batch 2:  Loss:     1.0605 Validation Accuracy: 0.525000\n",
      "Epoch 223, CIFAR-10 Batch 3:  Loss:     1.0782 Validation Accuracy: 0.600000\n",
      "Epoch 223, CIFAR-10 Batch 4:  Loss:     1.1339 Validation Accuracy: 0.600000\n",
      "Epoch 223, CIFAR-10 Batch 5:  Loss:     1.2856 Validation Accuracy: 0.525000\n",
      "Epoch 224, CIFAR-10 Batch 1:  Loss:     1.3698 Validation Accuracy: 0.525000\n",
      "Epoch 224, CIFAR-10 Batch 2:  Loss:     1.0602 Validation Accuracy: 0.525000\n",
      "Epoch 224, CIFAR-10 Batch 3:  Loss:     1.0775 Validation Accuracy: 0.600000\n",
      "Epoch 224, CIFAR-10 Batch 4:  Loss:     1.1331 Validation Accuracy: 0.600000\n",
      "Epoch 224, CIFAR-10 Batch 5:  Loss:     1.2853 Validation Accuracy: 0.525000\n",
      "Epoch 225, CIFAR-10 Batch 1:  Loss:     1.3687 Validation Accuracy: 0.525000\n",
      "Epoch 225, CIFAR-10 Batch 2:  Loss:     1.0606 Validation Accuracy: 0.525000\n",
      "Epoch 225, CIFAR-10 Batch 3:  Loss:     1.0770 Validation Accuracy: 0.600000\n",
      "Epoch 225, CIFAR-10 Batch 4:  Loss:     1.1326 Validation Accuracy: 0.600000\n",
      "Epoch 225, CIFAR-10 Batch 5:  Loss:     1.2849 Validation Accuracy: 0.525000\n",
      "Epoch 226, CIFAR-10 Batch 1:  Loss:     1.3693 Validation Accuracy: 0.525000\n",
      "Epoch 226, CIFAR-10 Batch 2:  Loss:     1.0597 Validation Accuracy: 0.525000\n",
      "Epoch 226, CIFAR-10 Batch 3:  Loss:     1.0756 Validation Accuracy: 0.600000\n",
      "Epoch 226, CIFAR-10 Batch 4:  Loss:     1.1327 Validation Accuracy: 0.600000\n",
      "Epoch 226, CIFAR-10 Batch 5:  Loss:     1.2859 Validation Accuracy: 0.525000\n",
      "Epoch 227, CIFAR-10 Batch 1:  Loss:     1.3697 Validation Accuracy: 0.525000\n",
      "Epoch 227, CIFAR-10 Batch 2:  Loss:     1.0586 Validation Accuracy: 0.550000\n",
      "Epoch 227, CIFAR-10 Batch 3:  Loss:     1.0737 Validation Accuracy: 0.600000\n",
      "Epoch 227, CIFAR-10 Batch 4:  Loss:     1.1317 Validation Accuracy: 0.600000\n",
      "Epoch 227, CIFAR-10 Batch 5:  Loss:     1.2870 Validation Accuracy: 0.525000\n",
      "Epoch 228, CIFAR-10 Batch 1:  Loss:     1.3689 Validation Accuracy: 0.525000\n",
      "Epoch 228, CIFAR-10 Batch 2:  Loss:     1.0574 Validation Accuracy: 0.550000\n",
      "Epoch 228, CIFAR-10 Batch 3:  Loss:     1.0728 Validation Accuracy: 0.625000\n",
      "Epoch 228, CIFAR-10 Batch 4:  Loss:     1.1305 Validation Accuracy: 0.600000\n",
      "Epoch 228, CIFAR-10 Batch 5:  Loss:     1.2867 Validation Accuracy: 0.525000\n",
      "Epoch 229, CIFAR-10 Batch 1:  Loss:     1.3693 Validation Accuracy: 0.525000\n",
      "Epoch 229, CIFAR-10 Batch 2:  Loss:     1.0569 Validation Accuracy: 0.550000\n",
      "Epoch 229, CIFAR-10 Batch 3:  Loss:     1.0715 Validation Accuracy: 0.625000\n",
      "Epoch 229, CIFAR-10 Batch 4:  Loss:     1.1286 Validation Accuracy: 0.600000\n",
      "Epoch 229, CIFAR-10 Batch 5:  Loss:     1.2878 Validation Accuracy: 0.525000\n",
      "Epoch 230, CIFAR-10 Batch 1:  Loss:     1.3698 Validation Accuracy: 0.525000\n",
      "Epoch 230, CIFAR-10 Batch 2:  Loss:     1.0560 Validation Accuracy: 0.550000\n",
      "Epoch 230, CIFAR-10 Batch 3:  Loss:     1.0713 Validation Accuracy: 0.625000\n",
      "Epoch 230, CIFAR-10 Batch 4:  Loss:     1.1268 Validation Accuracy: 0.600000\n",
      "Epoch 230, CIFAR-10 Batch 5:  Loss:     1.2878 Validation Accuracy: 0.525000\n",
      "Epoch 231, CIFAR-10 Batch 1:  Loss:     1.3698 Validation Accuracy: 0.525000\n",
      "Epoch 231, CIFAR-10 Batch 2:  Loss:     1.0551 Validation Accuracy: 0.550000\n",
      "Epoch 231, CIFAR-10 Batch 3:  Loss:     1.0706 Validation Accuracy: 0.625000\n",
      "Epoch 231, CIFAR-10 Batch 4:  Loss:     1.1266 Validation Accuracy: 0.600000\n",
      "Epoch 231, CIFAR-10 Batch 5:  Loss:     1.2875 Validation Accuracy: 0.525000\n",
      "Epoch 232, CIFAR-10 Batch 1:  Loss:     1.3695 Validation Accuracy: 0.525000\n",
      "Epoch 232, CIFAR-10 Batch 2:  Loss:     1.0545 Validation Accuracy: 0.550000\n",
      "Epoch 232, CIFAR-10 Batch 3:  Loss:     1.0692 Validation Accuracy: 0.625000\n",
      "Epoch 232, CIFAR-10 Batch 4:  Loss:     1.1259 Validation Accuracy: 0.600000\n",
      "Epoch 232, CIFAR-10 Batch 5:  Loss:     1.2881 Validation Accuracy: 0.525000\n",
      "Epoch 233, CIFAR-10 Batch 1:  Loss:     1.3694 Validation Accuracy: 0.525000\n",
      "Epoch 233, CIFAR-10 Batch 2:  Loss:     1.0535 Validation Accuracy: 0.550000\n",
      "Epoch 233, CIFAR-10 Batch 3:  Loss:     1.0682 Validation Accuracy: 0.625000\n",
      "Epoch 233, CIFAR-10 Batch 4:  Loss:     1.1257 Validation Accuracy: 0.600000\n",
      "Epoch 233, CIFAR-10 Batch 5:  Loss:     1.2881 Validation Accuracy: 0.525000\n",
      "Epoch 234, CIFAR-10 Batch 1:  Loss:     1.3696 Validation Accuracy: 0.525000\n",
      "Epoch 234, CIFAR-10 Batch 2:  Loss:     1.0522 Validation Accuracy: 0.550000\n",
      "Epoch 234, CIFAR-10 Batch 3:  Loss:     1.0668 Validation Accuracy: 0.625000\n",
      "Epoch 234, CIFAR-10 Batch 4:  Loss:     1.1258 Validation Accuracy: 0.600000\n",
      "Epoch 234, CIFAR-10 Batch 5:  Loss:     1.2882 Validation Accuracy: 0.525000\n",
      "Epoch 235, CIFAR-10 Batch 1:  Loss:     1.3696 Validation Accuracy: 0.525000\n",
      "Epoch 235, CIFAR-10 Batch 2:  Loss:     1.0510 Validation Accuracy: 0.550000\n",
      "Epoch 235, CIFAR-10 Batch 3:  Loss:     1.0662 Validation Accuracy: 0.625000\n",
      "Epoch 235, CIFAR-10 Batch 4:  Loss:     1.1263 Validation Accuracy: 0.600000\n",
      "Epoch 235, CIFAR-10 Batch 5:  Loss:     1.2882 Validation Accuracy: 0.525000\n",
      "Epoch 236, CIFAR-10 Batch 1:  Loss:     1.3695 Validation Accuracy: 0.525000\n",
      "Epoch 236, CIFAR-10 Batch 2:  Loss:     1.0500 Validation Accuracy: 0.550000\n",
      "Epoch 236, CIFAR-10 Batch 3:  Loss:     1.0658 Validation Accuracy: 0.625000\n",
      "Epoch 236, CIFAR-10 Batch 4:  Loss:     1.1251 Validation Accuracy: 0.600000\n",
      "Epoch 236, CIFAR-10 Batch 5:  Loss:     1.2875 Validation Accuracy: 0.525000\n",
      "Epoch 237, CIFAR-10 Batch 1:  Loss:     1.3698 Validation Accuracy: 0.525000\n",
      "Epoch 237, CIFAR-10 Batch 2:  Loss:     1.0492 Validation Accuracy: 0.550000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237, CIFAR-10 Batch 3:  Loss:     1.0644 Validation Accuracy: 0.625000\n",
      "Epoch 237, CIFAR-10 Batch 4:  Loss:     1.1238 Validation Accuracy: 0.600000\n",
      "Epoch 237, CIFAR-10 Batch 5:  Loss:     1.2869 Validation Accuracy: 0.525000\n",
      "Epoch 238, CIFAR-10 Batch 1:  Loss:     1.3693 Validation Accuracy: 0.525000\n",
      "Epoch 238, CIFAR-10 Batch 2:  Loss:     1.0483 Validation Accuracy: 0.550000\n",
      "Epoch 238, CIFAR-10 Batch 3:  Loss:     1.0641 Validation Accuracy: 0.625000\n",
      "Epoch 238, CIFAR-10 Batch 4:  Loss:     1.1240 Validation Accuracy: 0.600000\n",
      "Epoch 238, CIFAR-10 Batch 5:  Loss:     1.2867 Validation Accuracy: 0.525000\n",
      "Epoch 239, CIFAR-10 Batch 1:  Loss:     1.3687 Validation Accuracy: 0.525000\n",
      "Epoch 239, CIFAR-10 Batch 2:  Loss:     1.0472 Validation Accuracy: 0.550000\n",
      "Epoch 239, CIFAR-10 Batch 3:  Loss:     1.0637 Validation Accuracy: 0.625000\n",
      "Epoch 239, CIFAR-10 Batch 4:  Loss:     1.1239 Validation Accuracy: 0.600000\n",
      "Epoch 239, CIFAR-10 Batch 5:  Loss:     1.2872 Validation Accuracy: 0.525000\n",
      "Epoch 240, CIFAR-10 Batch 1:  Loss:     1.3677 Validation Accuracy: 0.525000\n",
      "Epoch 240, CIFAR-10 Batch 2:  Loss:     1.0458 Validation Accuracy: 0.550000\n",
      "Epoch 240, CIFAR-10 Batch 3:  Loss:     1.0638 Validation Accuracy: 0.625000\n",
      "Epoch 240, CIFAR-10 Batch 4:  Loss:     1.1231 Validation Accuracy: 0.600000\n",
      "Epoch 240, CIFAR-10 Batch 5:  Loss:     1.2871 Validation Accuracy: 0.525000\n",
      "Epoch 241, CIFAR-10 Batch 1:  Loss:     1.3675 Validation Accuracy: 0.525000\n",
      "Epoch 241, CIFAR-10 Batch 2:  Loss:     1.0444 Validation Accuracy: 0.550000\n",
      "Epoch 241, CIFAR-10 Batch 3:  Loss:     1.0621 Validation Accuracy: 0.625000\n",
      "Epoch 241, CIFAR-10 Batch 4:  Loss:     1.1224 Validation Accuracy: 0.600000\n",
      "Epoch 241, CIFAR-10 Batch 5:  Loss:     1.2874 Validation Accuracy: 0.525000\n",
      "Epoch 242, CIFAR-10 Batch 1:  Loss:     1.3665 Validation Accuracy: 0.525000\n",
      "Epoch 242, CIFAR-10 Batch 2:  Loss:     1.0442 Validation Accuracy: 0.550000\n",
      "Epoch 242, CIFAR-10 Batch 3:  Loss:     1.0605 Validation Accuracy: 0.625000\n",
      "Epoch 242, CIFAR-10 Batch 4:  Loss:     1.1214 Validation Accuracy: 0.600000\n",
      "Epoch 242, CIFAR-10 Batch 5:  Loss:     1.2872 Validation Accuracy: 0.525000\n",
      "Epoch 243, CIFAR-10 Batch 1:  Loss:     1.3661 Validation Accuracy: 0.525000\n",
      "Epoch 243, CIFAR-10 Batch 2:  Loss:     1.0426 Validation Accuracy: 0.550000\n",
      "Epoch 243, CIFAR-10 Batch 3:  Loss:     1.0602 Validation Accuracy: 0.625000\n",
      "Epoch 243, CIFAR-10 Batch 4:  Loss:     1.1217 Validation Accuracy: 0.600000\n",
      "Epoch 243, CIFAR-10 Batch 5:  Loss:     1.2876 Validation Accuracy: 0.500000\n",
      "Epoch 244, CIFAR-10 Batch 1:  Loss:     1.3664 Validation Accuracy: 0.525000\n",
      "Epoch 244, CIFAR-10 Batch 2:  Loss:     1.0425 Validation Accuracy: 0.550000\n",
      "Epoch 244, CIFAR-10 Batch 3:  Loss:     1.0583 Validation Accuracy: 0.625000\n",
      "Epoch 244, CIFAR-10 Batch 4:  Loss:     1.1212 Validation Accuracy: 0.600000\n",
      "Epoch 244, CIFAR-10 Batch 5:  Loss:     1.2874 Validation Accuracy: 0.500000\n",
      "Epoch 245, CIFAR-10 Batch 1:  Loss:     1.3659 Validation Accuracy: 0.525000\n",
      "Epoch 245, CIFAR-10 Batch 2:  Loss:     1.0415 Validation Accuracy: 0.550000\n",
      "Epoch 245, CIFAR-10 Batch 3:  Loss:     1.0583 Validation Accuracy: 0.625000\n",
      "Epoch 245, CIFAR-10 Batch 4:  Loss:     1.1211 Validation Accuracy: 0.600000\n",
      "Epoch 245, CIFAR-10 Batch 5:  Loss:     1.2871 Validation Accuracy: 0.500000\n",
      "Epoch 246, CIFAR-10 Batch 1:  Loss:     1.3667 Validation Accuracy: 0.525000\n",
      "Epoch 246, CIFAR-10 Batch 2:  Loss:     1.0422 Validation Accuracy: 0.550000\n",
      "Epoch 246, CIFAR-10 Batch 3:  Loss:     1.0573 Validation Accuracy: 0.625000\n",
      "Epoch 246, CIFAR-10 Batch 4:  Loss:     1.1209 Validation Accuracy: 0.600000\n",
      "Epoch 246, CIFAR-10 Batch 5:  Loss:     1.2864 Validation Accuracy: 0.500000\n",
      "Epoch 247, CIFAR-10 Batch 1:  Loss:     1.3663 Validation Accuracy: 0.525000\n",
      "Epoch 247, CIFAR-10 Batch 2:  Loss:     1.0407 Validation Accuracy: 0.550000\n",
      "Epoch 247, CIFAR-10 Batch 3:  Loss:     1.0556 Validation Accuracy: 0.625000\n",
      "Epoch 247, CIFAR-10 Batch 4:  Loss:     1.1204 Validation Accuracy: 0.600000\n",
      "Epoch 247, CIFAR-10 Batch 5:  Loss:     1.2861 Validation Accuracy: 0.525000\n",
      "Epoch 248, CIFAR-10 Batch 1:  Loss:     1.3661 Validation Accuracy: 0.525000\n",
      "Epoch 248, CIFAR-10 Batch 2:  Loss:     1.0409 Validation Accuracy: 0.550000\n",
      "Epoch 248, CIFAR-10 Batch 3:  Loss:     1.0546 Validation Accuracy: 0.625000\n",
      "Epoch 248, CIFAR-10 Batch 4:  Loss:     1.1204 Validation Accuracy: 0.600000\n",
      "Epoch 248, CIFAR-10 Batch 5:  Loss:     1.2856 Validation Accuracy: 0.525000\n",
      "Epoch 249, CIFAR-10 Batch 1:  Loss:     1.3648 Validation Accuracy: 0.525000\n",
      "Epoch 249, CIFAR-10 Batch 2:  Loss:     1.0398 Validation Accuracy: 0.550000\n",
      "Epoch 249, CIFAR-10 Batch 3:  Loss:     1.0535 Validation Accuracy: 0.625000\n",
      "Epoch 249, CIFAR-10 Batch 4:  Loss:     1.1195 Validation Accuracy: 0.600000\n",
      "Epoch 249, CIFAR-10 Batch 5:  Loss:     1.2849 Validation Accuracy: 0.525000\n",
      "Epoch 250, CIFAR-10 Batch 1:  Loss:     1.3655 Validation Accuracy: 0.525000\n",
      "Epoch 250, CIFAR-10 Batch 2:  Loss:     1.0391 Validation Accuracy: 0.550000\n",
      "Epoch 250, CIFAR-10 Batch 3:  Loss:     1.0520 Validation Accuracy: 0.625000\n",
      "Epoch 250, CIFAR-10 Batch 4:  Loss:     1.1192 Validation Accuracy: 0.600000\n",
      "Epoch 250, CIFAR-10 Batch 5:  Loss:     1.2856 Validation Accuracy: 0.525000\n",
      "Epoch 251, CIFAR-10 Batch 1:  Loss:     1.3643 Validation Accuracy: 0.525000\n",
      "Epoch 251, CIFAR-10 Batch 2:  Loss:     1.0378 Validation Accuracy: 0.550000\n",
      "Epoch 251, CIFAR-10 Batch 3:  Loss:     1.0510 Validation Accuracy: 0.625000\n",
      "Epoch 251, CIFAR-10 Batch 4:  Loss:     1.1193 Validation Accuracy: 0.600000\n",
      "Epoch 251, CIFAR-10 Batch 5:  Loss:     1.2848 Validation Accuracy: 0.525000\n",
      "Epoch 252, CIFAR-10 Batch 1:  Loss:     1.3651 Validation Accuracy: 0.525000\n",
      "Epoch 252, CIFAR-10 Batch 2:  Loss:     1.0375 Validation Accuracy: 0.550000\n",
      "Epoch 252, CIFAR-10 Batch 3:  Loss:     1.0493 Validation Accuracy: 0.625000\n",
      "Epoch 252, CIFAR-10 Batch 4:  Loss:     1.1188 Validation Accuracy: 0.600000\n",
      "Epoch 252, CIFAR-10 Batch 5:  Loss:     1.2855 Validation Accuracy: 0.525000\n",
      "Epoch 253, CIFAR-10 Batch 1:  Loss:     1.3638 Validation Accuracy: 0.525000\n",
      "Epoch 253, CIFAR-10 Batch 2:  Loss:     1.0362 Validation Accuracy: 0.550000\n",
      "Epoch 253, CIFAR-10 Batch 3:  Loss:     1.0487 Validation Accuracy: 0.625000\n",
      "Epoch 253, CIFAR-10 Batch 4:  Loss:     1.1182 Validation Accuracy: 0.600000\n",
      "Epoch 253, CIFAR-10 Batch 5:  Loss:     1.2845 Validation Accuracy: 0.500000\n",
      "Epoch 254, CIFAR-10 Batch 1:  Loss:     1.3623 Validation Accuracy: 0.525000\n",
      "Epoch 254, CIFAR-10 Batch 2:  Loss:     1.0363 Validation Accuracy: 0.550000\n",
      "Epoch 254, CIFAR-10 Batch 3:  Loss:     1.0467 Validation Accuracy: 0.650000\n",
      "Epoch 254, CIFAR-10 Batch 4:  Loss:     1.1181 Validation Accuracy: 0.600000\n",
      "Epoch 254, CIFAR-10 Batch 5:  Loss:     1.2846 Validation Accuracy: 0.500000\n",
      "Epoch 255, CIFAR-10 Batch 1:  Loss:     1.3615 Validation Accuracy: 0.525000\n",
      "Epoch 255, CIFAR-10 Batch 2:  Loss:     1.0352 Validation Accuracy: 0.550000\n",
      "Epoch 255, CIFAR-10 Batch 3:  Loss:     1.0453 Validation Accuracy: 0.650000\n",
      "Epoch 255, CIFAR-10 Batch 4:  Loss:     1.1182 Validation Accuracy: 0.600000\n",
      "Epoch 255, CIFAR-10 Batch 5:  Loss:     1.2850 Validation Accuracy: 0.500000\n",
      "Epoch 256, CIFAR-10 Batch 1:  Loss:     1.3620 Validation Accuracy: 0.525000\n",
      "Epoch 256, CIFAR-10 Batch 2:  Loss:     1.0345 Validation Accuracy: 0.550000\n",
      "Epoch 256, CIFAR-10 Batch 3:  Loss:     1.0447 Validation Accuracy: 0.650000\n",
      "Epoch 256, CIFAR-10 Batch 4:  Loss:     1.1182 Validation Accuracy: 0.600000\n",
      "Epoch 256, CIFAR-10 Batch 5:  Loss:     1.2855 Validation Accuracy: 0.525000\n",
      "Epoch 257, CIFAR-10 Batch 1:  Loss:     1.3617 Validation Accuracy: 0.525000\n",
      "Epoch 257, CIFAR-10 Batch 2:  Loss:     1.0336 Validation Accuracy: 0.550000\n",
      "Epoch 257, CIFAR-10 Batch 3:  Loss:     1.0441 Validation Accuracy: 0.650000\n",
      "Epoch 257, CIFAR-10 Batch 4:  Loss:     1.1174 Validation Accuracy: 0.600000\n",
      "Epoch 257, CIFAR-10 Batch 5:  Loss:     1.2848 Validation Accuracy: 0.525000\n",
      "Epoch 258, CIFAR-10 Batch 1:  Loss:     1.3605 Validation Accuracy: 0.525000\n",
      "Epoch 258, CIFAR-10 Batch 2:  Loss:     1.0326 Validation Accuracy: 0.550000\n",
      "Epoch 258, CIFAR-10 Batch 3:  Loss:     1.0429 Validation Accuracy: 0.650000\n",
      "Epoch 258, CIFAR-10 Batch 4:  Loss:     1.1174 Validation Accuracy: 0.600000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 258, CIFAR-10 Batch 5:  Loss:     1.2851 Validation Accuracy: 0.525000\n",
      "Epoch 259, CIFAR-10 Batch 1:  Loss:     1.3602 Validation Accuracy: 0.525000\n",
      "Epoch 259, CIFAR-10 Batch 2:  Loss:     1.0317 Validation Accuracy: 0.575000\n",
      "Epoch 259, CIFAR-10 Batch 3:  Loss:     1.0437 Validation Accuracy: 0.650000\n",
      "Epoch 259, CIFAR-10 Batch 4:  Loss:     1.1170 Validation Accuracy: 0.600000\n",
      "Epoch 259, CIFAR-10 Batch 5:  Loss:     1.2850 Validation Accuracy: 0.525000\n",
      "Epoch 260, CIFAR-10 Batch 1:  Loss:     1.3606 Validation Accuracy: 0.525000\n",
      "Epoch 260, CIFAR-10 Batch 2:  Loss:     1.0303 Validation Accuracy: 0.575000\n",
      "Epoch 260, CIFAR-10 Batch 3:  Loss:     1.0433 Validation Accuracy: 0.675000\n",
      "Epoch 260, CIFAR-10 Batch 4:  Loss:     1.1170 Validation Accuracy: 0.600000\n",
      "Epoch 260, CIFAR-10 Batch 5:  Loss:     1.2848 Validation Accuracy: 0.525000\n",
      "Epoch 261, CIFAR-10 Batch 1:  Loss:     1.3593 Validation Accuracy: 0.525000\n",
      "Epoch 261, CIFAR-10 Batch 2:  Loss:     1.0294 Validation Accuracy: 0.600000\n",
      "Epoch 261, CIFAR-10 Batch 3:  Loss:     1.0421 Validation Accuracy: 0.675000\n",
      "Epoch 261, CIFAR-10 Batch 4:  Loss:     1.1166 Validation Accuracy: 0.600000\n",
      "Epoch 261, CIFAR-10 Batch 5:  Loss:     1.2851 Validation Accuracy: 0.525000\n",
      "Epoch 262, CIFAR-10 Batch 1:  Loss:     1.3582 Validation Accuracy: 0.525000\n",
      "Epoch 262, CIFAR-10 Batch 2:  Loss:     1.0286 Validation Accuracy: 0.600000\n",
      "Epoch 262, CIFAR-10 Batch 3:  Loss:     1.0424 Validation Accuracy: 0.650000\n",
      "Epoch 262, CIFAR-10 Batch 4:  Loss:     1.1161 Validation Accuracy: 0.600000\n",
      "Epoch 262, CIFAR-10 Batch 5:  Loss:     1.2842 Validation Accuracy: 0.525000\n",
      "Epoch 263, CIFAR-10 Batch 1:  Loss:     1.3583 Validation Accuracy: 0.525000\n",
      "Epoch 263, CIFAR-10 Batch 2:  Loss:     1.0280 Validation Accuracy: 0.625000\n",
      "Epoch 263, CIFAR-10 Batch 3:  Loss:     1.0401 Validation Accuracy: 0.650000\n",
      "Epoch 263, CIFAR-10 Batch 4:  Loss:     1.1162 Validation Accuracy: 0.600000\n",
      "Epoch 263, CIFAR-10 Batch 5:  Loss:     1.2845 Validation Accuracy: 0.525000\n",
      "Epoch 264, CIFAR-10 Batch 1:  Loss:     1.3574 Validation Accuracy: 0.525000\n",
      "Epoch 264, CIFAR-10 Batch 2:  Loss:     1.0273 Validation Accuracy: 0.625000\n",
      "Epoch 264, CIFAR-10 Batch 3:  Loss:     1.0402 Validation Accuracy: 0.650000\n",
      "Epoch 264, CIFAR-10 Batch 4:  Loss:     1.1166 Validation Accuracy: 0.600000\n",
      "Epoch 264, CIFAR-10 Batch 5:  Loss:     1.2842 Validation Accuracy: 0.525000\n",
      "Epoch 265, CIFAR-10 Batch 1:  Loss:     1.3577 Validation Accuracy: 0.525000\n",
      "Epoch 265, CIFAR-10 Batch 2:  Loss:     1.0257 Validation Accuracy: 0.625000\n",
      "Epoch 265, CIFAR-10 Batch 3:  Loss:     1.0393 Validation Accuracy: 0.650000\n",
      "Epoch 265, CIFAR-10 Batch 4:  Loss:     1.1158 Validation Accuracy: 0.600000\n",
      "Epoch 265, CIFAR-10 Batch 5:  Loss:     1.2851 Validation Accuracy: 0.525000\n",
      "Epoch 266, CIFAR-10 Batch 1:  Loss:     1.3567 Validation Accuracy: 0.525000\n",
      "Epoch 266, CIFAR-10 Batch 2:  Loss:     1.0252 Validation Accuracy: 0.625000\n",
      "Epoch 266, CIFAR-10 Batch 3:  Loss:     1.0396 Validation Accuracy: 0.650000\n",
      "Epoch 266, CIFAR-10 Batch 4:  Loss:     1.1153 Validation Accuracy: 0.600000\n",
      "Epoch 266, CIFAR-10 Batch 5:  Loss:     1.2851 Validation Accuracy: 0.525000\n",
      "Epoch 267, CIFAR-10 Batch 1:  Loss:     1.3578 Validation Accuracy: 0.525000\n",
      "Epoch 267, CIFAR-10 Batch 2:  Loss:     1.0248 Validation Accuracy: 0.625000\n",
      "Epoch 267, CIFAR-10 Batch 3:  Loss:     1.0380 Validation Accuracy: 0.650000\n",
      "Epoch 267, CIFAR-10 Batch 4:  Loss:     1.1151 Validation Accuracy: 0.600000\n",
      "Epoch 267, CIFAR-10 Batch 5:  Loss:     1.2844 Validation Accuracy: 0.525000\n",
      "Epoch 268, CIFAR-10 Batch 1:  Loss:     1.3573 Validation Accuracy: 0.525000\n",
      "Epoch 268, CIFAR-10 Batch 2:  Loss:     1.0243 Validation Accuracy: 0.625000\n",
      "Epoch 268, CIFAR-10 Batch 3:  Loss:     1.0384 Validation Accuracy: 0.650000\n",
      "Epoch 268, CIFAR-10 Batch 4:  Loss:     1.1142 Validation Accuracy: 0.600000\n",
      "Epoch 268, CIFAR-10 Batch 5:  Loss:     1.2846 Validation Accuracy: 0.525000\n",
      "Epoch 269, CIFAR-10 Batch 1:  Loss:     1.3560 Validation Accuracy: 0.525000\n",
      "Epoch 269, CIFAR-10 Batch 2:  Loss:     1.0245 Validation Accuracy: 0.625000\n",
      "Epoch 269, CIFAR-10 Batch 3:  Loss:     1.0376 Validation Accuracy: 0.650000\n",
      "Epoch 269, CIFAR-10 Batch 4:  Loss:     1.1142 Validation Accuracy: 0.600000\n",
      "Epoch 269, CIFAR-10 Batch 5:  Loss:     1.2838 Validation Accuracy: 0.525000\n",
      "Epoch 270, CIFAR-10 Batch 1:  Loss:     1.3576 Validation Accuracy: 0.525000\n",
      "Epoch 270, CIFAR-10 Batch 2:  Loss:     1.0241 Validation Accuracy: 0.625000\n",
      "Epoch 270, CIFAR-10 Batch 3:  Loss:     1.0367 Validation Accuracy: 0.650000\n",
      "Epoch 270, CIFAR-10 Batch 4:  Loss:     1.1140 Validation Accuracy: 0.575000\n",
      "Epoch 270, CIFAR-10 Batch 5:  Loss:     1.2842 Validation Accuracy: 0.525000\n",
      "Epoch 271, CIFAR-10 Batch 1:  Loss:     1.3575 Validation Accuracy: 0.525000\n",
      "Epoch 271, CIFAR-10 Batch 2:  Loss:     1.0243 Validation Accuracy: 0.625000\n",
      "Epoch 271, CIFAR-10 Batch 3:  Loss:     1.0367 Validation Accuracy: 0.650000\n",
      "Epoch 271, CIFAR-10 Batch 4:  Loss:     1.1137 Validation Accuracy: 0.600000\n",
      "Epoch 271, CIFAR-10 Batch 5:  Loss:     1.2833 Validation Accuracy: 0.525000\n",
      "Epoch 272, CIFAR-10 Batch 1:  Loss:     1.3564 Validation Accuracy: 0.525000\n",
      "Epoch 272, CIFAR-10 Batch 2:  Loss:     1.0245 Validation Accuracy: 0.625000\n",
      "Epoch 272, CIFAR-10 Batch 3:  Loss:     1.0358 Validation Accuracy: 0.650000\n",
      "Epoch 272, CIFAR-10 Batch 4:  Loss:     1.1136 Validation Accuracy: 0.575000\n",
      "Epoch 272, CIFAR-10 Batch 5:  Loss:     1.2829 Validation Accuracy: 0.525000\n",
      "Epoch 273, CIFAR-10 Batch 1:  Loss:     1.3560 Validation Accuracy: 0.525000\n",
      "Epoch 273, CIFAR-10 Batch 2:  Loss:     1.0238 Validation Accuracy: 0.625000\n",
      "Epoch 273, CIFAR-10 Batch 3:  Loss:     1.0356 Validation Accuracy: 0.650000\n",
      "Epoch 273, CIFAR-10 Batch 4:  Loss:     1.1132 Validation Accuracy: 0.600000\n",
      "Epoch 273, CIFAR-10 Batch 5:  Loss:     1.2835 Validation Accuracy: 0.525000\n",
      "Epoch 274, CIFAR-10 Batch 1:  Loss:     1.3561 Validation Accuracy: 0.525000\n",
      "Epoch 274, CIFAR-10 Batch 2:  Loss:     1.0241 Validation Accuracy: 0.625000\n",
      "Epoch 274, CIFAR-10 Batch 3:  Loss:     1.0351 Validation Accuracy: 0.650000\n",
      "Epoch 274, CIFAR-10 Batch 4:  Loss:     1.1132 Validation Accuracy: 0.575000\n",
      "Epoch 274, CIFAR-10 Batch 5:  Loss:     1.2828 Validation Accuracy: 0.525000\n",
      "Epoch 275, CIFAR-10 Batch 1:  Loss:     1.3563 Validation Accuracy: 0.525000\n",
      "Epoch 275, CIFAR-10 Batch 2:  Loss:     1.0241 Validation Accuracy: 0.625000\n",
      "Epoch 275, CIFAR-10 Batch 3:  Loss:     1.0345 Validation Accuracy: 0.650000\n",
      "Epoch 275, CIFAR-10 Batch 4:  Loss:     1.1131 Validation Accuracy: 0.600000\n",
      "Epoch 275, CIFAR-10 Batch 5:  Loss:     1.2822 Validation Accuracy: 0.525000\n",
      "Epoch 276, CIFAR-10 Batch 1:  Loss:     1.3569 Validation Accuracy: 0.525000\n",
      "Epoch 276, CIFAR-10 Batch 2:  Loss:     1.0236 Validation Accuracy: 0.625000\n",
      "Epoch 276, CIFAR-10 Batch 3:  Loss:     1.0336 Validation Accuracy: 0.650000\n",
      "Epoch 276, CIFAR-10 Batch 4:  Loss:     1.1132 Validation Accuracy: 0.600000\n",
      "Epoch 276, CIFAR-10 Batch 5:  Loss:     1.2820 Validation Accuracy: 0.525000\n",
      "Epoch 277, CIFAR-10 Batch 1:  Loss:     1.3563 Validation Accuracy: 0.525000\n",
      "Epoch 277, CIFAR-10 Batch 2:  Loss:     1.0235 Validation Accuracy: 0.625000\n",
      "Epoch 277, CIFAR-10 Batch 3:  Loss:     1.0333 Validation Accuracy: 0.650000\n",
      "Epoch 277, CIFAR-10 Batch 4:  Loss:     1.1129 Validation Accuracy: 0.600000\n",
      "Epoch 277, CIFAR-10 Batch 5:  Loss:     1.2822 Validation Accuracy: 0.525000\n",
      "Epoch 278, CIFAR-10 Batch 1:  Loss:     1.3567 Validation Accuracy: 0.525000\n",
      "Epoch 278, CIFAR-10 Batch 2:  Loss:     1.0235 Validation Accuracy: 0.625000\n",
      "Epoch 278, CIFAR-10 Batch 3:  Loss:     1.0327 Validation Accuracy: 0.650000\n",
      "Epoch 278, CIFAR-10 Batch 4:  Loss:     1.1127 Validation Accuracy: 0.600000\n",
      "Epoch 278, CIFAR-10 Batch 5:  Loss:     1.2816 Validation Accuracy: 0.525000\n",
      "Epoch 279, CIFAR-10 Batch 1:  Loss:     1.3568 Validation Accuracy: 0.525000\n",
      "Epoch 279, CIFAR-10 Batch 2:  Loss:     1.0229 Validation Accuracy: 0.625000\n",
      "Epoch 279, CIFAR-10 Batch 3:  Loss:     1.0321 Validation Accuracy: 0.650000\n",
      "Epoch 279, CIFAR-10 Batch 4:  Loss:     1.1122 Validation Accuracy: 0.600000\n",
      "Epoch 279, CIFAR-10 Batch 5:  Loss:     1.2812 Validation Accuracy: 0.525000\n",
      "Epoch 280, CIFAR-10 Batch 1:  Loss:     1.3567 Validation Accuracy: 0.525000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280, CIFAR-10 Batch 2:  Loss:     1.0228 Validation Accuracy: 0.625000\n",
      "Epoch 280, CIFAR-10 Batch 3:  Loss:     1.0316 Validation Accuracy: 0.650000\n",
      "Epoch 280, CIFAR-10 Batch 4:  Loss:     1.1124 Validation Accuracy: 0.600000\n",
      "Epoch 280, CIFAR-10 Batch 5:  Loss:     1.2822 Validation Accuracy: 0.475000\n",
      "Epoch 281, CIFAR-10 Batch 1:  Loss:     1.3563 Validation Accuracy: 0.525000\n",
      "Epoch 281, CIFAR-10 Batch 2:  Loss:     1.0224 Validation Accuracy: 0.625000\n",
      "Epoch 281, CIFAR-10 Batch 3:  Loss:     1.0313 Validation Accuracy: 0.650000\n",
      "Epoch 281, CIFAR-10 Batch 4:  Loss:     1.1130 Validation Accuracy: 0.600000\n",
      "Epoch 281, CIFAR-10 Batch 5:  Loss:     1.2810 Validation Accuracy: 0.475000\n",
      "Epoch 282, CIFAR-10 Batch 1:  Loss:     1.3571 Validation Accuracy: 0.525000\n",
      "Epoch 282, CIFAR-10 Batch 2:  Loss:     1.0227 Validation Accuracy: 0.625000\n",
      "Epoch 282, CIFAR-10 Batch 3:  Loss:     1.0314 Validation Accuracy: 0.650000\n",
      "Epoch 282, CIFAR-10 Batch 4:  Loss:     1.1126 Validation Accuracy: 0.600000\n",
      "Epoch 282, CIFAR-10 Batch 5:  Loss:     1.2822 Validation Accuracy: 0.475000\n",
      "Epoch 283, CIFAR-10 Batch 1:  Loss:     1.3576 Validation Accuracy: 0.525000\n",
      "Epoch 283, CIFAR-10 Batch 2:  Loss:     1.0230 Validation Accuracy: 0.625000\n",
      "Epoch 283, CIFAR-10 Batch 3:  Loss:     1.0300 Validation Accuracy: 0.650000\n",
      "Epoch 283, CIFAR-10 Batch 4:  Loss:     1.1121 Validation Accuracy: 0.600000\n",
      "Epoch 283, CIFAR-10 Batch 5:  Loss:     1.2814 Validation Accuracy: 0.475000\n",
      "Epoch 284, CIFAR-10 Batch 1:  Loss:     1.3566 Validation Accuracy: 0.525000\n",
      "Epoch 284, CIFAR-10 Batch 2:  Loss:     1.0227 Validation Accuracy: 0.625000\n",
      "Epoch 284, CIFAR-10 Batch 3:  Loss:     1.0284 Validation Accuracy: 0.650000\n",
      "Epoch 284, CIFAR-10 Batch 4:  Loss:     1.1112 Validation Accuracy: 0.600000\n",
      "Epoch 284, CIFAR-10 Batch 5:  Loss:     1.2815 Validation Accuracy: 0.475000\n",
      "Epoch 285, CIFAR-10 Batch 1:  Loss:     1.3583 Validation Accuracy: 0.525000\n",
      "Epoch 285, CIFAR-10 Batch 2:  Loss:     1.0221 Validation Accuracy: 0.625000\n",
      "Epoch 285, CIFAR-10 Batch 3:  Loss:     1.0280 Validation Accuracy: 0.650000\n",
      "Epoch 285, CIFAR-10 Batch 4:  Loss:     1.1117 Validation Accuracy: 0.600000\n",
      "Epoch 285, CIFAR-10 Batch 5:  Loss:     1.2803 Validation Accuracy: 0.475000\n",
      "Epoch 286, CIFAR-10 Batch 1:  Loss:     1.3565 Validation Accuracy: 0.525000\n",
      "Epoch 286, CIFAR-10 Batch 2:  Loss:     1.0207 Validation Accuracy: 0.625000\n",
      "Epoch 286, CIFAR-10 Batch 3:  Loss:     1.0267 Validation Accuracy: 0.650000\n",
      "Epoch 286, CIFAR-10 Batch 4:  Loss:     1.1117 Validation Accuracy: 0.600000\n",
      "Epoch 286, CIFAR-10 Batch 5:  Loss:     1.2794 Validation Accuracy: 0.475000\n",
      "Epoch 287, CIFAR-10 Batch 1:  Loss:     1.3575 Validation Accuracy: 0.525000\n",
      "Epoch 287, CIFAR-10 Batch 2:  Loss:     1.0207 Validation Accuracy: 0.625000\n",
      "Epoch 287, CIFAR-10 Batch 3:  Loss:     1.0255 Validation Accuracy: 0.650000\n",
      "Epoch 287, CIFAR-10 Batch 4:  Loss:     1.1111 Validation Accuracy: 0.600000\n",
      "Epoch 287, CIFAR-10 Batch 5:  Loss:     1.2787 Validation Accuracy: 0.475000\n",
      "Epoch 288, CIFAR-10 Batch 1:  Loss:     1.3565 Validation Accuracy: 0.525000\n",
      "Epoch 288, CIFAR-10 Batch 2:  Loss:     1.0201 Validation Accuracy: 0.625000\n",
      "Epoch 288, CIFAR-10 Batch 3:  Loss:     1.0236 Validation Accuracy: 0.650000\n",
      "Epoch 288, CIFAR-10 Batch 4:  Loss:     1.1110 Validation Accuracy: 0.600000\n",
      "Epoch 288, CIFAR-10 Batch 5:  Loss:     1.2775 Validation Accuracy: 0.475000\n",
      "Epoch 289, CIFAR-10 Batch 1:  Loss:     1.3555 Validation Accuracy: 0.525000\n",
      "Epoch 289, CIFAR-10 Batch 2:  Loss:     1.0197 Validation Accuracy: 0.625000\n",
      "Epoch 289, CIFAR-10 Batch 3:  Loss:     1.0231 Validation Accuracy: 0.650000\n",
      "Epoch 289, CIFAR-10 Batch 4:  Loss:     1.1109 Validation Accuracy: 0.625000\n",
      "Epoch 289, CIFAR-10 Batch 5:  Loss:     1.2777 Validation Accuracy: 0.475000\n",
      "Epoch 290, CIFAR-10 Batch 1:  Loss:     1.3549 Validation Accuracy: 0.525000\n",
      "Epoch 290, CIFAR-10 Batch 2:  Loss:     1.0195 Validation Accuracy: 0.625000\n",
      "Epoch 290, CIFAR-10 Batch 3:  Loss:     1.0221 Validation Accuracy: 0.650000\n",
      "Epoch 290, CIFAR-10 Batch 4:  Loss:     1.1100 Validation Accuracy: 0.625000\n",
      "Epoch 290, CIFAR-10 Batch 5:  Loss:     1.2768 Validation Accuracy: 0.475000\n",
      "Epoch 291, CIFAR-10 Batch 1:  Loss:     1.3542 Validation Accuracy: 0.525000\n",
      "Epoch 291, CIFAR-10 Batch 2:  Loss:     1.0192 Validation Accuracy: 0.625000\n",
      "Epoch 291, CIFAR-10 Batch 3:  Loss:     1.0214 Validation Accuracy: 0.650000\n",
      "Epoch 291, CIFAR-10 Batch 4:  Loss:     1.1096 Validation Accuracy: 0.625000\n",
      "Epoch 291, CIFAR-10 Batch 5:  Loss:     1.2771 Validation Accuracy: 0.475000\n",
      "Epoch 292, CIFAR-10 Batch 1:  Loss:     1.3544 Validation Accuracy: 0.525000\n",
      "Epoch 292, CIFAR-10 Batch 2:  Loss:     1.0190 Validation Accuracy: 0.625000\n",
      "Epoch 292, CIFAR-10 Batch 3:  Loss:     1.0202 Validation Accuracy: 0.650000\n",
      "Epoch 292, CIFAR-10 Batch 4:  Loss:     1.1089 Validation Accuracy: 0.625000\n",
      "Epoch 292, CIFAR-10 Batch 5:  Loss:     1.2758 Validation Accuracy: 0.475000\n",
      "Epoch 293, CIFAR-10 Batch 1:  Loss:     1.3550 Validation Accuracy: 0.525000\n",
      "Epoch 293, CIFAR-10 Batch 2:  Loss:     1.0185 Validation Accuracy: 0.625000\n",
      "Epoch 293, CIFAR-10 Batch 3:  Loss:     1.0202 Validation Accuracy: 0.650000\n",
      "Epoch 293, CIFAR-10 Batch 4:  Loss:     1.1084 Validation Accuracy: 0.625000\n",
      "Epoch 293, CIFAR-10 Batch 5:  Loss:     1.2754 Validation Accuracy: 0.475000\n",
      "Epoch 294, CIFAR-10 Batch 1:  Loss:     1.3544 Validation Accuracy: 0.525000\n",
      "Epoch 294, CIFAR-10 Batch 2:  Loss:     1.0188 Validation Accuracy: 0.625000\n",
      "Epoch 294, CIFAR-10 Batch 3:  Loss:     1.0192 Validation Accuracy: 0.650000\n",
      "Epoch 294, CIFAR-10 Batch 4:  Loss:     1.1070 Validation Accuracy: 0.625000\n",
      "Epoch 294, CIFAR-10 Batch 5:  Loss:     1.2760 Validation Accuracy: 0.475000\n",
      "Epoch 295, CIFAR-10 Batch 1:  Loss:     1.3548 Validation Accuracy: 0.525000\n",
      "Epoch 295, CIFAR-10 Batch 2:  Loss:     1.0189 Validation Accuracy: 0.625000\n",
      "Epoch 295, CIFAR-10 Batch 3:  Loss:     1.0197 Validation Accuracy: 0.650000\n",
      "Epoch 295, CIFAR-10 Batch 4:  Loss:     1.1056 Validation Accuracy: 0.625000\n",
      "Epoch 295, CIFAR-10 Batch 5:  Loss:     1.2764 Validation Accuracy: 0.475000\n",
      "Epoch 296, CIFAR-10 Batch 1:  Loss:     1.3540 Validation Accuracy: 0.525000\n",
      "Epoch 296, CIFAR-10 Batch 2:  Loss:     1.0189 Validation Accuracy: 0.650000\n",
      "Epoch 296, CIFAR-10 Batch 3:  Loss:     1.0187 Validation Accuracy: 0.650000\n",
      "Epoch 296, CIFAR-10 Batch 4:  Loss:     1.1048 Validation Accuracy: 0.600000\n",
      "Epoch 296, CIFAR-10 Batch 5:  Loss:     1.2760 Validation Accuracy: 0.475000\n",
      "Epoch 297, CIFAR-10 Batch 1:  Loss:     1.3535 Validation Accuracy: 0.525000\n",
      "Epoch 297, CIFAR-10 Batch 2:  Loss:     1.0191 Validation Accuracy: 0.650000\n",
      "Epoch 297, CIFAR-10 Batch 3:  Loss:     1.0182 Validation Accuracy: 0.650000\n",
      "Epoch 297, CIFAR-10 Batch 4:  Loss:     1.1040 Validation Accuracy: 0.600000\n",
      "Epoch 297, CIFAR-10 Batch 5:  Loss:     1.2761 Validation Accuracy: 0.475000\n",
      "Epoch 298, CIFAR-10 Batch 1:  Loss:     1.3537 Validation Accuracy: 0.500000\n",
      "Epoch 298, CIFAR-10 Batch 2:  Loss:     1.0194 Validation Accuracy: 0.650000\n",
      "Epoch 298, CIFAR-10 Batch 3:  Loss:     1.0167 Validation Accuracy: 0.650000\n",
      "Epoch 298, CIFAR-10 Batch 4:  Loss:     1.1042 Validation Accuracy: 0.600000\n",
      "Epoch 298, CIFAR-10 Batch 5:  Loss:     1.2757 Validation Accuracy: 0.475000\n",
      "Epoch 299, CIFAR-10 Batch 1:  Loss:     1.3541 Validation Accuracy: 0.500000\n",
      "Epoch 299, CIFAR-10 Batch 2:  Loss:     1.0193 Validation Accuracy: 0.650000\n",
      "Epoch 299, CIFAR-10 Batch 3:  Loss:     1.0164 Validation Accuracy: 0.650000\n",
      "Epoch 299, CIFAR-10 Batch 4:  Loss:     1.1033 Validation Accuracy: 0.600000\n",
      "Epoch 299, CIFAR-10 Batch 5:  Loss:     1.2757 Validation Accuracy: 0.475000\n",
      "Epoch 300, CIFAR-10 Batch 1:  Loss:     1.3535 Validation Accuracy: 0.500000\n",
      "Epoch 300, CIFAR-10 Batch 2:  Loss:     1.0199 Validation Accuracy: 0.650000\n",
      "Epoch 300, CIFAR-10 Batch 3:  Loss:     1.0164 Validation Accuracy: 0.650000\n",
      "Epoch 300, CIFAR-10 Batch 4:  Loss:     1.1027 Validation Accuracy: 0.600000\n",
      "Epoch 300, CIFAR-10 Batch 5:  Loss:     1.2750 Validation Accuracy: 0.475000\n",
      "Epoch 301, CIFAR-10 Batch 1:  Loss:     1.3535 Validation Accuracy: 0.500000\n",
      "Epoch 301, CIFAR-10 Batch 2:  Loss:     1.0204 Validation Accuracy: 0.675000\n",
      "Epoch 301, CIFAR-10 Batch 3:  Loss:     1.0154 Validation Accuracy: 0.650000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301, CIFAR-10 Batch 4:  Loss:     1.1017 Validation Accuracy: 0.600000\n",
      "Epoch 301, CIFAR-10 Batch 5:  Loss:     1.2747 Validation Accuracy: 0.475000\n",
      "Epoch 302, CIFAR-10 Batch 1:  Loss:     1.3537 Validation Accuracy: 0.500000\n",
      "Epoch 302, CIFAR-10 Batch 2:  Loss:     1.0204 Validation Accuracy: 0.650000\n",
      "Epoch 302, CIFAR-10 Batch 3:  Loss:     1.0143 Validation Accuracy: 0.650000\n",
      "Epoch 302, CIFAR-10 Batch 4:  Loss:     1.1019 Validation Accuracy: 0.600000\n",
      "Epoch 302, CIFAR-10 Batch 5:  Loss:     1.2744 Validation Accuracy: 0.475000\n",
      "Epoch 303, CIFAR-10 Batch 1:  Loss:     1.3541 Validation Accuracy: 0.500000\n",
      "Epoch 303, CIFAR-10 Batch 2:  Loss:     1.0207 Validation Accuracy: 0.650000\n",
      "Epoch 303, CIFAR-10 Batch 3:  Loss:     1.0130 Validation Accuracy: 0.650000\n",
      "Epoch 303, CIFAR-10 Batch 4:  Loss:     1.1025 Validation Accuracy: 0.600000\n",
      "Epoch 303, CIFAR-10 Batch 5:  Loss:     1.2737 Validation Accuracy: 0.475000\n",
      "Epoch 304, CIFAR-10 Batch 1:  Loss:     1.3542 Validation Accuracy: 0.500000\n",
      "Epoch 304, CIFAR-10 Batch 2:  Loss:     1.0210 Validation Accuracy: 0.650000\n",
      "Epoch 304, CIFAR-10 Batch 3:  Loss:     1.0135 Validation Accuracy: 0.650000\n",
      "Epoch 304, CIFAR-10 Batch 4:  Loss:     1.1019 Validation Accuracy: 0.600000\n",
      "Epoch 304, CIFAR-10 Batch 5:  Loss:     1.2737 Validation Accuracy: 0.475000\n",
      "Epoch 305, CIFAR-10 Batch 1:  Loss:     1.3534 Validation Accuracy: 0.500000\n",
      "Epoch 305, CIFAR-10 Batch 2:  Loss:     1.0214 Validation Accuracy: 0.650000\n",
      "Epoch 305, CIFAR-10 Batch 3:  Loss:     1.0122 Validation Accuracy: 0.650000\n",
      "Epoch 305, CIFAR-10 Batch 4:  Loss:     1.1011 Validation Accuracy: 0.600000\n",
      "Epoch 305, CIFAR-10 Batch 5:  Loss:     1.2745 Validation Accuracy: 0.475000\n",
      "Epoch 306, CIFAR-10 Batch 1:  Loss:     1.3537 Validation Accuracy: 0.500000\n",
      "Epoch 306, CIFAR-10 Batch 2:  Loss:     1.0213 Validation Accuracy: 0.650000\n",
      "Epoch 306, CIFAR-10 Batch 3:  Loss:     1.0113 Validation Accuracy: 0.650000\n",
      "Epoch 306, CIFAR-10 Batch 4:  Loss:     1.1003 Validation Accuracy: 0.600000\n",
      "Epoch 306, CIFAR-10 Batch 5:  Loss:     1.2740 Validation Accuracy: 0.475000\n",
      "Epoch 307, CIFAR-10 Batch 1:  Loss:     1.3538 Validation Accuracy: 0.500000\n",
      "Epoch 307, CIFAR-10 Batch 2:  Loss:     1.0224 Validation Accuracy: 0.675000\n",
      "Epoch 307, CIFAR-10 Batch 3:  Loss:     1.0112 Validation Accuracy: 0.650000\n",
      "Epoch 307, CIFAR-10 Batch 4:  Loss:     1.1001 Validation Accuracy: 0.600000\n",
      "Epoch 307, CIFAR-10 Batch 5:  Loss:     1.2739 Validation Accuracy: 0.475000\n",
      "Epoch 308, CIFAR-10 Batch 1:  Loss:     1.3540 Validation Accuracy: 0.500000\n",
      "Epoch 308, CIFAR-10 Batch 2:  Loss:     1.0225 Validation Accuracy: 0.650000\n",
      "Epoch 308, CIFAR-10 Batch 3:  Loss:     1.0106 Validation Accuracy: 0.650000\n",
      "Epoch 308, CIFAR-10 Batch 4:  Loss:     1.0997 Validation Accuracy: 0.600000\n",
      "Epoch 308, CIFAR-10 Batch 5:  Loss:     1.2740 Validation Accuracy: 0.475000\n",
      "Epoch 309, CIFAR-10 Batch 1:  Loss:     1.3528 Validation Accuracy: 0.500000\n",
      "Epoch 309, CIFAR-10 Batch 2:  Loss:     1.0231 Validation Accuracy: 0.650000\n",
      "Epoch 309, CIFAR-10 Batch 3:  Loss:     1.0096 Validation Accuracy: 0.675000\n",
      "Epoch 309, CIFAR-10 Batch 4:  Loss:     1.0999 Validation Accuracy: 0.600000\n",
      "Epoch 309, CIFAR-10 Batch 5:  Loss:     1.2731 Validation Accuracy: 0.450000\n",
      "Epoch 310, CIFAR-10 Batch 1:  Loss:     1.3533 Validation Accuracy: 0.500000\n",
      "Epoch 310, CIFAR-10 Batch 2:  Loss:     1.0228 Validation Accuracy: 0.650000\n",
      "Epoch 310, CIFAR-10 Batch 3:  Loss:     1.0094 Validation Accuracy: 0.675000\n",
      "Epoch 310, CIFAR-10 Batch 4:  Loss:     1.1001 Validation Accuracy: 0.600000\n",
      "Epoch 310, CIFAR-10 Batch 5:  Loss:     1.2727 Validation Accuracy: 0.450000\n",
      "Epoch 311, CIFAR-10 Batch 1:  Loss:     1.3533 Validation Accuracy: 0.500000\n",
      "Epoch 311, CIFAR-10 Batch 2:  Loss:     1.0235 Validation Accuracy: 0.650000\n",
      "Epoch 311, CIFAR-10 Batch 3:  Loss:     1.0084 Validation Accuracy: 0.675000\n",
      "Epoch 311, CIFAR-10 Batch 4:  Loss:     1.1004 Validation Accuracy: 0.600000\n",
      "Epoch 311, CIFAR-10 Batch 5:  Loss:     1.2728 Validation Accuracy: 0.475000\n",
      "Epoch 312, CIFAR-10 Batch 1:  Loss:     1.3528 Validation Accuracy: 0.500000\n",
      "Epoch 312, CIFAR-10 Batch 2:  Loss:     1.0235 Validation Accuracy: 0.650000\n",
      "Epoch 312, CIFAR-10 Batch 3:  Loss:     1.0079 Validation Accuracy: 0.675000\n",
      "Epoch 312, CIFAR-10 Batch 4:  Loss:     1.1002 Validation Accuracy: 0.600000\n",
      "Epoch 312, CIFAR-10 Batch 5:  Loss:     1.2720 Validation Accuracy: 0.475000\n",
      "Epoch 313, CIFAR-10 Batch 1:  Loss:     1.3531 Validation Accuracy: 0.500000\n",
      "Epoch 313, CIFAR-10 Batch 2:  Loss:     1.0233 Validation Accuracy: 0.650000\n",
      "Epoch 313, CIFAR-10 Batch 3:  Loss:     1.0076 Validation Accuracy: 0.675000\n",
      "Epoch 313, CIFAR-10 Batch 4:  Loss:     1.1000 Validation Accuracy: 0.600000\n",
      "Epoch 313, CIFAR-10 Batch 5:  Loss:     1.2723 Validation Accuracy: 0.475000\n",
      "Epoch 314, CIFAR-10 Batch 1:  Loss:     1.3530 Validation Accuracy: 0.500000\n",
      "Epoch 314, CIFAR-10 Batch 2:  Loss:     1.0235 Validation Accuracy: 0.650000\n",
      "Epoch 314, CIFAR-10 Batch 3:  Loss:     1.0075 Validation Accuracy: 0.675000\n",
      "Epoch 314, CIFAR-10 Batch 4:  Loss:     1.1002 Validation Accuracy: 0.600000\n",
      "Epoch 314, CIFAR-10 Batch 5:  Loss:     1.2719 Validation Accuracy: 0.500000\n",
      "Epoch 315, CIFAR-10 Batch 1:  Loss:     1.3524 Validation Accuracy: 0.500000\n",
      "Epoch 315, CIFAR-10 Batch 2:  Loss:     1.0242 Validation Accuracy: 0.650000\n",
      "Epoch 315, CIFAR-10 Batch 3:  Loss:     1.0078 Validation Accuracy: 0.675000\n",
      "Epoch 315, CIFAR-10 Batch 4:  Loss:     1.1008 Validation Accuracy: 0.600000\n",
      "Epoch 315, CIFAR-10 Batch 5:  Loss:     1.2712 Validation Accuracy: 0.500000\n",
      "Epoch 316, CIFAR-10 Batch 1:  Loss:     1.3528 Validation Accuracy: 0.500000\n",
      "Epoch 316, CIFAR-10 Batch 2:  Loss:     1.0242 Validation Accuracy: 0.650000\n",
      "Epoch 316, CIFAR-10 Batch 3:  Loss:     1.0063 Validation Accuracy: 0.675000\n",
      "Epoch 316, CIFAR-10 Batch 4:  Loss:     1.1009 Validation Accuracy: 0.600000\n",
      "Epoch 316, CIFAR-10 Batch 5:  Loss:     1.2712 Validation Accuracy: 0.500000\n",
      "Epoch 317, CIFAR-10 Batch 1:  Loss:     1.3543 Validation Accuracy: 0.500000\n",
      "Epoch 317, CIFAR-10 Batch 2:  Loss:     1.0247 Validation Accuracy: 0.650000\n",
      "Epoch 317, CIFAR-10 Batch 3:  Loss:     1.0062 Validation Accuracy: 0.675000\n",
      "Epoch 317, CIFAR-10 Batch 4:  Loss:     1.1005 Validation Accuracy: 0.600000\n",
      "Epoch 317, CIFAR-10 Batch 5:  Loss:     1.2714 Validation Accuracy: 0.500000\n",
      "Epoch 318, CIFAR-10 Batch 1:  Loss:     1.3531 Validation Accuracy: 0.500000\n",
      "Epoch 318, CIFAR-10 Batch 2:  Loss:     1.0248 Validation Accuracy: 0.650000\n",
      "Epoch 318, CIFAR-10 Batch 3:  Loss:     1.0055 Validation Accuracy: 0.675000\n",
      "Epoch 318, CIFAR-10 Batch 4:  Loss:     1.1008 Validation Accuracy: 0.600000\n",
      "Epoch 318, CIFAR-10 Batch 5:  Loss:     1.2706 Validation Accuracy: 0.500000\n",
      "Epoch 319, CIFAR-10 Batch 1:  Loss:     1.3538 Validation Accuracy: 0.500000\n",
      "Epoch 319, CIFAR-10 Batch 2:  Loss:     1.0252 Validation Accuracy: 0.650000\n",
      "Epoch 319, CIFAR-10 Batch 3:  Loss:     1.0052 Validation Accuracy: 0.675000\n",
      "Epoch 319, CIFAR-10 Batch 4:  Loss:     1.1006 Validation Accuracy: 0.600000\n",
      "Epoch 319, CIFAR-10 Batch 5:  Loss:     1.2702 Validation Accuracy: 0.500000\n",
      "Epoch 320, CIFAR-10 Batch 1:  Loss:     1.3553 Validation Accuracy: 0.500000\n",
      "Epoch 320, CIFAR-10 Batch 2:  Loss:     1.0251 Validation Accuracy: 0.650000\n",
      "Epoch 320, CIFAR-10 Batch 3:  Loss:     1.0051 Validation Accuracy: 0.675000\n",
      "Epoch 320, CIFAR-10 Batch 4:  Loss:     1.1007 Validation Accuracy: 0.600000\n",
      "Epoch 320, CIFAR-10 Batch 5:  Loss:     1.2701 Validation Accuracy: 0.500000\n",
      "Epoch 321, CIFAR-10 Batch 1:  Loss:     1.3542 Validation Accuracy: 0.500000\n",
      "Epoch 321, CIFAR-10 Batch 2:  Loss:     1.0250 Validation Accuracy: 0.650000\n",
      "Epoch 321, CIFAR-10 Batch 3:  Loss:     1.0044 Validation Accuracy: 0.675000\n",
      "Epoch 321, CIFAR-10 Batch 4:  Loss:     1.1009 Validation Accuracy: 0.600000\n",
      "Epoch 321, CIFAR-10 Batch 5:  Loss:     1.2701 Validation Accuracy: 0.500000\n",
      "Epoch 322, CIFAR-10 Batch 1:  Loss:     1.3541 Validation Accuracy: 0.500000\n",
      "Epoch 322, CIFAR-10 Batch 2:  Loss:     1.0248 Validation Accuracy: 0.650000\n",
      "Epoch 322, CIFAR-10 Batch 3:  Loss:     1.0037 Validation Accuracy: 0.675000\n",
      "Epoch 322, CIFAR-10 Batch 4:  Loss:     1.1006 Validation Accuracy: 0.600000\n",
      "Epoch 322, CIFAR-10 Batch 5:  Loss:     1.2707 Validation Accuracy: 0.500000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 323, CIFAR-10 Batch 1:  Loss:     1.3544 Validation Accuracy: 0.500000\n",
      "Epoch 323, CIFAR-10 Batch 2:  Loss:     1.0252 Validation Accuracy: 0.650000\n",
      "Epoch 323, CIFAR-10 Batch 3:  Loss:     1.0041 Validation Accuracy: 0.675000\n",
      "Epoch 323, CIFAR-10 Batch 4:  Loss:     1.1001 Validation Accuracy: 0.600000\n",
      "Epoch 323, CIFAR-10 Batch 5:  Loss:     1.2701 Validation Accuracy: 0.475000\n",
      "Epoch 324, CIFAR-10 Batch 1:  Loss:     1.3547 Validation Accuracy: 0.500000\n",
      "Epoch 324, CIFAR-10 Batch 2:  Loss:     1.0255 Validation Accuracy: 0.650000\n",
      "Epoch 324, CIFAR-10 Batch 3:  Loss:     1.0038 Validation Accuracy: 0.675000\n",
      "Epoch 324, CIFAR-10 Batch 4:  Loss:     1.1009 Validation Accuracy: 0.600000\n",
      "Epoch 324, CIFAR-10 Batch 5:  Loss:     1.2700 Validation Accuracy: 0.475000\n",
      "Epoch 325, CIFAR-10 Batch 1:  Loss:     1.3555 Validation Accuracy: 0.500000\n",
      "Epoch 325, CIFAR-10 Batch 2:  Loss:     1.0256 Validation Accuracy: 0.650000\n",
      "Epoch 325, CIFAR-10 Batch 3:  Loss:     1.0035 Validation Accuracy: 0.675000\n",
      "Epoch 325, CIFAR-10 Batch 4:  Loss:     1.1005 Validation Accuracy: 0.600000\n",
      "Epoch 325, CIFAR-10 Batch 5:  Loss:     1.2696 Validation Accuracy: 0.475000\n",
      "Epoch 326, CIFAR-10 Batch 1:  Loss:     1.3553 Validation Accuracy: 0.500000\n",
      "Epoch 326, CIFAR-10 Batch 2:  Loss:     1.0255 Validation Accuracy: 0.650000\n",
      "Epoch 326, CIFAR-10 Batch 3:  Loss:     1.0028 Validation Accuracy: 0.675000\n",
      "Epoch 326, CIFAR-10 Batch 4:  Loss:     1.1005 Validation Accuracy: 0.600000\n",
      "Epoch 326, CIFAR-10 Batch 5:  Loss:     1.2690 Validation Accuracy: 0.450000\n",
      "Epoch 327, CIFAR-10 Batch 1:  Loss:     1.3554 Validation Accuracy: 0.500000\n",
      "Epoch 327, CIFAR-10 Batch 2:  Loss:     1.0256 Validation Accuracy: 0.650000\n",
      "Epoch 327, CIFAR-10 Batch 3:  Loss:     1.0026 Validation Accuracy: 0.675000\n",
      "Epoch 327, CIFAR-10 Batch 4:  Loss:     1.1004 Validation Accuracy: 0.600000\n",
      "Epoch 327, CIFAR-10 Batch 5:  Loss:     1.2686 Validation Accuracy: 0.450000\n",
      "Epoch 328, CIFAR-10 Batch 1:  Loss:     1.3556 Validation Accuracy: 0.500000\n",
      "Epoch 328, CIFAR-10 Batch 2:  Loss:     1.0259 Validation Accuracy: 0.650000\n",
      "Epoch 328, CIFAR-10 Batch 3:  Loss:     1.0017 Validation Accuracy: 0.675000\n",
      "Epoch 328, CIFAR-10 Batch 4:  Loss:     1.1002 Validation Accuracy: 0.600000\n",
      "Epoch 328, CIFAR-10 Batch 5:  Loss:     1.2686 Validation Accuracy: 0.450000\n",
      "Epoch 329, CIFAR-10 Batch 1:  Loss:     1.3560 Validation Accuracy: 0.500000\n",
      "Epoch 329, CIFAR-10 Batch 2:  Loss:     1.0257 Validation Accuracy: 0.650000\n",
      "Epoch 329, CIFAR-10 Batch 3:  Loss:     1.0015 Validation Accuracy: 0.675000\n",
      "Epoch 329, CIFAR-10 Batch 4:  Loss:     1.1005 Validation Accuracy: 0.600000\n",
      "Epoch 329, CIFAR-10 Batch 5:  Loss:     1.2682 Validation Accuracy: 0.450000\n",
      "Epoch 330, CIFAR-10 Batch 1:  Loss:     1.3568 Validation Accuracy: 0.500000\n",
      "Epoch 330, CIFAR-10 Batch 2:  Loss:     1.0266 Validation Accuracy: 0.625000\n",
      "Epoch 330, CIFAR-10 Batch 3:  Loss:     1.0008 Validation Accuracy: 0.675000\n",
      "Epoch 330, CIFAR-10 Batch 4:  Loss:     1.1002 Validation Accuracy: 0.600000\n",
      "Epoch 330, CIFAR-10 Batch 5:  Loss:     1.2687 Validation Accuracy: 0.450000\n",
      "Epoch 331, CIFAR-10 Batch 1:  Loss:     1.3564 Validation Accuracy: 0.475000\n",
      "Epoch 331, CIFAR-10 Batch 2:  Loss:     1.0259 Validation Accuracy: 0.625000\n",
      "Epoch 331, CIFAR-10 Batch 3:  Loss:     1.0011 Validation Accuracy: 0.675000\n",
      "Epoch 331, CIFAR-10 Batch 4:  Loss:     1.1008 Validation Accuracy: 0.600000\n",
      "Epoch 331, CIFAR-10 Batch 5:  Loss:     1.2686 Validation Accuracy: 0.450000\n",
      "Epoch 332, CIFAR-10 Batch 1:  Loss:     1.3569 Validation Accuracy: 0.475000\n",
      "Epoch 332, CIFAR-10 Batch 2:  Loss:     1.0264 Validation Accuracy: 0.625000\n",
      "Epoch 332, CIFAR-10 Batch 3:  Loss:     1.0011 Validation Accuracy: 0.675000\n",
      "Epoch 332, CIFAR-10 Batch 4:  Loss:     1.1012 Validation Accuracy: 0.600000\n",
      "Epoch 332, CIFAR-10 Batch 5:  Loss:     1.2686 Validation Accuracy: 0.450000\n",
      "Epoch 333, CIFAR-10 Batch 1:  Loss:     1.3572 Validation Accuracy: 0.475000\n",
      "Epoch 333, CIFAR-10 Batch 2:  Loss:     1.0263 Validation Accuracy: 0.625000\n",
      "Epoch 333, CIFAR-10 Batch 3:  Loss:     1.0001 Validation Accuracy: 0.675000\n",
      "Epoch 333, CIFAR-10 Batch 4:  Loss:     1.1009 Validation Accuracy: 0.600000\n",
      "Epoch 333, CIFAR-10 Batch 5:  Loss:     1.2688 Validation Accuracy: 0.450000\n",
      "Epoch 334, CIFAR-10 Batch 1:  Loss:     1.3573 Validation Accuracy: 0.475000\n",
      "Epoch 334, CIFAR-10 Batch 2:  Loss:     1.0263 Validation Accuracy: 0.625000\n",
      "Epoch 334, CIFAR-10 Batch 3:  Loss:     1.0000 Validation Accuracy: 0.675000\n",
      "Epoch 334, CIFAR-10 Batch 4:  Loss:     1.1010 Validation Accuracy: 0.600000\n",
      "Epoch 334, CIFAR-10 Batch 5:  Loss:     1.2683 Validation Accuracy: 0.450000\n",
      "Epoch 335, CIFAR-10 Batch 1:  Loss:     1.3558 Validation Accuracy: 0.475000\n",
      "Epoch 335, CIFAR-10 Batch 2:  Loss:     1.0264 Validation Accuracy: 0.625000\n",
      "Epoch 335, CIFAR-10 Batch 3:  Loss:     0.9990 Validation Accuracy: 0.675000\n",
      "Epoch 335, CIFAR-10 Batch 4:  Loss:     1.1010 Validation Accuracy: 0.600000\n",
      "Epoch 335, CIFAR-10 Batch 5:  Loss:     1.2688 Validation Accuracy: 0.450000\n",
      "Epoch 336, CIFAR-10 Batch 1:  Loss:     1.3558 Validation Accuracy: 0.475000\n",
      "Epoch 336, CIFAR-10 Batch 2:  Loss:     1.0262 Validation Accuracy: 0.625000\n",
      "Epoch 336, CIFAR-10 Batch 3:  Loss:     0.9993 Validation Accuracy: 0.675000\n",
      "Epoch 336, CIFAR-10 Batch 4:  Loss:     1.1003 Validation Accuracy: 0.600000\n",
      "Epoch 336, CIFAR-10 Batch 5:  Loss:     1.2694 Validation Accuracy: 0.450000\n",
      "Epoch 337, CIFAR-10 Batch 1:  Loss:     1.3566 Validation Accuracy: 0.475000\n",
      "Epoch 337, CIFAR-10 Batch 2:  Loss:     1.0263 Validation Accuracy: 0.625000\n",
      "Epoch 337, CIFAR-10 Batch 3:  Loss:     0.9983 Validation Accuracy: 0.675000\n",
      "Epoch 337, CIFAR-10 Batch 4:  Loss:     1.0997 Validation Accuracy: 0.600000\n",
      "Epoch 337, CIFAR-10 Batch 5:  Loss:     1.2689 Validation Accuracy: 0.450000\n",
      "Epoch 338, CIFAR-10 Batch 1:  Loss:     1.3559 Validation Accuracy: 0.475000\n",
      "Epoch 338, CIFAR-10 Batch 2:  Loss:     1.0266 Validation Accuracy: 0.650000\n",
      "Epoch 338, CIFAR-10 Batch 3:  Loss:     0.9987 Validation Accuracy: 0.675000\n",
      "Epoch 338, CIFAR-10 Batch 4:  Loss:     1.0996 Validation Accuracy: 0.600000\n",
      "Epoch 338, CIFAR-10 Batch 5:  Loss:     1.2688 Validation Accuracy: 0.450000\n",
      "Epoch 339, CIFAR-10 Batch 1:  Loss:     1.3562 Validation Accuracy: 0.475000\n",
      "Epoch 339, CIFAR-10 Batch 2:  Loss:     1.0265 Validation Accuracy: 0.650000\n",
      "Epoch 339, CIFAR-10 Batch 3:  Loss:     0.9988 Validation Accuracy: 0.675000\n",
      "Epoch 339, CIFAR-10 Batch 4:  Loss:     1.0989 Validation Accuracy: 0.600000\n",
      "Epoch 339, CIFAR-10 Batch 5:  Loss:     1.2697 Validation Accuracy: 0.450000\n",
      "Epoch 340, CIFAR-10 Batch 1:  Loss:     1.3559 Validation Accuracy: 0.475000\n",
      "Epoch 340, CIFAR-10 Batch 2:  Loss:     1.0261 Validation Accuracy: 0.625000\n",
      "Epoch 340, CIFAR-10 Batch 3:  Loss:     0.9988 Validation Accuracy: 0.675000\n",
      "Epoch 340, CIFAR-10 Batch 4:  Loss:     1.0993 Validation Accuracy: 0.600000\n",
      "Epoch 340, CIFAR-10 Batch 5:  Loss:     1.2697 Validation Accuracy: 0.450000\n",
      "Epoch 341, CIFAR-10 Batch 1:  Loss:     1.3554 Validation Accuracy: 0.475000\n",
      "Epoch 341, CIFAR-10 Batch 2:  Loss:     1.0259 Validation Accuracy: 0.625000\n",
      "Epoch 341, CIFAR-10 Batch 3:  Loss:     0.9981 Validation Accuracy: 0.675000\n",
      "Epoch 341, CIFAR-10 Batch 4:  Loss:     1.0986 Validation Accuracy: 0.600000\n",
      "Epoch 341, CIFAR-10 Batch 5:  Loss:     1.2694 Validation Accuracy: 0.450000\n",
      "Epoch 342, CIFAR-10 Batch 1:  Loss:     1.3552 Validation Accuracy: 0.475000\n",
      "Epoch 342, CIFAR-10 Batch 2:  Loss:     1.0261 Validation Accuracy: 0.625000\n",
      "Epoch 342, CIFAR-10 Batch 3:  Loss:     0.9981 Validation Accuracy: 0.675000\n",
      "Epoch 342, CIFAR-10 Batch 4:  Loss:     1.0991 Validation Accuracy: 0.600000\n",
      "Epoch 342, CIFAR-10 Batch 5:  Loss:     1.2691 Validation Accuracy: 0.450000\n",
      "Epoch 343, CIFAR-10 Batch 1:  Loss:     1.3547 Validation Accuracy: 0.475000\n",
      "Epoch 343, CIFAR-10 Batch 2:  Loss:     1.0263 Validation Accuracy: 0.625000\n",
      "Epoch 343, CIFAR-10 Batch 3:  Loss:     0.9987 Validation Accuracy: 0.675000\n",
      "Epoch 343, CIFAR-10 Batch 4:  Loss:     1.0985 Validation Accuracy: 0.600000\n",
      "Epoch 343, CIFAR-10 Batch 5:  Loss:     1.2695 Validation Accuracy: 0.450000\n",
      "Epoch 344, CIFAR-10 Batch 1:  Loss:     1.3555 Validation Accuracy: 0.450000\n",
      "Epoch 344, CIFAR-10 Batch 2:  Loss:     1.0258 Validation Accuracy: 0.625000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344, CIFAR-10 Batch 3:  Loss:     0.9991 Validation Accuracy: 0.675000\n",
      "Epoch 344, CIFAR-10 Batch 4:  Loss:     1.0985 Validation Accuracy: 0.600000\n",
      "Epoch 344, CIFAR-10 Batch 5:  Loss:     1.2691 Validation Accuracy: 0.450000\n",
      "Epoch 345, CIFAR-10 Batch 1:  Loss:     1.3556 Validation Accuracy: 0.450000\n",
      "Epoch 345, CIFAR-10 Batch 2:  Loss:     1.0257 Validation Accuracy: 0.625000\n",
      "Epoch 345, CIFAR-10 Batch 3:  Loss:     0.9989 Validation Accuracy: 0.675000\n",
      "Epoch 345, CIFAR-10 Batch 4:  Loss:     1.0988 Validation Accuracy: 0.600000\n",
      "Epoch 345, CIFAR-10 Batch 5:  Loss:     1.2687 Validation Accuracy: 0.450000\n",
      "Epoch 346, CIFAR-10 Batch 1:  Loss:     1.3551 Validation Accuracy: 0.450000\n",
      "Epoch 346, CIFAR-10 Batch 2:  Loss:     1.0256 Validation Accuracy: 0.625000\n",
      "Epoch 346, CIFAR-10 Batch 3:  Loss:     0.9985 Validation Accuracy: 0.675000\n",
      "Epoch 346, CIFAR-10 Batch 4:  Loss:     1.0990 Validation Accuracy: 0.600000\n",
      "Epoch 346, CIFAR-10 Batch 5:  Loss:     1.2683 Validation Accuracy: 0.450000\n",
      "Epoch 347, CIFAR-10 Batch 1:  Loss:     1.3557 Validation Accuracy: 0.450000\n",
      "Epoch 347, CIFAR-10 Batch 2:  Loss:     1.0252 Validation Accuracy: 0.625000\n",
      "Epoch 347, CIFAR-10 Batch 3:  Loss:     0.9982 Validation Accuracy: 0.675000\n",
      "Epoch 347, CIFAR-10 Batch 4:  Loss:     1.0987 Validation Accuracy: 0.600000\n",
      "Epoch 347, CIFAR-10 Batch 5:  Loss:     1.2682 Validation Accuracy: 0.450000\n",
      "Epoch 348, CIFAR-10 Batch 1:  Loss:     1.3550 Validation Accuracy: 0.450000\n",
      "Epoch 348, CIFAR-10 Batch 2:  Loss:     1.0250 Validation Accuracy: 0.625000\n",
      "Epoch 348, CIFAR-10 Batch 3:  Loss:     0.9983 Validation Accuracy: 0.675000\n",
      "Epoch 348, CIFAR-10 Batch 4:  Loss:     1.0989 Validation Accuracy: 0.600000\n",
      "Epoch 348, CIFAR-10 Batch 5:  Loss:     1.2673 Validation Accuracy: 0.450000\n",
      "Epoch 349, CIFAR-10 Batch 1:  Loss:     1.3552 Validation Accuracy: 0.450000\n",
      "Epoch 349, CIFAR-10 Batch 2:  Loss:     1.0251 Validation Accuracy: 0.625000\n",
      "Epoch 349, CIFAR-10 Batch 3:  Loss:     0.9980 Validation Accuracy: 0.675000\n",
      "Epoch 349, CIFAR-10 Batch 4:  Loss:     1.0991 Validation Accuracy: 0.600000\n",
      "Epoch 349, CIFAR-10 Batch 5:  Loss:     1.2671 Validation Accuracy: 0.450000\n",
      "Epoch 350, CIFAR-10 Batch 1:  Loss:     1.3553 Validation Accuracy: 0.450000\n",
      "Epoch 350, CIFAR-10 Batch 2:  Loss:     1.0250 Validation Accuracy: 0.650000\n",
      "Epoch 350, CIFAR-10 Batch 3:  Loss:     0.9982 Validation Accuracy: 0.675000\n",
      "Epoch 350, CIFAR-10 Batch 4:  Loss:     1.0988 Validation Accuracy: 0.600000\n",
      "Epoch 350, CIFAR-10 Batch 5:  Loss:     1.2666 Validation Accuracy: 0.450000\n",
      "Epoch 351, CIFAR-10 Batch 1:  Loss:     1.3552 Validation Accuracy: 0.450000\n",
      "Epoch 351, CIFAR-10 Batch 2:  Loss:     1.0254 Validation Accuracy: 0.650000\n",
      "Epoch 351, CIFAR-10 Batch 3:  Loss:     0.9975 Validation Accuracy: 0.675000\n",
      "Epoch 351, CIFAR-10 Batch 4:  Loss:     1.0993 Validation Accuracy: 0.600000\n",
      "Epoch 351, CIFAR-10 Batch 5:  Loss:     1.2670 Validation Accuracy: 0.450000\n",
      "Epoch 352, CIFAR-10 Batch 1:  Loss:     1.3544 Validation Accuracy: 0.450000\n",
      "Epoch 352, CIFAR-10 Batch 2:  Loss:     1.0254 Validation Accuracy: 0.650000\n",
      "Epoch 352, CIFAR-10 Batch 3:  Loss:     0.9978 Validation Accuracy: 0.675000\n",
      "Epoch 352, CIFAR-10 Batch 4:  Loss:     1.0996 Validation Accuracy: 0.600000\n",
      "Epoch 352, CIFAR-10 Batch 5:  Loss:     1.2665 Validation Accuracy: 0.450000\n",
      "Epoch 353, CIFAR-10 Batch 1:  Loss:     1.3543 Validation Accuracy: 0.450000\n",
      "Epoch 353, CIFAR-10 Batch 2:  Loss:     1.0250 Validation Accuracy: 0.650000\n",
      "Epoch 353, CIFAR-10 Batch 3:  Loss:     0.9980 Validation Accuracy: 0.675000\n",
      "Epoch 353, CIFAR-10 Batch 4:  Loss:     1.0996 Validation Accuracy: 0.600000\n",
      "Epoch 353, CIFAR-10 Batch 5:  Loss:     1.2666 Validation Accuracy: 0.450000\n",
      "Epoch 354, CIFAR-10 Batch 1:  Loss:     1.3543 Validation Accuracy: 0.450000\n",
      "Epoch 354, CIFAR-10 Batch 2:  Loss:     1.0252 Validation Accuracy: 0.650000\n",
      "Epoch 354, CIFAR-10 Batch 3:  Loss:     0.9972 Validation Accuracy: 0.675000\n",
      "Epoch 354, CIFAR-10 Batch 4:  Loss:     1.0997 Validation Accuracy: 0.600000\n",
      "Epoch 354, CIFAR-10 Batch 5:  Loss:     1.2662 Validation Accuracy: 0.450000\n",
      "Epoch 355, CIFAR-10 Batch 1:  Loss:     1.3539 Validation Accuracy: 0.450000\n",
      "Epoch 355, CIFAR-10 Batch 2:  Loss:     1.0250 Validation Accuracy: 0.650000\n",
      "Epoch 355, CIFAR-10 Batch 3:  Loss:     0.9979 Validation Accuracy: 0.650000\n",
      "Epoch 355, CIFAR-10 Batch 4:  Loss:     1.0991 Validation Accuracy: 0.600000\n",
      "Epoch 355, CIFAR-10 Batch 5:  Loss:     1.2660 Validation Accuracy: 0.450000\n",
      "Epoch 356, CIFAR-10 Batch 1:  Loss:     1.3541 Validation Accuracy: 0.450000\n",
      "Epoch 356, CIFAR-10 Batch 2:  Loss:     1.0257 Validation Accuracy: 0.650000\n",
      "Epoch 356, CIFAR-10 Batch 3:  Loss:     0.9978 Validation Accuracy: 0.650000\n",
      "Epoch 356, CIFAR-10 Batch 4:  Loss:     1.0994 Validation Accuracy: 0.600000\n",
      "Epoch 356, CIFAR-10 Batch 5:  Loss:     1.2657 Validation Accuracy: 0.450000\n",
      "Epoch 357, CIFAR-10 Batch 1:  Loss:     1.3545 Validation Accuracy: 0.450000\n",
      "Epoch 357, CIFAR-10 Batch 2:  Loss:     1.0250 Validation Accuracy: 0.650000\n",
      "Epoch 357, CIFAR-10 Batch 3:  Loss:     0.9976 Validation Accuracy: 0.650000\n",
      "Epoch 357, CIFAR-10 Batch 4:  Loss:     1.0996 Validation Accuracy: 0.600000\n",
      "Epoch 357, CIFAR-10 Batch 5:  Loss:     1.2655 Validation Accuracy: 0.450000\n",
      "Epoch 358, CIFAR-10 Batch 1:  Loss:     1.3549 Validation Accuracy: 0.450000\n",
      "Epoch 358, CIFAR-10 Batch 2:  Loss:     1.0258 Validation Accuracy: 0.650000\n",
      "Epoch 358, CIFAR-10 Batch 3:  Loss:     0.9976 Validation Accuracy: 0.650000\n",
      "Epoch 358, CIFAR-10 Batch 4:  Loss:     1.0997 Validation Accuracy: 0.600000\n",
      "Epoch 358, CIFAR-10 Batch 5:  Loss:     1.2654 Validation Accuracy: 0.450000\n",
      "Epoch 359, CIFAR-10 Batch 1:  Loss:     1.3536 Validation Accuracy: 0.450000\n",
      "Epoch 359, CIFAR-10 Batch 2:  Loss:     1.0256 Validation Accuracy: 0.650000\n",
      "Epoch 359, CIFAR-10 Batch 3:  Loss:     0.9973 Validation Accuracy: 0.650000\n",
      "Epoch 359, CIFAR-10 Batch 4:  Loss:     1.0999 Validation Accuracy: 0.600000\n",
      "Epoch 359, CIFAR-10 Batch 5:  Loss:     1.2660 Validation Accuracy: 0.450000\n",
      "Epoch 360, CIFAR-10 Batch 1:  Loss:     1.3535 Validation Accuracy: 0.475000\n",
      "Epoch 360, CIFAR-10 Batch 2:  Loss:     1.0252 Validation Accuracy: 0.650000\n",
      "Epoch 360, CIFAR-10 Batch 3:  Loss:     0.9976 Validation Accuracy: 0.650000\n",
      "Epoch 360, CIFAR-10 Batch 4:  Loss:     1.0997 Validation Accuracy: 0.600000\n",
      "Epoch 360, CIFAR-10 Batch 5:  Loss:     1.2657 Validation Accuracy: 0.450000\n",
      "Epoch 361, CIFAR-10 Batch 1:  Loss:     1.3536 Validation Accuracy: 0.475000\n",
      "Epoch 361, CIFAR-10 Batch 2:  Loss:     1.0258 Validation Accuracy: 0.650000\n",
      "Epoch 361, CIFAR-10 Batch 3:  Loss:     0.9976 Validation Accuracy: 0.650000\n",
      "Epoch 361, CIFAR-10 Batch 4:  Loss:     1.1000 Validation Accuracy: 0.600000\n",
      "Epoch 361, CIFAR-10 Batch 5:  Loss:     1.2656 Validation Accuracy: 0.450000\n",
      "Epoch 362, CIFAR-10 Batch 1:  Loss:     1.3533 Validation Accuracy: 0.475000\n",
      "Epoch 362, CIFAR-10 Batch 2:  Loss:     1.0251 Validation Accuracy: 0.650000\n",
      "Epoch 362, CIFAR-10 Batch 3:  Loss:     0.9973 Validation Accuracy: 0.650000\n",
      "Epoch 362, CIFAR-10 Batch 4:  Loss:     1.1001 Validation Accuracy: 0.600000\n",
      "Epoch 362, CIFAR-10 Batch 5:  Loss:     1.2658 Validation Accuracy: 0.450000\n",
      "Epoch 363, CIFAR-10 Batch 1:  Loss:     1.3542 Validation Accuracy: 0.475000\n",
      "Epoch 363, CIFAR-10 Batch 2:  Loss:     1.0253 Validation Accuracy: 0.650000\n",
      "Epoch 363, CIFAR-10 Batch 3:  Loss:     0.9961 Validation Accuracy: 0.650000\n",
      "Epoch 363, CIFAR-10 Batch 4:  Loss:     1.1001 Validation Accuracy: 0.600000\n",
      "Epoch 363, CIFAR-10 Batch 5:  Loss:     1.2657 Validation Accuracy: 0.450000\n",
      "Epoch 364, CIFAR-10 Batch 1:  Loss:     1.3523 Validation Accuracy: 0.475000\n",
      "Epoch 364, CIFAR-10 Batch 2:  Loss:     1.0256 Validation Accuracy: 0.650000\n",
      "Epoch 364, CIFAR-10 Batch 3:  Loss:     0.9956 Validation Accuracy: 0.675000\n",
      "Epoch 364, CIFAR-10 Batch 4:  Loss:     1.0989 Validation Accuracy: 0.600000\n",
      "Epoch 364, CIFAR-10 Batch 5:  Loss:     1.2656 Validation Accuracy: 0.450000\n",
      "Epoch 365, CIFAR-10 Batch 1:  Loss:     1.3534 Validation Accuracy: 0.475000\n",
      "Epoch 365, CIFAR-10 Batch 2:  Loss:     1.0252 Validation Accuracy: 0.650000\n",
      "Epoch 365, CIFAR-10 Batch 3:  Loss:     0.9951 Validation Accuracy: 0.675000\n",
      "Epoch 365, CIFAR-10 Batch 4:  Loss:     1.0989 Validation Accuracy: 0.600000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365, CIFAR-10 Batch 5:  Loss:     1.2658 Validation Accuracy: 0.450000\n",
      "Epoch 366, CIFAR-10 Batch 1:  Loss:     1.3541 Validation Accuracy: 0.475000\n",
      "Epoch 366, CIFAR-10 Batch 2:  Loss:     1.0249 Validation Accuracy: 0.650000\n",
      "Epoch 366, CIFAR-10 Batch 3:  Loss:     0.9946 Validation Accuracy: 0.675000\n",
      "Epoch 366, CIFAR-10 Batch 4:  Loss:     1.0992 Validation Accuracy: 0.625000\n",
      "Epoch 366, CIFAR-10 Batch 5:  Loss:     1.2657 Validation Accuracy: 0.450000\n",
      "Epoch 367, CIFAR-10 Batch 1:  Loss:     1.3535 Validation Accuracy: 0.475000\n",
      "Epoch 367, CIFAR-10 Batch 2:  Loss:     1.0253 Validation Accuracy: 0.650000\n",
      "Epoch 367, CIFAR-10 Batch 3:  Loss:     0.9942 Validation Accuracy: 0.675000\n",
      "Epoch 367, CIFAR-10 Batch 4:  Loss:     1.0990 Validation Accuracy: 0.625000\n",
      "Epoch 367, CIFAR-10 Batch 5:  Loss:     1.2655 Validation Accuracy: 0.450000\n",
      "Epoch 368, CIFAR-10 Batch 1:  Loss:     1.3534 Validation Accuracy: 0.475000\n",
      "Epoch 368, CIFAR-10 Batch 2:  Loss:     1.0254 Validation Accuracy: 0.650000\n",
      "Epoch 368, CIFAR-10 Batch 3:  Loss:     0.9934 Validation Accuracy: 0.675000\n",
      "Epoch 368, CIFAR-10 Batch 4:  Loss:     1.0996 Validation Accuracy: 0.625000\n",
      "Epoch 368, CIFAR-10 Batch 5:  Loss:     1.2656 Validation Accuracy: 0.450000\n",
      "Epoch 369, CIFAR-10 Batch 1:  Loss:     1.3542 Validation Accuracy: 0.475000\n",
      "Epoch 369, CIFAR-10 Batch 2:  Loss:     1.0248 Validation Accuracy: 0.650000\n",
      "Epoch 369, CIFAR-10 Batch 3:  Loss:     0.9930 Validation Accuracy: 0.675000\n",
      "Epoch 369, CIFAR-10 Batch 4:  Loss:     1.0996 Validation Accuracy: 0.625000\n",
      "Epoch 369, CIFAR-10 Batch 5:  Loss:     1.2658 Validation Accuracy: 0.450000\n",
      "Epoch 370, CIFAR-10 Batch 1:  Loss:     1.3550 Validation Accuracy: 0.475000\n",
      "Epoch 370, CIFAR-10 Batch 2:  Loss:     1.0254 Validation Accuracy: 0.650000\n",
      "Epoch 370, CIFAR-10 Batch 3:  Loss:     0.9928 Validation Accuracy: 0.650000\n",
      "Epoch 370, CIFAR-10 Batch 4:  Loss:     1.0993 Validation Accuracy: 0.625000\n",
      "Epoch 370, CIFAR-10 Batch 5:  Loss:     1.2655 Validation Accuracy: 0.450000\n",
      "Epoch 371, CIFAR-10 Batch 1:  Loss:     1.3553 Validation Accuracy: 0.475000\n",
      "Epoch 371, CIFAR-10 Batch 2:  Loss:     1.0258 Validation Accuracy: 0.650000\n",
      "Epoch 371, CIFAR-10 Batch 3:  Loss:     0.9932 Validation Accuracy: 0.675000\n",
      "Epoch 371, CIFAR-10 Batch 4:  Loss:     1.0994 Validation Accuracy: 0.600000\n",
      "Epoch 371, CIFAR-10 Batch 5:  Loss:     1.2651 Validation Accuracy: 0.450000\n",
      "Epoch 372, CIFAR-10 Batch 1:  Loss:     1.3550 Validation Accuracy: 0.475000\n",
      "Epoch 372, CIFAR-10 Batch 2:  Loss:     1.0265 Validation Accuracy: 0.650000\n",
      "Epoch 372, CIFAR-10 Batch 3:  Loss:     0.9928 Validation Accuracy: 0.675000\n",
      "Epoch 372, CIFAR-10 Batch 4:  Loss:     1.0996 Validation Accuracy: 0.600000\n",
      "Epoch 372, CIFAR-10 Batch 5:  Loss:     1.2656 Validation Accuracy: 0.450000\n",
      "Epoch 373, CIFAR-10 Batch 1:  Loss:     1.3553 Validation Accuracy: 0.475000\n",
      "Epoch 373, CIFAR-10 Batch 2:  Loss:     1.0264 Validation Accuracy: 0.675000\n",
      "Epoch 373, CIFAR-10 Batch 3:  Loss:     0.9933 Validation Accuracy: 0.675000\n",
      "Epoch 373, CIFAR-10 Batch 4:  Loss:     1.0985 Validation Accuracy: 0.600000\n",
      "Epoch 373, CIFAR-10 Batch 5:  Loss:     1.2657 Validation Accuracy: 0.450000\n",
      "Epoch 374, CIFAR-10 Batch 1:  Loss:     1.3550 Validation Accuracy: 0.475000\n",
      "Epoch 374, CIFAR-10 Batch 2:  Loss:     1.0265 Validation Accuracy: 0.675000\n",
      "Epoch 374, CIFAR-10 Batch 3:  Loss:     0.9934 Validation Accuracy: 0.650000\n",
      "Epoch 374, CIFAR-10 Batch 4:  Loss:     1.0985 Validation Accuracy: 0.625000\n",
      "Epoch 374, CIFAR-10 Batch 5:  Loss:     1.2660 Validation Accuracy: 0.450000\n",
      "Epoch 375, CIFAR-10 Batch 1:  Loss:     1.3555 Validation Accuracy: 0.475000\n",
      "Epoch 375, CIFAR-10 Batch 2:  Loss:     1.0263 Validation Accuracy: 0.675000\n",
      "Epoch 375, CIFAR-10 Batch 3:  Loss:     0.9924 Validation Accuracy: 0.675000\n",
      "Epoch 375, CIFAR-10 Batch 4:  Loss:     1.0988 Validation Accuracy: 0.600000\n",
      "Epoch 375, CIFAR-10 Batch 5:  Loss:     1.2657 Validation Accuracy: 0.450000\n",
      "Epoch 376, CIFAR-10 Batch 1:  Loss:     1.3555 Validation Accuracy: 0.475000\n",
      "Epoch 376, CIFAR-10 Batch 2:  Loss:     1.0266 Validation Accuracy: 0.675000\n",
      "Epoch 376, CIFAR-10 Batch 3:  Loss:     0.9919 Validation Accuracy: 0.650000\n",
      "Epoch 376, CIFAR-10 Batch 4:  Loss:     1.0990 Validation Accuracy: 0.600000\n",
      "Epoch 376, CIFAR-10 Batch 5:  Loss:     1.2656 Validation Accuracy: 0.450000\n",
      "Epoch 377, CIFAR-10 Batch 1:  Loss:     1.3552 Validation Accuracy: 0.475000\n",
      "Epoch 377, CIFAR-10 Batch 2:  Loss:     1.0267 Validation Accuracy: 0.675000\n",
      "Epoch 377, CIFAR-10 Batch 3:  Loss:     0.9918 Validation Accuracy: 0.675000\n",
      "Epoch 377, CIFAR-10 Batch 4:  Loss:     1.0994 Validation Accuracy: 0.600000\n",
      "Epoch 377, CIFAR-10 Batch 5:  Loss:     1.2659 Validation Accuracy: 0.450000\n",
      "Epoch 378, CIFAR-10 Batch 1:  Loss:     1.3549 Validation Accuracy: 0.475000\n",
      "Epoch 378, CIFAR-10 Batch 2:  Loss:     1.0264 Validation Accuracy: 0.675000\n",
      "Epoch 378, CIFAR-10 Batch 3:  Loss:     0.9917 Validation Accuracy: 0.675000\n",
      "Epoch 378, CIFAR-10 Batch 4:  Loss:     1.0998 Validation Accuracy: 0.600000\n",
      "Epoch 378, CIFAR-10 Batch 5:  Loss:     1.2652 Validation Accuracy: 0.450000\n",
      "Epoch 379, CIFAR-10 Batch 1:  Loss:     1.3553 Validation Accuracy: 0.475000\n",
      "Epoch 379, CIFAR-10 Batch 2:  Loss:     1.0260 Validation Accuracy: 0.675000\n",
      "Epoch 379, CIFAR-10 Batch 3:  Loss:     0.9916 Validation Accuracy: 0.675000\n",
      "Epoch 379, CIFAR-10 Batch 4:  Loss:     1.0994 Validation Accuracy: 0.600000\n",
      "Epoch 379, CIFAR-10 Batch 5:  Loss:     1.2650 Validation Accuracy: 0.450000\n",
      "Epoch 380, CIFAR-10 Batch 1:  Loss:     1.3556 Validation Accuracy: 0.475000\n",
      "Epoch 380, CIFAR-10 Batch 2:  Loss:     1.0262 Validation Accuracy: 0.675000\n",
      "Epoch 380, CIFAR-10 Batch 3:  Loss:     0.9913 Validation Accuracy: 0.675000\n",
      "Epoch 380, CIFAR-10 Batch 4:  Loss:     1.0998 Validation Accuracy: 0.600000\n",
      "Epoch 380, CIFAR-10 Batch 5:  Loss:     1.2652 Validation Accuracy: 0.450000\n",
      "Epoch 381, CIFAR-10 Batch 1:  Loss:     1.3552 Validation Accuracy: 0.475000\n",
      "Epoch 381, CIFAR-10 Batch 2:  Loss:     1.0265 Validation Accuracy: 0.675000\n",
      "Epoch 381, CIFAR-10 Batch 3:  Loss:     0.9911 Validation Accuracy: 0.650000\n",
      "Epoch 381, CIFAR-10 Batch 4:  Loss:     1.1002 Validation Accuracy: 0.575000\n",
      "Epoch 381, CIFAR-10 Batch 5:  Loss:     1.2652 Validation Accuracy: 0.450000\n",
      "Epoch 382, CIFAR-10 Batch 1:  Loss:     1.3549 Validation Accuracy: 0.475000\n",
      "Epoch 382, CIFAR-10 Batch 2:  Loss:     1.0269 Validation Accuracy: 0.675000\n",
      "Epoch 382, CIFAR-10 Batch 3:  Loss:     0.9914 Validation Accuracy: 0.675000\n",
      "Epoch 382, CIFAR-10 Batch 4:  Loss:     1.1003 Validation Accuracy: 0.600000\n",
      "Epoch 382, CIFAR-10 Batch 5:  Loss:     1.2651 Validation Accuracy: 0.450000\n",
      "Epoch 383, CIFAR-10 Batch 1:  Loss:     1.3545 Validation Accuracy: 0.475000\n",
      "Epoch 383, CIFAR-10 Batch 2:  Loss:     1.0277 Validation Accuracy: 0.675000\n",
      "Epoch 383, CIFAR-10 Batch 3:  Loss:     0.9912 Validation Accuracy: 0.650000\n",
      "Epoch 383, CIFAR-10 Batch 4:  Loss:     1.1010 Validation Accuracy: 0.600000\n",
      "Epoch 383, CIFAR-10 Batch 5:  Loss:     1.2651 Validation Accuracy: 0.450000\n",
      "Epoch 384, CIFAR-10 Batch 1:  Loss:     1.3548 Validation Accuracy: 0.475000\n",
      "Epoch 384, CIFAR-10 Batch 2:  Loss:     1.0281 Validation Accuracy: 0.675000\n",
      "Epoch 384, CIFAR-10 Batch 3:  Loss:     0.9911 Validation Accuracy: 0.650000\n",
      "Epoch 384, CIFAR-10 Batch 4:  Loss:     1.1004 Validation Accuracy: 0.600000\n",
      "Epoch 384, CIFAR-10 Batch 5:  Loss:     1.2652 Validation Accuracy: 0.450000\n",
      "Epoch 385, CIFAR-10 Batch 1:  Loss:     1.3543 Validation Accuracy: 0.450000\n",
      "Epoch 385, CIFAR-10 Batch 2:  Loss:     1.0281 Validation Accuracy: 0.675000\n",
      "Epoch 385, CIFAR-10 Batch 3:  Loss:     0.9901 Validation Accuracy: 0.675000\n",
      "Epoch 385, CIFAR-10 Batch 4:  Loss:     1.1005 Validation Accuracy: 0.600000\n",
      "Epoch 385, CIFAR-10 Batch 5:  Loss:     1.2651 Validation Accuracy: 0.450000\n",
      "Epoch 386, CIFAR-10 Batch 1:  Loss:     1.3541 Validation Accuracy: 0.475000\n",
      "Epoch 386, CIFAR-10 Batch 2:  Loss:     1.0278 Validation Accuracy: 0.675000\n",
      "Epoch 386, CIFAR-10 Batch 3:  Loss:     0.9906 Validation Accuracy: 0.675000\n",
      "Epoch 386, CIFAR-10 Batch 4:  Loss:     1.1014 Validation Accuracy: 0.600000\n",
      "Epoch 386, CIFAR-10 Batch 5:  Loss:     1.2653 Validation Accuracy: 0.450000\n",
      "Epoch 387, CIFAR-10 Batch 1:  Loss:     1.3546 Validation Accuracy: 0.475000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387, CIFAR-10 Batch 2:  Loss:     1.0276 Validation Accuracy: 0.675000\n",
      "Epoch 387, CIFAR-10 Batch 3:  Loss:     0.9902 Validation Accuracy: 0.650000\n",
      "Epoch 387, CIFAR-10 Batch 4:  Loss:     1.1012 Validation Accuracy: 0.575000\n",
      "Epoch 387, CIFAR-10 Batch 5:  Loss:     1.2655 Validation Accuracy: 0.450000\n",
      "Epoch 388, CIFAR-10 Batch 1:  Loss:     1.3549 Validation Accuracy: 0.450000\n",
      "Epoch 388, CIFAR-10 Batch 2:  Loss:     1.0279 Validation Accuracy: 0.675000\n",
      "Epoch 388, CIFAR-10 Batch 3:  Loss:     0.9905 Validation Accuracy: 0.675000\n",
      "Epoch 388, CIFAR-10 Batch 4:  Loss:     1.1012 Validation Accuracy: 0.575000\n",
      "Epoch 388, CIFAR-10 Batch 5:  Loss:     1.2653 Validation Accuracy: 0.450000\n",
      "Epoch 389, CIFAR-10 Batch 1:  Loss:     1.3539 Validation Accuracy: 0.475000\n",
      "Epoch 389, CIFAR-10 Batch 2:  Loss:     1.0279 Validation Accuracy: 0.675000\n",
      "Epoch 389, CIFAR-10 Batch 3:  Loss:     0.9891 Validation Accuracy: 0.650000\n",
      "Epoch 389, CIFAR-10 Batch 4:  Loss:     1.1015 Validation Accuracy: 0.575000\n",
      "Epoch 389, CIFAR-10 Batch 5:  Loss:     1.2644 Validation Accuracy: 0.450000\n",
      "Epoch 390, CIFAR-10 Batch 1:  Loss:     1.3544 Validation Accuracy: 0.450000\n",
      "Epoch 390, CIFAR-10 Batch 2:  Loss:     1.0278 Validation Accuracy: 0.675000\n",
      "Epoch 390, CIFAR-10 Batch 3:  Loss:     0.9901 Validation Accuracy: 0.650000\n",
      "Epoch 390, CIFAR-10 Batch 4:  Loss:     1.1011 Validation Accuracy: 0.600000\n",
      "Epoch 390, CIFAR-10 Batch 5:  Loss:     1.2649 Validation Accuracy: 0.450000\n",
      "Epoch 391, CIFAR-10 Batch 1:  Loss:     1.3541 Validation Accuracy: 0.450000\n",
      "Epoch 391, CIFAR-10 Batch 2:  Loss:     1.0277 Validation Accuracy: 0.675000\n",
      "Epoch 391, CIFAR-10 Batch 3:  Loss:     0.9897 Validation Accuracy: 0.650000\n",
      "Epoch 391, CIFAR-10 Batch 4:  Loss:     1.1010 Validation Accuracy: 0.575000\n",
      "Epoch 391, CIFAR-10 Batch 5:  Loss:     1.2642 Validation Accuracy: 0.450000\n",
      "Epoch 392, CIFAR-10 Batch 1:  Loss:     1.3525 Validation Accuracy: 0.450000\n",
      "Epoch 392, CIFAR-10 Batch 2:  Loss:     1.0279 Validation Accuracy: 0.675000\n",
      "Epoch 392, CIFAR-10 Batch 3:  Loss:     0.9890 Validation Accuracy: 0.650000\n",
      "Epoch 392, CIFAR-10 Batch 4:  Loss:     1.1013 Validation Accuracy: 0.575000\n",
      "Epoch 392, CIFAR-10 Batch 5:  Loss:     1.2638 Validation Accuracy: 0.450000\n",
      "Epoch 393, CIFAR-10 Batch 1:  Loss:     1.3532 Validation Accuracy: 0.450000\n",
      "Epoch 393, CIFAR-10 Batch 2:  Loss:     1.0278 Validation Accuracy: 0.675000\n",
      "Epoch 393, CIFAR-10 Batch 3:  Loss:     0.9884 Validation Accuracy: 0.650000\n",
      "Epoch 393, CIFAR-10 Batch 4:  Loss:     1.1017 Validation Accuracy: 0.575000\n",
      "Epoch 393, CIFAR-10 Batch 5:  Loss:     1.2639 Validation Accuracy: 0.450000\n",
      "Epoch 394, CIFAR-10 Batch 1:  Loss:     1.3526 Validation Accuracy: 0.450000\n",
      "Epoch 394, CIFAR-10 Batch 2:  Loss:     1.0278 Validation Accuracy: 0.675000\n",
      "Epoch 394, CIFAR-10 Batch 3:  Loss:     0.9884 Validation Accuracy: 0.650000\n",
      "Epoch 394, CIFAR-10 Batch 4:  Loss:     1.1019 Validation Accuracy: 0.575000\n",
      "Epoch 394, CIFAR-10 Batch 5:  Loss:     1.2636 Validation Accuracy: 0.450000\n",
      "Epoch 395, CIFAR-10 Batch 1:  Loss:     1.3527 Validation Accuracy: 0.450000\n",
      "Epoch 395, CIFAR-10 Batch 2:  Loss:     1.0280 Validation Accuracy: 0.675000\n",
      "Epoch 395, CIFAR-10 Batch 3:  Loss:     0.9875 Validation Accuracy: 0.650000\n",
      "Epoch 395, CIFAR-10 Batch 4:  Loss:     1.1019 Validation Accuracy: 0.575000\n",
      "Epoch 395, CIFAR-10 Batch 5:  Loss:     1.2634 Validation Accuracy: 0.450000\n",
      "Epoch 396, CIFAR-10 Batch 1:  Loss:     1.3527 Validation Accuracy: 0.450000\n",
      "Epoch 396, CIFAR-10 Batch 2:  Loss:     1.0280 Validation Accuracy: 0.675000\n",
      "Epoch 396, CIFAR-10 Batch 3:  Loss:     0.9883 Validation Accuracy: 0.675000\n",
      "Epoch 396, CIFAR-10 Batch 4:  Loss:     1.1018 Validation Accuracy: 0.575000\n",
      "Epoch 396, CIFAR-10 Batch 5:  Loss:     1.2629 Validation Accuracy: 0.450000\n",
      "Epoch 397, CIFAR-10 Batch 1:  Loss:     1.3526 Validation Accuracy: 0.450000\n",
      "Epoch 397, CIFAR-10 Batch 2:  Loss:     1.0282 Validation Accuracy: 0.675000\n",
      "Epoch 397, CIFAR-10 Batch 3:  Loss:     0.9878 Validation Accuracy: 0.650000\n",
      "Epoch 397, CIFAR-10 Batch 4:  Loss:     1.1022 Validation Accuracy: 0.575000\n",
      "Epoch 397, CIFAR-10 Batch 5:  Loss:     1.2629 Validation Accuracy: 0.450000\n",
      "Epoch 398, CIFAR-10 Batch 1:  Loss:     1.3527 Validation Accuracy: 0.450000\n",
      "Epoch 398, CIFAR-10 Batch 2:  Loss:     1.0282 Validation Accuracy: 0.675000\n",
      "Epoch 398, CIFAR-10 Batch 3:  Loss:     0.9880 Validation Accuracy: 0.650000\n",
      "Epoch 398, CIFAR-10 Batch 4:  Loss:     1.1023 Validation Accuracy: 0.575000\n",
      "Epoch 398, CIFAR-10 Batch 5:  Loss:     1.2631 Validation Accuracy: 0.450000\n",
      "Epoch 399, CIFAR-10 Batch 1:  Loss:     1.3530 Validation Accuracy: 0.450000\n",
      "Epoch 399, CIFAR-10 Batch 2:  Loss:     1.0281 Validation Accuracy: 0.675000\n",
      "Epoch 399, CIFAR-10 Batch 3:  Loss:     0.9869 Validation Accuracy: 0.650000\n",
      "Epoch 399, CIFAR-10 Batch 4:  Loss:     1.1020 Validation Accuracy: 0.575000\n",
      "Epoch 399, CIFAR-10 Batch 5:  Loss:     1.2629 Validation Accuracy: 0.450000\n",
      "Epoch 400, CIFAR-10 Batch 1:  Loss:     1.3522 Validation Accuracy: 0.450000\n",
      "Epoch 400, CIFAR-10 Batch 2:  Loss:     1.0279 Validation Accuracy: 0.675000\n",
      "Epoch 400, CIFAR-10 Batch 3:  Loss:     0.9868 Validation Accuracy: 0.650000\n",
      "Epoch 400, CIFAR-10 Batch 4:  Loss:     1.1021 Validation Accuracy: 0.575000\n",
      "Epoch 400, CIFAR-10 Batch 5:  Loss:     1.2625 Validation Accuracy: 0.450000\n",
      "Epoch 401, CIFAR-10 Batch 1:  Loss:     1.3530 Validation Accuracy: 0.450000\n",
      "Epoch 401, CIFAR-10 Batch 2:  Loss:     1.0278 Validation Accuracy: 0.675000\n",
      "Epoch 401, CIFAR-10 Batch 3:  Loss:     0.9866 Validation Accuracy: 0.650000\n",
      "Epoch 401, CIFAR-10 Batch 4:  Loss:     1.1020 Validation Accuracy: 0.575000\n",
      "Epoch 401, CIFAR-10 Batch 5:  Loss:     1.2621 Validation Accuracy: 0.450000\n",
      "Epoch 402, CIFAR-10 Batch 1:  Loss:     1.3538 Validation Accuracy: 0.450000\n",
      "Epoch 402, CIFAR-10 Batch 2:  Loss:     1.0286 Validation Accuracy: 0.675000\n",
      "Epoch 402, CIFAR-10 Batch 3:  Loss:     0.9866 Validation Accuracy: 0.650000\n",
      "Epoch 402, CIFAR-10 Batch 4:  Loss:     1.1022 Validation Accuracy: 0.575000\n",
      "Epoch 402, CIFAR-10 Batch 5:  Loss:     1.2619 Validation Accuracy: 0.450000\n",
      "Epoch 403, CIFAR-10 Batch 1:  Loss:     1.3531 Validation Accuracy: 0.450000\n",
      "Epoch 403, CIFAR-10 Batch 2:  Loss:     1.0281 Validation Accuracy: 0.675000\n",
      "Epoch 403, CIFAR-10 Batch 3:  Loss:     0.9862 Validation Accuracy: 0.650000\n",
      "Epoch 403, CIFAR-10 Batch 4:  Loss:     1.1020 Validation Accuracy: 0.575000\n",
      "Epoch 403, CIFAR-10 Batch 5:  Loss:     1.2616 Validation Accuracy: 0.450000\n",
      "Epoch 404, CIFAR-10 Batch 1:  Loss:     1.3540 Validation Accuracy: 0.450000\n",
      "Epoch 404, CIFAR-10 Batch 2:  Loss:     1.0283 Validation Accuracy: 0.675000\n",
      "Epoch 404, CIFAR-10 Batch 3:  Loss:     0.9863 Validation Accuracy: 0.650000\n",
      "Epoch 404, CIFAR-10 Batch 4:  Loss:     1.1013 Validation Accuracy: 0.575000\n",
      "Epoch 404, CIFAR-10 Batch 5:  Loss:     1.2618 Validation Accuracy: 0.450000\n",
      "Epoch 405, CIFAR-10 Batch 1:  Loss:     1.3536 Validation Accuracy: 0.475000\n",
      "Epoch 405, CIFAR-10 Batch 2:  Loss:     1.0277 Validation Accuracy: 0.675000\n",
      "Epoch 405, CIFAR-10 Batch 3:  Loss:     0.9855 Validation Accuracy: 0.650000\n",
      "Epoch 405, CIFAR-10 Batch 4:  Loss:     1.1015 Validation Accuracy: 0.575000\n",
      "Epoch 405, CIFAR-10 Batch 5:  Loss:     1.2609 Validation Accuracy: 0.450000\n",
      "Epoch 406, CIFAR-10 Batch 1:  Loss:     1.3540 Validation Accuracy: 0.450000\n",
      "Epoch 406, CIFAR-10 Batch 2:  Loss:     1.0278 Validation Accuracy: 0.675000\n",
      "Epoch 406, CIFAR-10 Batch 3:  Loss:     0.9864 Validation Accuracy: 0.650000\n",
      "Epoch 406, CIFAR-10 Batch 4:  Loss:     1.1013 Validation Accuracy: 0.575000\n",
      "Epoch 406, CIFAR-10 Batch 5:  Loss:     1.2610 Validation Accuracy: 0.450000\n",
      "Epoch 407, CIFAR-10 Batch 1:  Loss:     1.3539 Validation Accuracy: 0.475000\n",
      "Epoch 407, CIFAR-10 Batch 2:  Loss:     1.0275 Validation Accuracy: 0.675000\n",
      "Epoch 407, CIFAR-10 Batch 3:  Loss:     0.9866 Validation Accuracy: 0.650000\n",
      "Epoch 407, CIFAR-10 Batch 4:  Loss:     1.1009 Validation Accuracy: 0.575000\n",
      "Epoch 407, CIFAR-10 Batch 5:  Loss:     1.2608 Validation Accuracy: 0.450000\n",
      "Epoch 408, CIFAR-10 Batch 1:  Loss:     1.3530 Validation Accuracy: 0.475000\n",
      "Epoch 408, CIFAR-10 Batch 2:  Loss:     1.0274 Validation Accuracy: 0.675000\n",
      "Epoch 408, CIFAR-10 Batch 3:  Loss:     0.9863 Validation Accuracy: 0.650000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 408, CIFAR-10 Batch 4:  Loss:     1.1005 Validation Accuracy: 0.575000\n",
      "Epoch 408, CIFAR-10 Batch 5:  Loss:     1.2606 Validation Accuracy: 0.450000\n",
      "Epoch 409, CIFAR-10 Batch 1:  Loss:     1.3537 Validation Accuracy: 0.475000\n",
      "Epoch 409, CIFAR-10 Batch 2:  Loss:     1.0268 Validation Accuracy: 0.675000\n",
      "Epoch 409, CIFAR-10 Batch 3:  Loss:     0.9874 Validation Accuracy: 0.650000\n",
      "Epoch 409, CIFAR-10 Batch 4:  Loss:     1.1012 Validation Accuracy: 0.575000\n",
      "Epoch 409, CIFAR-10 Batch 5:  Loss:     1.2603 Validation Accuracy: 0.450000\n",
      "Epoch 410, CIFAR-10 Batch 1:  Loss:     1.3523 Validation Accuracy: 0.475000\n",
      "Epoch 410, CIFAR-10 Batch 2:  Loss:     1.0273 Validation Accuracy: 0.675000\n",
      "Epoch 410, CIFAR-10 Batch 3:  Loss:     0.9864 Validation Accuracy: 0.650000\n",
      "Epoch 410, CIFAR-10 Batch 4:  Loss:     1.1011 Validation Accuracy: 0.575000\n",
      "Epoch 410, CIFAR-10 Batch 5:  Loss:     1.2596 Validation Accuracy: 0.450000\n",
      "Epoch 411, CIFAR-10 Batch 1:  Loss:     1.3525 Validation Accuracy: 0.475000\n",
      "Epoch 411, CIFAR-10 Batch 2:  Loss:     1.0274 Validation Accuracy: 0.675000\n",
      "Epoch 411, CIFAR-10 Batch 3:  Loss:     0.9866 Validation Accuracy: 0.650000\n",
      "Epoch 411, CIFAR-10 Batch 4:  Loss:     1.1009 Validation Accuracy: 0.575000\n",
      "Epoch 411, CIFAR-10 Batch 5:  Loss:     1.2591 Validation Accuracy: 0.450000\n",
      "Epoch 412, CIFAR-10 Batch 1:  Loss:     1.3532 Validation Accuracy: 0.475000\n",
      "Epoch 412, CIFAR-10 Batch 2:  Loss:     1.0270 Validation Accuracy: 0.675000\n",
      "Epoch 412, CIFAR-10 Batch 3:  Loss:     0.9859 Validation Accuracy: 0.650000\n",
      "Epoch 412, CIFAR-10 Batch 4:  Loss:     1.1011 Validation Accuracy: 0.575000\n",
      "Epoch 412, CIFAR-10 Batch 5:  Loss:     1.2588 Validation Accuracy: 0.450000\n",
      "Epoch 413, CIFAR-10 Batch 1:  Loss:     1.3525 Validation Accuracy: 0.475000\n",
      "Epoch 413, CIFAR-10 Batch 2:  Loss:     1.0269 Validation Accuracy: 0.675000\n",
      "Epoch 413, CIFAR-10 Batch 3:  Loss:     0.9860 Validation Accuracy: 0.650000\n",
      "Epoch 413, CIFAR-10 Batch 4:  Loss:     1.1008 Validation Accuracy: 0.575000\n",
      "Epoch 413, CIFAR-10 Batch 5:  Loss:     1.2587 Validation Accuracy: 0.450000\n",
      "Epoch 414, CIFAR-10 Batch 1:  Loss:     1.3531 Validation Accuracy: 0.475000\n",
      "Epoch 414, CIFAR-10 Batch 2:  Loss:     1.0266 Validation Accuracy: 0.675000\n",
      "Epoch 414, CIFAR-10 Batch 3:  Loss:     0.9854 Validation Accuracy: 0.650000\n",
      "Epoch 414, CIFAR-10 Batch 4:  Loss:     1.1010 Validation Accuracy: 0.575000\n",
      "Epoch 414, CIFAR-10 Batch 5:  Loss:     1.2583 Validation Accuracy: 0.450000\n",
      "Epoch 415, CIFAR-10 Batch 1:  Loss:     1.3526 Validation Accuracy: 0.475000\n",
      "Epoch 415, CIFAR-10 Batch 2:  Loss:     1.0264 Validation Accuracy: 0.675000\n",
      "Epoch 415, CIFAR-10 Batch 3:  Loss:     0.9852 Validation Accuracy: 0.650000\n",
      "Epoch 415, CIFAR-10 Batch 4:  Loss:     1.1011 Validation Accuracy: 0.575000\n",
      "Epoch 415, CIFAR-10 Batch 5:  Loss:     1.2578 Validation Accuracy: 0.450000\n",
      "Epoch 416, CIFAR-10 Batch 1:  Loss:     1.3528 Validation Accuracy: 0.475000\n",
      "Epoch 416, CIFAR-10 Batch 2:  Loss:     1.0263 Validation Accuracy: 0.675000\n",
      "Epoch 416, CIFAR-10 Batch 3:  Loss:     0.9848 Validation Accuracy: 0.650000\n",
      "Epoch 416, CIFAR-10 Batch 4:  Loss:     1.1007 Validation Accuracy: 0.575000\n",
      "Epoch 416, CIFAR-10 Batch 5:  Loss:     1.2574 Validation Accuracy: 0.450000\n",
      "Epoch 417, CIFAR-10 Batch 1:  Loss:     1.3520 Validation Accuracy: 0.475000\n",
      "Epoch 417, CIFAR-10 Batch 2:  Loss:     1.0261 Validation Accuracy: 0.675000\n",
      "Epoch 417, CIFAR-10 Batch 3:  Loss:     0.9849 Validation Accuracy: 0.650000\n",
      "Epoch 417, CIFAR-10 Batch 4:  Loss:     1.1004 Validation Accuracy: 0.575000\n",
      "Epoch 417, CIFAR-10 Batch 5:  Loss:     1.2572 Validation Accuracy: 0.450000\n",
      "Epoch 418, CIFAR-10 Batch 1:  Loss:     1.3523 Validation Accuracy: 0.475000\n",
      "Epoch 418, CIFAR-10 Batch 2:  Loss:     1.0263 Validation Accuracy: 0.675000\n",
      "Epoch 418, CIFAR-10 Batch 3:  Loss:     0.9842 Validation Accuracy: 0.650000\n",
      "Epoch 418, CIFAR-10 Batch 4:  Loss:     1.1005 Validation Accuracy: 0.575000\n",
      "Epoch 418, CIFAR-10 Batch 5:  Loss:     1.2566 Validation Accuracy: 0.450000\n",
      "Epoch 419, CIFAR-10 Batch 1:  Loss:     1.3524 Validation Accuracy: 0.475000\n",
      "Epoch 419, CIFAR-10 Batch 2:  Loss:     1.0260 Validation Accuracy: 0.675000\n",
      "Epoch 419, CIFAR-10 Batch 3:  Loss:     0.9841 Validation Accuracy: 0.650000\n",
      "Epoch 419, CIFAR-10 Batch 4:  Loss:     1.1000 Validation Accuracy: 0.575000\n",
      "Epoch 419, CIFAR-10 Batch 5:  Loss:     1.2562 Validation Accuracy: 0.450000\n",
      "Epoch 420, CIFAR-10 Batch 1:  Loss:     1.3523 Validation Accuracy: 0.475000\n",
      "Epoch 420, CIFAR-10 Batch 2:  Loss:     1.0260 Validation Accuracy: 0.675000\n",
      "Epoch 420, CIFAR-10 Batch 3:  Loss:     0.9842 Validation Accuracy: 0.650000\n",
      "Epoch 420, CIFAR-10 Batch 4:  Loss:     1.1000 Validation Accuracy: 0.600000\n",
      "Epoch 420, CIFAR-10 Batch 5:  Loss:     1.2559 Validation Accuracy: 0.450000\n",
      "Epoch 421, CIFAR-10 Batch 1:  Loss:     1.3519 Validation Accuracy: 0.475000\n",
      "Epoch 421, CIFAR-10 Batch 2:  Loss:     1.0254 Validation Accuracy: 0.675000\n",
      "Epoch 421, CIFAR-10 Batch 3:  Loss:     0.9840 Validation Accuracy: 0.650000\n",
      "Epoch 421, CIFAR-10 Batch 4:  Loss:     1.0993 Validation Accuracy: 0.575000\n",
      "Epoch 421, CIFAR-10 Batch 5:  Loss:     1.2554 Validation Accuracy: 0.450000\n",
      "Epoch 422, CIFAR-10 Batch 1:  Loss:     1.3509 Validation Accuracy: 0.475000\n",
      "Epoch 422, CIFAR-10 Batch 2:  Loss:     1.0255 Validation Accuracy: 0.675000\n",
      "Epoch 422, CIFAR-10 Batch 3:  Loss:     0.9842 Validation Accuracy: 0.650000\n",
      "Epoch 422, CIFAR-10 Batch 4:  Loss:     1.0993 Validation Accuracy: 0.575000\n",
      "Epoch 422, CIFAR-10 Batch 5:  Loss:     1.2551 Validation Accuracy: 0.450000\n",
      "Epoch 423, CIFAR-10 Batch 1:  Loss:     1.3510 Validation Accuracy: 0.475000\n",
      "Epoch 423, CIFAR-10 Batch 2:  Loss:     1.0251 Validation Accuracy: 0.675000\n",
      "Epoch 423, CIFAR-10 Batch 3:  Loss:     0.9852 Validation Accuracy: 0.650000\n",
      "Epoch 423, CIFAR-10 Batch 4:  Loss:     1.0992 Validation Accuracy: 0.575000\n",
      "Epoch 423, CIFAR-10 Batch 5:  Loss:     1.2552 Validation Accuracy: 0.450000\n",
      "Epoch 424, CIFAR-10 Batch 1:  Loss:     1.3510 Validation Accuracy: 0.475000\n",
      "Epoch 424, CIFAR-10 Batch 2:  Loss:     1.0253 Validation Accuracy: 0.675000\n",
      "Epoch 424, CIFAR-10 Batch 3:  Loss:     0.9847 Validation Accuracy: 0.650000\n",
      "Epoch 424, CIFAR-10 Batch 4:  Loss:     1.0992 Validation Accuracy: 0.600000\n",
      "Epoch 424, CIFAR-10 Batch 5:  Loss:     1.2549 Validation Accuracy: 0.450000\n",
      "Epoch 425, CIFAR-10 Batch 1:  Loss:     1.3507 Validation Accuracy: 0.475000\n",
      "Epoch 425, CIFAR-10 Batch 2:  Loss:     1.0249 Validation Accuracy: 0.675000\n",
      "Epoch 425, CIFAR-10 Batch 3:  Loss:     0.9844 Validation Accuracy: 0.650000\n",
      "Epoch 425, CIFAR-10 Batch 4:  Loss:     1.0988 Validation Accuracy: 0.600000\n",
      "Epoch 425, CIFAR-10 Batch 5:  Loss:     1.2547 Validation Accuracy: 0.450000\n",
      "Epoch 426, CIFAR-10 Batch 1:  Loss:     1.3503 Validation Accuracy: 0.475000\n",
      "Epoch 426, CIFAR-10 Batch 2:  Loss:     1.0248 Validation Accuracy: 0.675000\n",
      "Epoch 426, CIFAR-10 Batch 3:  Loss:     0.9850 Validation Accuracy: 0.650000\n",
      "Epoch 426, CIFAR-10 Batch 4:  Loss:     1.0988 Validation Accuracy: 0.575000\n",
      "Epoch 426, CIFAR-10 Batch 5:  Loss:     1.2549 Validation Accuracy: 0.450000\n",
      "Epoch 427, CIFAR-10 Batch 1:  Loss:     1.3506 Validation Accuracy: 0.475000\n",
      "Epoch 427, CIFAR-10 Batch 2:  Loss:     1.0249 Validation Accuracy: 0.675000\n",
      "Epoch 427, CIFAR-10 Batch 3:  Loss:     0.9849 Validation Accuracy: 0.650000\n",
      "Epoch 427, CIFAR-10 Batch 4:  Loss:     1.0987 Validation Accuracy: 0.575000\n",
      "Epoch 427, CIFAR-10 Batch 5:  Loss:     1.2542 Validation Accuracy: 0.450000\n",
      "Epoch 428, CIFAR-10 Batch 1:  Loss:     1.3502 Validation Accuracy: 0.475000\n",
      "Epoch 428, CIFAR-10 Batch 2:  Loss:     1.0247 Validation Accuracy: 0.675000\n",
      "Epoch 428, CIFAR-10 Batch 3:  Loss:     0.9849 Validation Accuracy: 0.650000\n",
      "Epoch 428, CIFAR-10 Batch 4:  Loss:     1.0984 Validation Accuracy: 0.600000\n",
      "Epoch 428, CIFAR-10 Batch 5:  Loss:     1.2537 Validation Accuracy: 0.450000\n",
      "Epoch 429, CIFAR-10 Batch 1:  Loss:     1.3506 Validation Accuracy: 0.475000\n",
      "Epoch 429, CIFAR-10 Batch 2:  Loss:     1.0243 Validation Accuracy: 0.675000\n",
      "Epoch 429, CIFAR-10 Batch 3:  Loss:     0.9851 Validation Accuracy: 0.650000\n",
      "Epoch 429, CIFAR-10 Batch 4:  Loss:     1.0984 Validation Accuracy: 0.600000\n",
      "Epoch 429, CIFAR-10 Batch 5:  Loss:     1.2538 Validation Accuracy: 0.450000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 430, CIFAR-10 Batch 1:  Loss:     1.3505 Validation Accuracy: 0.475000\n",
      "Epoch 430, CIFAR-10 Batch 2:  Loss:     1.0241 Validation Accuracy: 0.675000\n",
      "Epoch 430, CIFAR-10 Batch 3:  Loss:     0.9847 Validation Accuracy: 0.650000\n",
      "Epoch 430, CIFAR-10 Batch 4:  Loss:     1.0981 Validation Accuracy: 0.575000\n",
      "Epoch 430, CIFAR-10 Batch 5:  Loss:     1.2532 Validation Accuracy: 0.450000\n",
      "Epoch 431, CIFAR-10 Batch 1:  Loss:     1.3501 Validation Accuracy: 0.475000\n",
      "Epoch 431, CIFAR-10 Batch 2:  Loss:     1.0244 Validation Accuracy: 0.675000\n",
      "Epoch 431, CIFAR-10 Batch 3:  Loss:     0.9845 Validation Accuracy: 0.650000\n",
      "Epoch 431, CIFAR-10 Batch 4:  Loss:     1.0978 Validation Accuracy: 0.600000\n",
      "Epoch 431, CIFAR-10 Batch 5:  Loss:     1.2534 Validation Accuracy: 0.450000\n",
      "Epoch 432, CIFAR-10 Batch 1:  Loss:     1.3503 Validation Accuracy: 0.475000\n",
      "Epoch 432, CIFAR-10 Batch 2:  Loss:     1.0241 Validation Accuracy: 0.675000\n",
      "Epoch 432, CIFAR-10 Batch 3:  Loss:     0.9842 Validation Accuracy: 0.650000\n",
      "Epoch 432, CIFAR-10 Batch 4:  Loss:     1.0977 Validation Accuracy: 0.575000\n",
      "Epoch 432, CIFAR-10 Batch 5:  Loss:     1.2533 Validation Accuracy: 0.450000\n",
      "Epoch 433, CIFAR-10 Batch 1:  Loss:     1.3497 Validation Accuracy: 0.475000\n",
      "Epoch 433, CIFAR-10 Batch 2:  Loss:     1.0246 Validation Accuracy: 0.675000\n",
      "Epoch 433, CIFAR-10 Batch 3:  Loss:     0.9840 Validation Accuracy: 0.650000\n",
      "Epoch 433, CIFAR-10 Batch 4:  Loss:     1.0978 Validation Accuracy: 0.575000\n",
      "Epoch 433, CIFAR-10 Batch 5:  Loss:     1.2532 Validation Accuracy: 0.450000\n",
      "Epoch 434, CIFAR-10 Batch 1:  Loss:     1.3500 Validation Accuracy: 0.475000\n",
      "Epoch 434, CIFAR-10 Batch 2:  Loss:     1.0242 Validation Accuracy: 0.675000\n",
      "Epoch 434, CIFAR-10 Batch 3:  Loss:     0.9844 Validation Accuracy: 0.650000\n",
      "Epoch 434, CIFAR-10 Batch 4:  Loss:     1.0976 Validation Accuracy: 0.600000\n",
      "Epoch 434, CIFAR-10 Batch 5:  Loss:     1.2530 Validation Accuracy: 0.450000\n",
      "Epoch 435, CIFAR-10 Batch 1:  Loss:     1.3501 Validation Accuracy: 0.475000\n",
      "Epoch 435, CIFAR-10 Batch 2:  Loss:     1.0240 Validation Accuracy: 0.650000\n",
      "Epoch 435, CIFAR-10 Batch 3:  Loss:     0.9840 Validation Accuracy: 0.650000\n",
      "Epoch 435, CIFAR-10 Batch 4:  Loss:     1.0974 Validation Accuracy: 0.575000\n",
      "Epoch 435, CIFAR-10 Batch 5:  Loss:     1.2535 Validation Accuracy: 0.450000\n",
      "Epoch 436, CIFAR-10 Batch 1:  Loss:     1.3507 Validation Accuracy: 0.475000\n",
      "Epoch 436, CIFAR-10 Batch 2:  Loss:     1.0240 Validation Accuracy: 0.675000\n",
      "Epoch 436, CIFAR-10 Batch 3:  Loss:     0.9844 Validation Accuracy: 0.650000\n",
      "Epoch 436, CIFAR-10 Batch 4:  Loss:     1.0970 Validation Accuracy: 0.575000\n",
      "Epoch 436, CIFAR-10 Batch 5:  Loss:     1.2538 Validation Accuracy: 0.450000\n",
      "Epoch 437, CIFAR-10 Batch 1:  Loss:     1.3504 Validation Accuracy: 0.475000\n",
      "Epoch 437, CIFAR-10 Batch 2:  Loss:     1.0233 Validation Accuracy: 0.675000\n",
      "Epoch 437, CIFAR-10 Batch 3:  Loss:     0.9845 Validation Accuracy: 0.650000\n",
      "Epoch 437, CIFAR-10 Batch 4:  Loss:     1.0971 Validation Accuracy: 0.575000\n",
      "Epoch 437, CIFAR-10 Batch 5:  Loss:     1.2534 Validation Accuracy: 0.450000\n",
      "Epoch 438, CIFAR-10 Batch 1:  Loss:     1.3500 Validation Accuracy: 0.500000\n",
      "Epoch 438, CIFAR-10 Batch 2:  Loss:     1.0232 Validation Accuracy: 0.675000\n",
      "Epoch 438, CIFAR-10 Batch 3:  Loss:     0.9849 Validation Accuracy: 0.650000\n",
      "Epoch 438, CIFAR-10 Batch 4:  Loss:     1.0966 Validation Accuracy: 0.575000\n",
      "Epoch 438, CIFAR-10 Batch 5:  Loss:     1.2537 Validation Accuracy: 0.450000\n",
      "Epoch 439, CIFAR-10 Batch 1:  Loss:     1.3497 Validation Accuracy: 0.500000\n",
      "Epoch 439, CIFAR-10 Batch 2:  Loss:     1.0232 Validation Accuracy: 0.650000\n",
      "Epoch 439, CIFAR-10 Batch 3:  Loss:     0.9840 Validation Accuracy: 0.650000\n",
      "Epoch 439, CIFAR-10 Batch 4:  Loss:     1.0965 Validation Accuracy: 0.575000\n",
      "Epoch 439, CIFAR-10 Batch 5:  Loss:     1.2531 Validation Accuracy: 0.450000\n",
      "Epoch 440, CIFAR-10 Batch 1:  Loss:     1.3490 Validation Accuracy: 0.475000\n",
      "Epoch 440, CIFAR-10 Batch 2:  Loss:     1.0230 Validation Accuracy: 0.675000\n",
      "Epoch 440, CIFAR-10 Batch 3:  Loss:     0.9846 Validation Accuracy: 0.650000\n",
      "Epoch 440, CIFAR-10 Batch 4:  Loss:     1.0961 Validation Accuracy: 0.575000\n",
      "Epoch 440, CIFAR-10 Batch 5:  Loss:     1.2534 Validation Accuracy: 0.450000\n",
      "Epoch 441, CIFAR-10 Batch 1:  Loss:     1.3489 Validation Accuracy: 0.500000\n",
      "Epoch 441, CIFAR-10 Batch 2:  Loss:     1.0231 Validation Accuracy: 0.650000\n",
      "Epoch 441, CIFAR-10 Batch 3:  Loss:     0.9841 Validation Accuracy: 0.650000\n",
      "Epoch 441, CIFAR-10 Batch 4:  Loss:     1.0961 Validation Accuracy: 0.575000\n",
      "Epoch 441, CIFAR-10 Batch 5:  Loss:     1.2529 Validation Accuracy: 0.450000\n",
      "Epoch 442, CIFAR-10 Batch 1:  Loss:     1.3491 Validation Accuracy: 0.500000\n",
      "Epoch 442, CIFAR-10 Batch 2:  Loss:     1.0225 Validation Accuracy: 0.700000\n",
      "Epoch 442, CIFAR-10 Batch 3:  Loss:     0.9843 Validation Accuracy: 0.650000\n",
      "Epoch 442, CIFAR-10 Batch 4:  Loss:     1.0959 Validation Accuracy: 0.575000\n",
      "Epoch 442, CIFAR-10 Batch 5:  Loss:     1.2531 Validation Accuracy: 0.450000\n",
      "Epoch 443, CIFAR-10 Batch 1:  Loss:     1.3488 Validation Accuracy: 0.500000\n",
      "Epoch 443, CIFAR-10 Batch 2:  Loss:     1.0228 Validation Accuracy: 0.650000\n",
      "Epoch 443, CIFAR-10 Batch 3:  Loss:     0.9843 Validation Accuracy: 0.650000\n",
      "Epoch 443, CIFAR-10 Batch 4:  Loss:     1.0955 Validation Accuracy: 0.575000\n",
      "Epoch 443, CIFAR-10 Batch 5:  Loss:     1.2534 Validation Accuracy: 0.475000\n",
      "Epoch 444, CIFAR-10 Batch 1:  Loss:     1.3495 Validation Accuracy: 0.500000\n",
      "Epoch 444, CIFAR-10 Batch 2:  Loss:     1.0224 Validation Accuracy: 0.700000\n",
      "Epoch 444, CIFAR-10 Batch 3:  Loss:     0.9844 Validation Accuracy: 0.650000\n",
      "Epoch 444, CIFAR-10 Batch 4:  Loss:     1.0954 Validation Accuracy: 0.575000\n",
      "Epoch 444, CIFAR-10 Batch 5:  Loss:     1.2530 Validation Accuracy: 0.450000\n",
      "Epoch 445, CIFAR-10 Batch 1:  Loss:     1.3483 Validation Accuracy: 0.500000\n",
      "Epoch 445, CIFAR-10 Batch 2:  Loss:     1.0224 Validation Accuracy: 0.675000\n",
      "Epoch 445, CIFAR-10 Batch 3:  Loss:     0.9838 Validation Accuracy: 0.625000\n",
      "Epoch 445, CIFAR-10 Batch 4:  Loss:     1.0955 Validation Accuracy: 0.600000\n",
      "Epoch 445, CIFAR-10 Batch 5:  Loss:     1.2530 Validation Accuracy: 0.475000\n",
      "Epoch 446, CIFAR-10 Batch 1:  Loss:     1.3498 Validation Accuracy: 0.500000\n",
      "Epoch 446, CIFAR-10 Batch 2:  Loss:     1.0225 Validation Accuracy: 0.700000\n",
      "Epoch 446, CIFAR-10 Batch 3:  Loss:     0.9838 Validation Accuracy: 0.650000\n",
      "Epoch 446, CIFAR-10 Batch 4:  Loss:     1.0959 Validation Accuracy: 0.600000\n",
      "Epoch 446, CIFAR-10 Batch 5:  Loss:     1.2530 Validation Accuracy: 0.475000\n",
      "Epoch 447, CIFAR-10 Batch 1:  Loss:     1.3494 Validation Accuracy: 0.500000\n",
      "Epoch 447, CIFAR-10 Batch 2:  Loss:     1.0224 Validation Accuracy: 0.675000\n",
      "Epoch 447, CIFAR-10 Batch 3:  Loss:     0.9834 Validation Accuracy: 0.650000\n",
      "Epoch 447, CIFAR-10 Batch 4:  Loss:     1.0960 Validation Accuracy: 0.600000\n",
      "Epoch 447, CIFAR-10 Batch 5:  Loss:     1.2529 Validation Accuracy: 0.475000\n",
      "Epoch 448, CIFAR-10 Batch 1:  Loss:     1.3498 Validation Accuracy: 0.500000\n",
      "Epoch 448, CIFAR-10 Batch 2:  Loss:     1.0224 Validation Accuracy: 0.675000\n",
      "Epoch 448, CIFAR-10 Batch 3:  Loss:     0.9832 Validation Accuracy: 0.650000\n",
      "Epoch 448, CIFAR-10 Batch 4:  Loss:     1.0960 Validation Accuracy: 0.600000\n",
      "Epoch 448, CIFAR-10 Batch 5:  Loss:     1.2528 Validation Accuracy: 0.450000\n",
      "Epoch 449, CIFAR-10 Batch 1:  Loss:     1.3496 Validation Accuracy: 0.500000\n",
      "Epoch 449, CIFAR-10 Batch 2:  Loss:     1.0214 Validation Accuracy: 0.675000\n",
      "Epoch 449, CIFAR-10 Batch 3:  Loss:     0.9833 Validation Accuracy: 0.650000\n",
      "Epoch 449, CIFAR-10 Batch 4:  Loss:     1.0965 Validation Accuracy: 0.600000\n",
      "Epoch 449, CIFAR-10 Batch 5:  Loss:     1.2526 Validation Accuracy: 0.450000\n",
      "Epoch 450, CIFAR-10 Batch 1:  Loss:     1.3488 Validation Accuracy: 0.500000\n",
      "Epoch 450, CIFAR-10 Batch 2:  Loss:     1.0217 Validation Accuracy: 0.675000\n",
      "Epoch 450, CIFAR-10 Batch 3:  Loss:     0.9832 Validation Accuracy: 0.650000\n",
      "Epoch 450, CIFAR-10 Batch 4:  Loss:     1.0962 Validation Accuracy: 0.600000\n",
      "Epoch 450, CIFAR-10 Batch 5:  Loss:     1.2532 Validation Accuracy: 0.475000\n",
      "Epoch 451, CIFAR-10 Batch 1:  Loss:     1.3492 Validation Accuracy: 0.500000\n",
      "Epoch 451, CIFAR-10 Batch 2:  Loss:     1.0217 Validation Accuracy: 0.700000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451, CIFAR-10 Batch 3:  Loss:     0.9829 Validation Accuracy: 0.650000\n",
      "Epoch 451, CIFAR-10 Batch 4:  Loss:     1.0964 Validation Accuracy: 0.600000\n",
      "Epoch 451, CIFAR-10 Batch 5:  Loss:     1.2529 Validation Accuracy: 0.475000\n",
      "Epoch 452, CIFAR-10 Batch 1:  Loss:     1.3493 Validation Accuracy: 0.500000\n",
      "Epoch 452, CIFAR-10 Batch 2:  Loss:     1.0213 Validation Accuracy: 0.700000\n",
      "Epoch 452, CIFAR-10 Batch 3:  Loss:     0.9833 Validation Accuracy: 0.650000\n",
      "Epoch 452, CIFAR-10 Batch 4:  Loss:     1.0965 Validation Accuracy: 0.600000\n",
      "Epoch 452, CIFAR-10 Batch 5:  Loss:     1.2531 Validation Accuracy: 0.475000\n",
      "Epoch 453, CIFAR-10 Batch 1:  Loss:     1.3488 Validation Accuracy: 0.500000\n",
      "Epoch 453, CIFAR-10 Batch 2:  Loss:     1.0215 Validation Accuracy: 0.675000\n",
      "Epoch 453, CIFAR-10 Batch 3:  Loss:     0.9829 Validation Accuracy: 0.650000\n",
      "Epoch 453, CIFAR-10 Batch 4:  Loss:     1.0965 Validation Accuracy: 0.600000\n",
      "Epoch 453, CIFAR-10 Batch 5:  Loss:     1.2530 Validation Accuracy: 0.475000\n",
      "Epoch 454, CIFAR-10 Batch 1:  Loss:     1.3492 Validation Accuracy: 0.500000\n",
      "Epoch 454, CIFAR-10 Batch 2:  Loss:     1.0210 Validation Accuracy: 0.675000\n",
      "Epoch 454, CIFAR-10 Batch 3:  Loss:     0.9827 Validation Accuracy: 0.650000\n",
      "Epoch 454, CIFAR-10 Batch 4:  Loss:     1.0963 Validation Accuracy: 0.600000\n",
      "Epoch 454, CIFAR-10 Batch 5:  Loss:     1.2530 Validation Accuracy: 0.475000\n",
      "Epoch 455, CIFAR-10 Batch 1:  Loss:     1.3494 Validation Accuracy: 0.500000\n",
      "Epoch 455, CIFAR-10 Batch 2:  Loss:     1.0214 Validation Accuracy: 0.675000\n",
      "Epoch 455, CIFAR-10 Batch 3:  Loss:     0.9823 Validation Accuracy: 0.650000\n",
      "Epoch 455, CIFAR-10 Batch 4:  Loss:     1.0963 Validation Accuracy: 0.600000\n",
      "Epoch 455, CIFAR-10 Batch 5:  Loss:     1.2528 Validation Accuracy: 0.475000\n",
      "Epoch 456, CIFAR-10 Batch 1:  Loss:     1.3483 Validation Accuracy: 0.500000\n",
      "Epoch 456, CIFAR-10 Batch 2:  Loss:     1.0213 Validation Accuracy: 0.675000\n",
      "Epoch 456, CIFAR-10 Batch 3:  Loss:     0.9820 Validation Accuracy: 0.650000\n",
      "Epoch 456, CIFAR-10 Batch 4:  Loss:     1.0965 Validation Accuracy: 0.600000\n",
      "Epoch 456, CIFAR-10 Batch 5:  Loss:     1.2520 Validation Accuracy: 0.475000\n",
      "Epoch 457, CIFAR-10 Batch 1:  Loss:     1.3491 Validation Accuracy: 0.500000\n",
      "Epoch 457, CIFAR-10 Batch 2:  Loss:     1.0211 Validation Accuracy: 0.675000\n",
      "Epoch 457, CIFAR-10 Batch 3:  Loss:     0.9821 Validation Accuracy: 0.650000\n",
      "Epoch 457, CIFAR-10 Batch 4:  Loss:     1.0965 Validation Accuracy: 0.600000\n",
      "Epoch 457, CIFAR-10 Batch 5:  Loss:     1.2522 Validation Accuracy: 0.475000\n",
      "Epoch 458, CIFAR-10 Batch 1:  Loss:     1.3483 Validation Accuracy: 0.500000\n",
      "Epoch 458, CIFAR-10 Batch 2:  Loss:     1.0211 Validation Accuracy: 0.675000\n",
      "Epoch 458, CIFAR-10 Batch 3:  Loss:     0.9821 Validation Accuracy: 0.650000\n",
      "Epoch 458, CIFAR-10 Batch 4:  Loss:     1.0963 Validation Accuracy: 0.600000\n",
      "Epoch 458, CIFAR-10 Batch 5:  Loss:     1.2516 Validation Accuracy: 0.475000\n",
      "Epoch 459, CIFAR-10 Batch 1:  Loss:     1.3484 Validation Accuracy: 0.500000\n",
      "Epoch 459, CIFAR-10 Batch 2:  Loss:     1.0210 Validation Accuracy: 0.675000\n",
      "Epoch 459, CIFAR-10 Batch 3:  Loss:     0.9823 Validation Accuracy: 0.650000\n",
      "Epoch 459, CIFAR-10 Batch 4:  Loss:     1.0963 Validation Accuracy: 0.600000\n",
      "Epoch 459, CIFAR-10 Batch 5:  Loss:     1.2516 Validation Accuracy: 0.475000\n",
      "Epoch 460, CIFAR-10 Batch 1:  Loss:     1.3483 Validation Accuracy: 0.500000\n",
      "Epoch 460, CIFAR-10 Batch 2:  Loss:     1.0211 Validation Accuracy: 0.675000\n",
      "Epoch 460, CIFAR-10 Batch 3:  Loss:     0.9814 Validation Accuracy: 0.650000\n",
      "Epoch 460, CIFAR-10 Batch 4:  Loss:     1.0965 Validation Accuracy: 0.600000\n",
      "Epoch 460, CIFAR-10 Batch 5:  Loss:     1.2510 Validation Accuracy: 0.475000\n",
      "Epoch 461, CIFAR-10 Batch 1:  Loss:     1.3484 Validation Accuracy: 0.500000\n",
      "Epoch 461, CIFAR-10 Batch 2:  Loss:     1.0208 Validation Accuracy: 0.675000\n",
      "Epoch 461, CIFAR-10 Batch 3:  Loss:     0.9816 Validation Accuracy: 0.625000\n",
      "Epoch 461, CIFAR-10 Batch 4:  Loss:     1.0963 Validation Accuracy: 0.600000\n",
      "Epoch 461, CIFAR-10 Batch 5:  Loss:     1.2509 Validation Accuracy: 0.475000\n",
      "Epoch 462, CIFAR-10 Batch 1:  Loss:     1.3476 Validation Accuracy: 0.500000\n",
      "Epoch 462, CIFAR-10 Batch 2:  Loss:     1.0209 Validation Accuracy: 0.675000\n",
      "Epoch 462, CIFAR-10 Batch 3:  Loss:     0.9810 Validation Accuracy: 0.625000\n",
      "Epoch 462, CIFAR-10 Batch 4:  Loss:     1.0960 Validation Accuracy: 0.600000\n",
      "Epoch 462, CIFAR-10 Batch 5:  Loss:     1.2506 Validation Accuracy: 0.475000\n",
      "Epoch 463, CIFAR-10 Batch 1:  Loss:     1.3483 Validation Accuracy: 0.500000\n",
      "Epoch 463, CIFAR-10 Batch 2:  Loss:     1.0208 Validation Accuracy: 0.675000\n",
      "Epoch 463, CIFAR-10 Batch 3:  Loss:     0.9809 Validation Accuracy: 0.650000\n",
      "Epoch 463, CIFAR-10 Batch 4:  Loss:     1.0961 Validation Accuracy: 0.600000\n",
      "Epoch 463, CIFAR-10 Batch 5:  Loss:     1.2504 Validation Accuracy: 0.475000\n",
      "Epoch 464, CIFAR-10 Batch 1:  Loss:     1.3487 Validation Accuracy: 0.500000\n",
      "Epoch 464, CIFAR-10 Batch 2:  Loss:     1.0212 Validation Accuracy: 0.675000\n",
      "Epoch 464, CIFAR-10 Batch 3:  Loss:     0.9810 Validation Accuracy: 0.650000\n",
      "Epoch 464, CIFAR-10 Batch 4:  Loss:     1.0959 Validation Accuracy: 0.600000\n",
      "Epoch 464, CIFAR-10 Batch 5:  Loss:     1.2503 Validation Accuracy: 0.475000\n",
      "Epoch 465, CIFAR-10 Batch 1:  Loss:     1.3479 Validation Accuracy: 0.500000\n",
      "Epoch 465, CIFAR-10 Batch 2:  Loss:     1.0212 Validation Accuracy: 0.675000\n",
      "Epoch 465, CIFAR-10 Batch 3:  Loss:     0.9813 Validation Accuracy: 0.625000\n",
      "Epoch 465, CIFAR-10 Batch 4:  Loss:     1.0961 Validation Accuracy: 0.600000\n",
      "Epoch 465, CIFAR-10 Batch 5:  Loss:     1.2494 Validation Accuracy: 0.475000\n",
      "Epoch 466, CIFAR-10 Batch 1:  Loss:     1.3475 Validation Accuracy: 0.500000\n",
      "Epoch 466, CIFAR-10 Batch 2:  Loss:     1.0213 Validation Accuracy: 0.675000\n",
      "Epoch 466, CIFAR-10 Batch 3:  Loss:     0.9809 Validation Accuracy: 0.650000\n",
      "Epoch 466, CIFAR-10 Batch 4:  Loss:     1.0960 Validation Accuracy: 0.600000\n",
      "Epoch 466, CIFAR-10 Batch 5:  Loss:     1.2491 Validation Accuracy: 0.475000\n",
      "Epoch 467, CIFAR-10 Batch 1:  Loss:     1.3484 Validation Accuracy: 0.500000\n",
      "Epoch 467, CIFAR-10 Batch 2:  Loss:     1.0209 Validation Accuracy: 0.675000\n",
      "Epoch 467, CIFAR-10 Batch 3:  Loss:     0.9802 Validation Accuracy: 0.625000\n",
      "Epoch 467, CIFAR-10 Batch 4:  Loss:     1.0958 Validation Accuracy: 0.600000\n",
      "Epoch 467, CIFAR-10 Batch 5:  Loss:     1.2487 Validation Accuracy: 0.475000\n",
      "Epoch 468, CIFAR-10 Batch 1:  Loss:     1.3474 Validation Accuracy: 0.500000\n",
      "Epoch 468, CIFAR-10 Batch 2:  Loss:     1.0210 Validation Accuracy: 0.675000\n",
      "Epoch 468, CIFAR-10 Batch 3:  Loss:     0.9805 Validation Accuracy: 0.625000\n",
      "Epoch 468, CIFAR-10 Batch 4:  Loss:     1.0955 Validation Accuracy: 0.600000\n",
      "Epoch 468, CIFAR-10 Batch 5:  Loss:     1.2486 Validation Accuracy: 0.475000\n",
      "Epoch 469, CIFAR-10 Batch 1:  Loss:     1.3484 Validation Accuracy: 0.500000\n",
      "Epoch 469, CIFAR-10 Batch 2:  Loss:     1.0210 Validation Accuracy: 0.675000\n",
      "Epoch 469, CIFAR-10 Batch 3:  Loss:     0.9804 Validation Accuracy: 0.650000\n",
      "Epoch 469, CIFAR-10 Batch 4:  Loss:     1.0957 Validation Accuracy: 0.600000\n",
      "Epoch 469, CIFAR-10 Batch 5:  Loss:     1.2489 Validation Accuracy: 0.475000\n",
      "Epoch 470, CIFAR-10 Batch 1:  Loss:     1.3478 Validation Accuracy: 0.500000\n",
      "Epoch 470, CIFAR-10 Batch 2:  Loss:     1.0214 Validation Accuracy: 0.675000\n",
      "Epoch 470, CIFAR-10 Batch 3:  Loss:     0.9800 Validation Accuracy: 0.625000\n",
      "Epoch 470, CIFAR-10 Batch 4:  Loss:     1.0955 Validation Accuracy: 0.600000\n",
      "Epoch 470, CIFAR-10 Batch 5:  Loss:     1.2485 Validation Accuracy: 0.475000\n",
      "Epoch 471, CIFAR-10 Batch 1:  Loss:     1.3491 Validation Accuracy: 0.500000\n",
      "Epoch 471, CIFAR-10 Batch 2:  Loss:     1.0217 Validation Accuracy: 0.675000\n",
      "Epoch 471, CIFAR-10 Batch 3:  Loss:     0.9800 Validation Accuracy: 0.625000\n",
      "Epoch 471, CIFAR-10 Batch 4:  Loss:     1.0952 Validation Accuracy: 0.600000\n",
      "Epoch 471, CIFAR-10 Batch 5:  Loss:     1.2482 Validation Accuracy: 0.475000\n",
      "Epoch 472, CIFAR-10 Batch 1:  Loss:     1.3485 Validation Accuracy: 0.500000\n",
      "Epoch 472, CIFAR-10 Batch 2:  Loss:     1.0220 Validation Accuracy: 0.675000\n",
      "Epoch 472, CIFAR-10 Batch 3:  Loss:     0.9796 Validation Accuracy: 0.650000\n",
      "Epoch 472, CIFAR-10 Batch 4:  Loss:     1.0950 Validation Accuracy: 0.600000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 472, CIFAR-10 Batch 5:  Loss:     1.2480 Validation Accuracy: 0.475000\n",
      "Epoch 473, CIFAR-10 Batch 1:  Loss:     1.3492 Validation Accuracy: 0.500000\n",
      "Epoch 473, CIFAR-10 Batch 2:  Loss:     1.0218 Validation Accuracy: 0.675000\n",
      "Epoch 473, CIFAR-10 Batch 3:  Loss:     0.9796 Validation Accuracy: 0.625000\n",
      "Epoch 473, CIFAR-10 Batch 4:  Loss:     1.0951 Validation Accuracy: 0.600000\n",
      "Epoch 473, CIFAR-10 Batch 5:  Loss:     1.2476 Validation Accuracy: 0.475000\n",
      "Epoch 474, CIFAR-10 Batch 1:  Loss:     1.3494 Validation Accuracy: 0.500000\n",
      "Epoch 474, CIFAR-10 Batch 2:  Loss:     1.0219 Validation Accuracy: 0.675000\n",
      "Epoch 474, CIFAR-10 Batch 3:  Loss:     0.9795 Validation Accuracy: 0.650000\n",
      "Epoch 474, CIFAR-10 Batch 4:  Loss:     1.0944 Validation Accuracy: 0.600000\n",
      "Epoch 474, CIFAR-10 Batch 5:  Loss:     1.2477 Validation Accuracy: 0.475000\n",
      "Epoch 475, CIFAR-10 Batch 1:  Loss:     1.3494 Validation Accuracy: 0.500000\n",
      "Epoch 475, CIFAR-10 Batch 2:  Loss:     1.0217 Validation Accuracy: 0.675000\n",
      "Epoch 475, CIFAR-10 Batch 3:  Loss:     0.9790 Validation Accuracy: 0.625000\n",
      "Epoch 475, CIFAR-10 Batch 4:  Loss:     1.0947 Validation Accuracy: 0.600000\n",
      "Epoch 475, CIFAR-10 Batch 5:  Loss:     1.2474 Validation Accuracy: 0.475000\n",
      "Epoch 476, CIFAR-10 Batch 1:  Loss:     1.3495 Validation Accuracy: 0.500000\n",
      "Epoch 476, CIFAR-10 Batch 2:  Loss:     1.0216 Validation Accuracy: 0.675000\n",
      "Epoch 476, CIFAR-10 Batch 3:  Loss:     0.9787 Validation Accuracy: 0.650000\n",
      "Epoch 476, CIFAR-10 Batch 4:  Loss:     1.0946 Validation Accuracy: 0.600000\n",
      "Epoch 476, CIFAR-10 Batch 5:  Loss:     1.2475 Validation Accuracy: 0.475000\n",
      "Epoch 477, CIFAR-10 Batch 1:  Loss:     1.3494 Validation Accuracy: 0.500000\n",
      "Epoch 477, CIFAR-10 Batch 2:  Loss:     1.0225 Validation Accuracy: 0.675000\n",
      "Epoch 477, CIFAR-10 Batch 3:  Loss:     0.9789 Validation Accuracy: 0.650000\n",
      "Epoch 477, CIFAR-10 Batch 4:  Loss:     1.0942 Validation Accuracy: 0.600000\n",
      "Epoch 477, CIFAR-10 Batch 5:  Loss:     1.2475 Validation Accuracy: 0.475000\n",
      "Epoch 478, CIFAR-10 Batch 1:  Loss:     1.3496 Validation Accuracy: 0.500000\n",
      "Epoch 478, CIFAR-10 Batch 2:  Loss:     1.0224 Validation Accuracy: 0.675000\n",
      "Epoch 478, CIFAR-10 Batch 3:  Loss:     0.9801 Validation Accuracy: 0.675000\n",
      "Epoch 478, CIFAR-10 Batch 4:  Loss:     1.0945 Validation Accuracy: 0.600000\n",
      "Epoch 478, CIFAR-10 Batch 5:  Loss:     1.2468 Validation Accuracy: 0.475000\n",
      "Epoch 479, CIFAR-10 Batch 1:  Loss:     1.3501 Validation Accuracy: 0.500000\n",
      "Epoch 479, CIFAR-10 Batch 2:  Loss:     1.0229 Validation Accuracy: 0.675000\n",
      "Epoch 479, CIFAR-10 Batch 3:  Loss:     0.9794 Validation Accuracy: 0.675000\n",
      "Epoch 479, CIFAR-10 Batch 4:  Loss:     1.0947 Validation Accuracy: 0.600000\n",
      "Epoch 479, CIFAR-10 Batch 5:  Loss:     1.2468 Validation Accuracy: 0.475000\n",
      "Epoch 480, CIFAR-10 Batch 1:  Loss:     1.3493 Validation Accuracy: 0.500000\n",
      "Epoch 480, CIFAR-10 Batch 2:  Loss:     1.0225 Validation Accuracy: 0.675000\n",
      "Epoch 480, CIFAR-10 Batch 3:  Loss:     0.9791 Validation Accuracy: 0.675000\n",
      "Epoch 480, CIFAR-10 Batch 4:  Loss:     1.0938 Validation Accuracy: 0.600000\n",
      "Epoch 480, CIFAR-10 Batch 5:  Loss:     1.2466 Validation Accuracy: 0.475000\n",
      "Epoch 481, CIFAR-10 Batch 1:  Loss:     1.3496 Validation Accuracy: 0.500000\n",
      "Epoch 481, CIFAR-10 Batch 2:  Loss:     1.0226 Validation Accuracy: 0.675000\n",
      "Epoch 481, CIFAR-10 Batch 3:  Loss:     0.9791 Validation Accuracy: 0.700000\n",
      "Epoch 481, CIFAR-10 Batch 4:  Loss:     1.0943 Validation Accuracy: 0.600000\n",
      "Epoch 481, CIFAR-10 Batch 5:  Loss:     1.2466 Validation Accuracy: 0.475000\n",
      "Epoch 482, CIFAR-10 Batch 1:  Loss:     1.3492 Validation Accuracy: 0.500000\n",
      "Epoch 482, CIFAR-10 Batch 2:  Loss:     1.0227 Validation Accuracy: 0.675000\n",
      "Epoch 482, CIFAR-10 Batch 3:  Loss:     0.9793 Validation Accuracy: 0.675000\n",
      "Epoch 482, CIFAR-10 Batch 4:  Loss:     1.0947 Validation Accuracy: 0.600000\n",
      "Epoch 482, CIFAR-10 Batch 5:  Loss:     1.2461 Validation Accuracy: 0.475000\n",
      "Epoch 483, CIFAR-10 Batch 1:  Loss:     1.3497 Validation Accuracy: 0.500000\n",
      "Epoch 483, CIFAR-10 Batch 2:  Loss:     1.0229 Validation Accuracy: 0.675000\n",
      "Epoch 483, CIFAR-10 Batch 3:  Loss:     0.9791 Validation Accuracy: 0.700000\n",
      "Epoch 483, CIFAR-10 Batch 4:  Loss:     1.0944 Validation Accuracy: 0.600000\n",
      "Epoch 483, CIFAR-10 Batch 5:  Loss:     1.2465 Validation Accuracy: 0.475000\n",
      "Epoch 484, CIFAR-10 Batch 1:  Loss:     1.3503 Validation Accuracy: 0.500000\n",
      "Epoch 484, CIFAR-10 Batch 2:  Loss:     1.0229 Validation Accuracy: 0.675000\n",
      "Epoch 484, CIFAR-10 Batch 3:  Loss:     0.9787 Validation Accuracy: 0.675000\n",
      "Epoch 484, CIFAR-10 Batch 4:  Loss:     1.0944 Validation Accuracy: 0.600000\n",
      "Epoch 484, CIFAR-10 Batch 5:  Loss:     1.2461 Validation Accuracy: 0.475000\n",
      "Epoch 485, CIFAR-10 Batch 1:  Loss:     1.3504 Validation Accuracy: 0.500000\n",
      "Epoch 485, CIFAR-10 Batch 2:  Loss:     1.0224 Validation Accuracy: 0.675000\n",
      "Epoch 485, CIFAR-10 Batch 3:  Loss:     0.9784 Validation Accuracy: 0.700000\n",
      "Epoch 485, CIFAR-10 Batch 4:  Loss:     1.0941 Validation Accuracy: 0.600000\n",
      "Epoch 485, CIFAR-10 Batch 5:  Loss:     1.2462 Validation Accuracy: 0.475000\n",
      "Epoch 486, CIFAR-10 Batch 1:  Loss:     1.3497 Validation Accuracy: 0.500000\n",
      "Epoch 486, CIFAR-10 Batch 2:  Loss:     1.0221 Validation Accuracy: 0.675000\n",
      "Epoch 486, CIFAR-10 Batch 3:  Loss:     0.9782 Validation Accuracy: 0.700000\n",
      "Epoch 486, CIFAR-10 Batch 4:  Loss:     1.0945 Validation Accuracy: 0.600000\n",
      "Epoch 486, CIFAR-10 Batch 5:  Loss:     1.2462 Validation Accuracy: 0.475000\n",
      "Epoch 487, CIFAR-10 Batch 1:  Loss:     1.3500 Validation Accuracy: 0.500000\n",
      "Epoch 487, CIFAR-10 Batch 2:  Loss:     1.0221 Validation Accuracy: 0.675000\n",
      "Epoch 487, CIFAR-10 Batch 3:  Loss:     0.9782 Validation Accuracy: 0.675000\n",
      "Epoch 487, CIFAR-10 Batch 4:  Loss:     1.0938 Validation Accuracy: 0.600000\n",
      "Epoch 487, CIFAR-10 Batch 5:  Loss:     1.2460 Validation Accuracy: 0.475000\n",
      "Epoch 488, CIFAR-10 Batch 1:  Loss:     1.3501 Validation Accuracy: 0.500000\n",
      "Epoch 488, CIFAR-10 Batch 2:  Loss:     1.0222 Validation Accuracy: 0.675000\n",
      "Epoch 488, CIFAR-10 Batch 3:  Loss:     0.9780 Validation Accuracy: 0.700000\n",
      "Epoch 488, CIFAR-10 Batch 4:  Loss:     1.0938 Validation Accuracy: 0.600000\n",
      "Epoch 488, CIFAR-10 Batch 5:  Loss:     1.2463 Validation Accuracy: 0.475000\n",
      "Epoch 489, CIFAR-10 Batch 1:  Loss:     1.3503 Validation Accuracy: 0.500000\n",
      "Epoch 489, CIFAR-10 Batch 2:  Loss:     1.0225 Validation Accuracy: 0.675000\n",
      "Epoch 489, CIFAR-10 Batch 3:  Loss:     0.9776 Validation Accuracy: 0.700000\n",
      "Epoch 489, CIFAR-10 Batch 4:  Loss:     1.0934 Validation Accuracy: 0.625000\n",
      "Epoch 489, CIFAR-10 Batch 5:  Loss:     1.2467 Validation Accuracy: 0.475000\n",
      "Epoch 490, CIFAR-10 Batch 1:  Loss:     1.3500 Validation Accuracy: 0.500000\n",
      "Epoch 490, CIFAR-10 Batch 2:  Loss:     1.0225 Validation Accuracy: 0.675000\n",
      "Epoch 490, CIFAR-10 Batch 3:  Loss:     0.9778 Validation Accuracy: 0.675000\n",
      "Epoch 490, CIFAR-10 Batch 4:  Loss:     1.0929 Validation Accuracy: 0.625000\n",
      "Epoch 490, CIFAR-10 Batch 5:  Loss:     1.2459 Validation Accuracy: 0.475000\n",
      "Epoch 491, CIFAR-10 Batch 1:  Loss:     1.3499 Validation Accuracy: 0.500000\n",
      "Epoch 491, CIFAR-10 Batch 2:  Loss:     1.0224 Validation Accuracy: 0.675000\n",
      "Epoch 491, CIFAR-10 Batch 3:  Loss:     0.9780 Validation Accuracy: 0.700000\n",
      "Epoch 491, CIFAR-10 Batch 4:  Loss:     1.0937 Validation Accuracy: 0.625000\n",
      "Epoch 491, CIFAR-10 Batch 5:  Loss:     1.2466 Validation Accuracy: 0.475000\n",
      "Epoch 492, CIFAR-10 Batch 1:  Loss:     1.3499 Validation Accuracy: 0.500000\n",
      "Epoch 492, CIFAR-10 Batch 2:  Loss:     1.0226 Validation Accuracy: 0.675000\n",
      "Epoch 492, CIFAR-10 Batch 3:  Loss:     0.9778 Validation Accuracy: 0.700000\n",
      "Epoch 492, CIFAR-10 Batch 4:  Loss:     1.0927 Validation Accuracy: 0.625000\n",
      "Epoch 492, CIFAR-10 Batch 5:  Loss:     1.2462 Validation Accuracy: 0.475000\n",
      "Epoch 493, CIFAR-10 Batch 1:  Loss:     1.3506 Validation Accuracy: 0.500000\n",
      "Epoch 493, CIFAR-10 Batch 2:  Loss:     1.0230 Validation Accuracy: 0.675000\n",
      "Epoch 493, CIFAR-10 Batch 3:  Loss:     0.9765 Validation Accuracy: 0.700000\n",
      "Epoch 493, CIFAR-10 Batch 4:  Loss:     1.0930 Validation Accuracy: 0.625000\n",
      "Epoch 493, CIFAR-10 Batch 5:  Loss:     1.2467 Validation Accuracy: 0.475000\n",
      "Epoch 494, CIFAR-10 Batch 1:  Loss:     1.3500 Validation Accuracy: 0.500000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 494, CIFAR-10 Batch 2:  Loss:     1.0229 Validation Accuracy: 0.675000\n",
      "Epoch 494, CIFAR-10 Batch 3:  Loss:     0.9776 Validation Accuracy: 0.700000\n",
      "Epoch 494, CIFAR-10 Batch 4:  Loss:     1.0932 Validation Accuracy: 0.625000\n",
      "Epoch 494, CIFAR-10 Batch 5:  Loss:     1.2458 Validation Accuracy: 0.475000\n",
      "Epoch 495, CIFAR-10 Batch 1:  Loss:     1.3506 Validation Accuracy: 0.500000\n",
      "Epoch 495, CIFAR-10 Batch 2:  Loss:     1.0227 Validation Accuracy: 0.675000\n",
      "Epoch 495, CIFAR-10 Batch 3:  Loss:     0.9767 Validation Accuracy: 0.700000\n",
      "Epoch 495, CIFAR-10 Batch 4:  Loss:     1.0924 Validation Accuracy: 0.625000\n",
      "Epoch 495, CIFAR-10 Batch 5:  Loss:     1.2461 Validation Accuracy: 0.475000\n",
      "Epoch 496, CIFAR-10 Batch 1:  Loss:     1.3504 Validation Accuracy: 0.500000\n",
      "Epoch 496, CIFAR-10 Batch 2:  Loss:     1.0229 Validation Accuracy: 0.675000\n",
      "Epoch 496, CIFAR-10 Batch 3:  Loss:     0.9762 Validation Accuracy: 0.700000\n",
      "Epoch 496, CIFAR-10 Batch 4:  Loss:     1.0919 Validation Accuracy: 0.625000\n",
      "Epoch 496, CIFAR-10 Batch 5:  Loss:     1.2459 Validation Accuracy: 0.475000\n",
      "Epoch 497, CIFAR-10 Batch 1:  Loss:     1.3504 Validation Accuracy: 0.500000\n",
      "Epoch 497, CIFAR-10 Batch 2:  Loss:     1.0227 Validation Accuracy: 0.675000\n",
      "Epoch 497, CIFAR-10 Batch 3:  Loss:     0.9760 Validation Accuracy: 0.700000\n",
      "Epoch 497, CIFAR-10 Batch 4:  Loss:     1.0925 Validation Accuracy: 0.625000\n",
      "Epoch 497, CIFAR-10 Batch 5:  Loss:     1.2455 Validation Accuracy: 0.475000\n",
      "Epoch 498, CIFAR-10 Batch 1:  Loss:     1.3502 Validation Accuracy: 0.500000\n",
      "Epoch 498, CIFAR-10 Batch 2:  Loss:     1.0232 Validation Accuracy: 0.675000\n",
      "Epoch 498, CIFAR-10 Batch 3:  Loss:     0.9757 Validation Accuracy: 0.700000\n",
      "Epoch 498, CIFAR-10 Batch 4:  Loss:     1.0915 Validation Accuracy: 0.625000\n",
      "Epoch 498, CIFAR-10 Batch 5:  Loss:     1.2459 Validation Accuracy: 0.475000\n",
      "Epoch 499, CIFAR-10 Batch 1:  Loss:     1.3511 Validation Accuracy: 0.500000\n",
      "Epoch 499, CIFAR-10 Batch 2:  Loss:     1.0228 Validation Accuracy: 0.675000\n",
      "Epoch 499, CIFAR-10 Batch 3:  Loss:     0.9750 Validation Accuracy: 0.700000\n",
      "Epoch 499, CIFAR-10 Batch 4:  Loss:     1.0923 Validation Accuracy: 0.625000\n",
      "Epoch 499, CIFAR-10 Batch 5:  Loss:     1.2460 Validation Accuracy: 0.475000\n",
      "Epoch 500, CIFAR-10 Batch 1:  Loss:     1.3511 Validation Accuracy: 0.500000\n",
      "Epoch 500, CIFAR-10 Batch 2:  Loss:     1.0229 Validation Accuracy: 0.675000\n",
      "Epoch 500, CIFAR-10 Batch 3:  Loss:     0.9754 Validation Accuracy: 0.700000\n",
      "Epoch 500, CIFAR-10 Batch 4:  Loss:     1.0923 Validation Accuracy: 0.625000\n",
      "Epoch 500, CIFAR-10 Batch 5:  Loss:     1.2455 Validation Accuracy: 0.475000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查点\n",
    "\n",
    "模型已保存到本地。\n",
    "\n",
    "## 测试模型\n",
    "\n",
    "利用测试数据集测试你的模型。这将是最终的准确率。你的准确率应该高于 50%。如果没达到，请继续调整模型结构和参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./image_classification\n",
      "Testing Accuracy: 0.5015625\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3XmcZFV9///Xp/dlelaGYViHVQYVUTYBA0PURMUFjUrcgWjcFzRGo34Vzc8lakTFJMQYnLhjNOjDKEpcQEVxAZVdERl2Bmbvnt6quj6/Pz6n6t6+U91dPdP7vJ+PRz2q695zzz1VXcupT33OOebuiIiIiIgINM12A0RERERE5gp1jkVEREREEnWORUREREQSdY5FRERERBJ1jkVEREREEnWORUREREQSdY5FRERERBJ1jkVEREREEnWORUREREQSdY5FRERERBJ1jkVEREREEnWORUREREQSdY5FRERERBJ1jkVEREREEnWOZ5mZHWJmzzGzV5vZP5jZ283s9Wb2PDM7wcwWzXYbx2JmTWb2LDP7ipn90cx2mJnnLt+Y7TaKzDVmtqbwOrlwKsrOVWa2rnAfzp3tNomIjKdlthuwNzKz5cCrgVcAh0xQvGJmtwA/Ab4N/MDdB6e5iRNK9+FrwJmz3RaZeWa2HnjZBMXKwDZgE3A98Rz+srtvn97WiYiI7D5FjmeYmT0duAX4/5i4YwzxP3oU0Zn+X+C509e6Sfkck+gYK3q0V2oB9gGOBl4I/Btwn5ldaGb6Yj6PFF6762e7PSIi00kfUDPIzJ4PfJldv5TsAG4EHgSGgGXAwcDaOmVnnZk9Hjgrt+ku4L3Ar4He3Pb+mWyXzAvdwHuA083sqe4+NNsNEhERyVPneIaY2eFEtDXf2b0JeCfwHXcv1zlmEXAG8Dzg2cDiGWhqI55TuP0sd//drLRE5oq3Emk2eS3AKuAJwGuIL3xVZxKR5PNnpHUiIiINUud45rwfaM/d/j7wTHcfGOsAd+8j8oy/bWavB15ORJdn2/G5vzeoYyzAJnffUGf7H4FrzOxi4AvEl7yqc83sk+7+25lo4HyUHlOb7XbsCXe/inl+H0Rk7zLnfrJfiMysE3hmblMJeNl4HeMid+9194vc/ftT3sDJ2zf39/2z1gqZN9y9H3gR8IfcZgNeNTstEhERqU+d45nxOKAzd/tn7j6fO5X56eVKs9YKmVfSl8GLCpufOBttERERGYvSKmbGfoXb983kyc1sMfBnwAHACmLQ3EbgF+5+9+5UOYXNmxJmdhiR7nEg0AZsAH7k7g9NcNyBRE7sQcT9eiAdd+8etOUA4JHAYcDStHkLcDfw8718KrMfFG4fbmbN7j4ymUrM7FHAMcBqYpDfBnf/UgPHtQGnAGuIX0AqwEPADVORHmRmRwInAfsDg8C9wC/dfUZf83XadRRwHLCSeE72E8/1m4Bb3L0yi82bkJkdBDyeyGHvIV5P9wM/cfdtU3yuw4iAxkFAM/FeeY27/2kP6nwE8fjvRwQXykAfcA9wO3Cbu/seNl1Epoq76zLNF+CvAc9drpih854AXAEMF86fv9xATLNl49Szbpzjx7pclY7dsLvHFtqwPl8mt/0M4EdEJ6dYzzDwr8CiOvUdA3xnjOMqwNeBAxp8nJtSO/4NuGOC+zYC/B9wZoN1/1fh+E9P4v//wcKx3xrv/zzJ59b6Qt3nNnhcZ53HZN865fLPm6ty288jOnTFOrZNcN5HAF8ivhiO9b+5F3gz0LYbj8dpwC/GqLdMjB04PpVdU9h/4Tj1Nly2zrFLgX8kvpSN95x8GLgUOHGC/3FDlwbePxp6rqRjnw/8dpzzldLr6fGTqPOq3PEbcttPJr681XtPcOBa4JRJnKcVeAuRdz/R47aNeM958lS8PnXRRZc9u8x6A/aGC/DnhTfCXmDpNJ7PgA+P8yZf73IVsGyM+oofbg3Vl47dsLvHFtow6oM6bXtDg/fxV+Q6yMRsG/0NHLcBOKiBx/v83biPDvwz0DxB3d3AbYXjzmmgTX9ReGzuBVZM4XNsfaFN5zZ43G51jonBrF8d57Gs2zkmXgvvIzpRjf5fbmrk/547xzsafB4OE3nXawrbLxyn7obLFo57NrB1ks/H307wP27o0sD7x4TPFWJmnu9P8twfB5oaqPuq3DEb0rbXM34QIf8/fH4D51hJLHwz2cfvG1P1GtVFF112/6K0iplxHRExbE63FwGfM7MXesxIMdX+A/ibwrZhIvJxPxFROoFYoKHqDODHZna6u2+dhjZNqTRn9CfSTSeiS3cQnaHjgMNzxU8ALgbOM7MzgcvIUopuS5dhYl7pR+eOO4TGFjsp5u4PADcTP1vvIDqEBwPHEikfVW8mOm1vH6tid9+Z7usvgI60+dNm9mt3v6PeMWa2H/B5svSXEeCF7r55gvsxEw4o3HagkXZ9nJjSsHrMb8g60IcBhxYPMDMjIu8vKewaIDou1bz/I4jnTPXxeiTwMzM70d3HnR3GzN5EzESTN0L8v+4hUgAeS6R/tBIdzuJrc0qlNn2MXdOfHiR+KdoEdBEpSI9m9Cw6s87MeoCrif9J3lbgl+l6NZFmkW/7G4n3tBdP8nwvBj6Z23QTEe0dIt5Hjid7LFuB9Wb2G3e/fYz6DPgf4v+et5GYz34T8WVqSar/CJTiKDK3zHbvfG+5EKvbFaME9xMLIjyaqfu5+2WFc1SIjsXSQrkW4kN6e6H8l+vU2UFEsKqXe3Plry3sq172S8cemG4XU0v+bozjascW2rC+cHw1Kva/wOF1yj+f6ATlH4dT0mPuwM+A4+oct47orOXP9bQJHvPqFHsfTOeoGw0mvpS8DdhZaNfJDfxfX1Vo06+p8/M/0VEvRtz+3zQ8n4v/j3MbPO5vC8f9cYxyG3Jl8qkQnwcOrFN+TZ1tby+ca0t6HDvqlD0U+Gah/PcYP93o0ewabfxS8fmb/ifPJ3Kbq+3IH3PhOOdY02jZVP4vic55/pirgVPr3Reic/kM4if96wr79iF7Tebr+xpjv3br/R/WTea5Any2UH4H8EqgtVBuCfHrSzFq/8oJ6r8qV7aP7H3icuCIOuXXAr8rnOOyceo/q1D2dmLgad3nEvHr0LOArwD/PdWvVV100WXyl1lvwN5yIaIgg4U3zfxlM5GX+P+AJwPdu3GORUTuWr7eCyY45mRGd9acCfLeGCMfdIJjJvUBWef49XUesy8yzs+oxJLb9TrU3wfaxznu6Y1+EKby+41XX53ypxSeC+PWnzuumFbwiTpl3lko84PxHqM9eD4X/x8T/j+JL1m3Fo6rm0NN/XScD06ifY9kdCrFPdTpuBWOMSL3Nn/Os8Yp/6NC2U810KZix3jKOsdENHhjsU2N/v+BVePsy9e5fpLPlYZf+8TA4XzZfuC0Cep/XeGYPsZIEUvlr6rzP/gU438RWsXoNJXBsc5BjD2olisBh07isdrli5suuugy8xdN5TZDPBY6eAnxplrPcuBpRH7klcBWM/uJmb0yzTbRiJcR0ZSq77p7ceqsYrt+Aby7sPmNDZ5vNt1PRIjGG2X/n0RkvKo6Sv8lPs6yxe7+v8Dvc5vWjdcQd39wvPrqlP858C+5TWebWSM/bb8cyI+Yf4OZPat6w8yeQCzjXfUw8OIJHqMZYWYdRNT36MKuf2+wit8C75rEKf+e7KdqB57n9RcpqXF3J1byy89UUve1YGaPZPTz4g9Emsx49d+c2jVdXsHoOch/BLy+0f+/u2+cllZNzhsKt9/r7teMd4C7f4r4Bamqm8mlrtxEBBF8nHNsJDq9Ve1EWkc9+ZUgf+vudzbaEHcf6/NBRGaQOsczyN3/m/h586cNFG8lphi7BPiTmb0m5bKN50WF2+9psGmfJDpSVU8zs+UNHjtbPu0T5Gu7+zBQ/GD9irs/0ED9P8z9vW/K451K38z93cau+ZW7cPcdwDnET/lVnzWzg81sBfBlsrx2B17a4H2dCvuY2ZrC5QgzO9XM/h64BXhu4Zgvuvt1Ddb/cW9wujczWwq8ILfp2+5+bSPHps7Jp3ObzjSzrjpFi6+1D6fn20QuZfqmcnxF4fa4Hb65xsy6gbNzm7YSKWGNKH5xmkze8UXu3sh87d8p3H5MA8esnEQ7RGSOUOd4hrn7b9z9z4DTicjmuPPwJiuISONX0jytu0iRx/yyzn9y91822KYS8N/56hg7KjJXXNlgueKgtf9r8Lg/Fm5P+kPOQo+Z7V/sOLLrYKliRLUud/81kbdctYzoFK8n8rurPuLu351sm/fAR4A7C5fbiS8n/8SuA+auYdfO3Hi+NYmypxFfLqu+NoljAX6S+7uFSD0qOiX3d3XqvwmlKO5/T1hwksxsJZG2UfUrn3/Lup/I6IFplzf6i0y6r7fkNj06DexrRKOvk9sKt8d6T8j/6nSImb22wfpFZI7QCNlZ4u4/IX0Im9kxRET5BOID4jjqf3F5PjHSud6b7aMYPRPCLybZpGuJn5SrjmfXSMlcUvygGsuOwu3f1y018XETpraYWTPwJGJWhROJDm/dLzN1LGuwHO7+8TTrRnVJ8lMLRa4lco/nogFilpF3NxitA7jb3bdM4hynFW5vTl9IGtVcuF3v2Mfl/r7dJ7cQxa8mUbZRxQ78T+qWmtuOL9zenfewY9LfTcT76ESPww5vfLXS4uI9Y70nfAW4IHf7U2Z2NjHQ8AqfB7MBiezt1DmeA9z9FiLq8Rmo/Sx8NvEGe2yh+GvM7D/d/frC9mIUo+40Q+Modhrn+s+Bja4yV56i41rrlkrM7BQif/bR45UbR6N55VXnEdOZHVzYvg14gbsX2z8bRojHezPR1p8AX5pkRxdGp/w04sDC7clEnesZlWKU8qfz/6+6U+qNo/irxFQopv3cOg3nmG6z8R7W8GqV7l4qZLbVfU9w91+a2b8yOtjwpHSpmNmNxC8nP6aBVTxFZOYprWIOcvdt7r6eiHy8r06R4qAVyJYpripGPidS/JBoOJI5G/ZgkNmUD04zs6cQg592t2MMk3wtpg7mB+rsestEA8+myXnuboVLi7uvcPej3P0cd//UbnSMIWYfmIypzpdfVLg91a+1qbCicHtKl1SeIbPxHjZdg1VfR/x601/Y3kTkKr+GiDA/YGY/MrPnNjCmRERmiDrHc5iH9xCLVuQ9aTbaI7tKAxe/wOjFCDYQy/Y+lVi2eCkxRVOt40idRSsmed4VxLR/RS82s739dT1ulH83zMdOy7wZiLcQpffuDxAL1LwN+Dm7/hoF8Rm8jshDv9rMVs9YI0VkTEqrmB8uJmYpqDrAzDrdfSC3rRgpmuzP9EsKt5UX15jXMDpq9xXgZQ3MXNDoYKFd5FZ+K642B7Ga37uo/4vD3qIYnT7G3acyzWCqX2tToXifi1HY+WDBvYelKeA+DHzYzBYBJxFzOZ9J5MbnP4P/DPiumZ00makhRWTq7e0Rpvmi3qjz4k+GxbzMIyZ5jqMmqE/qOyv393bg5Q1O6bUnU8NdUDjvLxk968m7zezP9qD++a6Yw7lP3VK7KU33lv/J//Cxyo5hsq/NRhSXuV47DeeYbgv6Pczd+9z9h+7+XndfRyyB/S5ikGrVscD5s9E+Ecmoczw/1MuLK+bj3cTo+W9PmuQ5ilO3NTr/bKMW6s+8+Q/wn7r7zgaP262p8szsROBDuU1bidkxXkr2GDcDX0qpF3uj4pzG9aZi21P5AbFHpkG0jTpxqhvDrvd5Pn45Kr7nTPb/ln9NVYiFY+Ysd9/k7u9n1ykNnzEb7RGRjDrH88MjCrf7igtgpJ/h8h8uR5hZcWqkusyshehg1apj8tMoTaT4M2GjU5zNdfmfchsaQJTSIl442ROllRK/wuic2vPd/W53/x4x13DVgcTUUXujHzL6y9jzp+EcP8/93QT8VSMHpXzw501YcJLc/WHiC3LVSWa2JwNEi/Kv3+l67f6K0Xm5zx5rXvciMzuW0fM83+TuvVPZuGl0GaMf3zWz1A4RSdQ5ngFmtsrMVu1BFcWf2a4ao9yXCreLy0KP5XWMXnb2Cnff3OCxjSqOJJ/qFedmSz5Psviz7lheQoOLfhT8BzHAp+pid/9G7vY7Gf2l5hlmNh+WAp9SKc8z/7icaGZT3SH9YuH23zfYkTuf+rniU+HThdsfm8IZEPKv32l57aZfXfIrRy6n/pzu9RRz7L8wJY2aAWnaxfwvTo2kZYnINFLneGasJZaA/pCZ7Tth6Rwz+yvg1YXNxdkrqv6L0R9izzSz14xRtlr/icTMCnmfnEwbG/QnRkeFzpyGc8yGG3N/H29mZ4xX2MxOIgZYToqZ/S2jI6C/Ad6aL5M+ZP+a0c+BD5tZfsGKvcX7GJ2OdOlE/5siM1ttZk+rt8/dbwauzm06CvjYBPUdQwzOmi7/CWzM3X4ScFGjHeQJvsDn5xA+MQ0umw7F955/TO9RYzKzVwPPym3aSTwWs8LMXp1WLGy0/FMZPf1gowsVicg0Ued45nQRU/rca2aXm9lfjfcGamZrzezTwFcZvWLX9ewaIQYg/Yz45sLmi83sI2Y2aiS3mbWY2XnEcsr5D7qvpp/op1RK+8hHNdeZ2WfM7IlmdmRheeX5FFUuLk38dTN7ZrGQmXWa2QXAD4hR+JsaPYGZPQr4eG5TH3BOvRHtaY7jl+c2tRHLjk9XZ2ZOcvffEoOdqhYBPzCzT5rZmAPozGypmT3fzC4jpuR76TineT2QX+XvtWb2xeLz18yaUuT6KmIg7bTMQezu/UR7818K3kjc71PqHWNm7Wb2dDP7OuOviPnj3N+LgG+b2bPT+1RxafQ9uQ8/Bj6f29QN/J+Z/U1K/8q3fbGZfRj4VKGat+7mfNpT5W3A3em5cPZYy1in9+CXEsu/582bqLfIQqWp3GZeK7H63dkAZvZH4G6is1QhPjyPAQ6qc+y9wPPGWwDD3S81s9OBl6VNTcDfAa83s58DDxDTPJ3IrqP4b2HXKPVUupjRS/v+TboUXU3M/TkfXErMHnFkur0C+KaZ3UV8kRkkfoY+mfiCBDE6/dXE3KbjMrMu4peCztzmV7n7mKuHufvXzOwS4FVp05HAJcCLG7xPC4K7fzB11v42bWomOrSvN7M7iSXItxKvyaXE47RmEvXfaGZvY3TE+IXAOWZ2LXAP0ZE8npiZAOLXkwuYpnxwd7/SzP4O+Gey+ZnPBH5mZg8ANxArFnYSeenHks3RXW9WnKrPAG8BOtLt09Olnj1N5XgdsVBGdXXQJen8/2RmvyS+XOwHnJJrT9VX3P3f9vD8U6GDeC68EHAz+wNwJ9n0cquBx7Lr9HPfcPc9XdFRRPaQOsczYwvR+a03pdQRNDZl0feBVzS4+tl56ZxvIvugamf8DudPgWdNZ8TF3S8zs5OJzsGC4O5DKVL8Q7IOEMAh6VLURwzIuq3BU1xMfFmq+qy7F/Nd67mA+CJSHZT1IjP7gbvvVYP03P2VZnYDMVgx/wXjUBpbiGXcuXLd/aL0BeYfyV5rzYz+ElhVJr4M/rjOvimT2nQf0aHMRy1XM/o5Opk6N5jZuUSnvnOC4nvE3XekFJj/YXT61QpiYZ2x/Av1Vw+dbUYMqi4OrC66jCyoISKzSGkVM8DdbyAiHX9ORJl+DYw0cOgg8QHxdHd/cqPLAqfVmd5MTG10JfVXZqq6mfgp9vSZ+Ckytetk4oPsV0QUa14PQHH324DHET+HjvVY9wGfA4519+82Uq+ZvYDRgzFvIyKfjbRpkFg4Jr987cVmtjsDAec1d/8XoiP8UeC+Bg75A/FT/anuPuEvKWk6rtOJ+abrqRCvw9Pc/XMNNXoPuftXicGbH2V0HnI9G4nBfON2zNz9MmL8xHuJFJEHGD1H75Rx923AE4nI6w3jFB0hUpVOc/fX7cGy8lPpWcRjdC2j027qqRDtP8vd/1qLf4jMDea+UKefndtStOmodNmXLMKzg4j63gzckgZZ7em5lhAf3gcQAz/6iA/EXzTa4ZbGpLmFTyeixp3E43wf8JOUEyqzLH1BeAzxS85SYhqtbcAdxGtuos7keHUfSXwpXU18ub0P+KW737On7d6DNhlxfx8JrCRSPfpS224GbvU5/kFgZgcTj+sq4r1yC3A/8bqa9ZXwxmJmHcCjiF8H9yMe+xIxaPaPwPWznB8tInWocywiIiIikiitQkREREQkUedYRERERCRR51hEREREJFHnWEREREQkUedYRERERCRR51hEREREJFHnWEREREQkUedYRERERCRR51hEREREJFHnWEREREQkUedYRERERCRR51hEREREJFHnWEREREQkUedYRERERCRR51hEREREJFHnWEREREQkUedYRERERCRR51hEREREJFHnWEREREQkUedYRERERCRR51hEREREJFHnWEREREQkUedYRERERCRR51hEREREJGmZ7QZIfWZ2LrAG+Ia7/3Z2WyMiIiKyd1DneO46FzgD2ACocywiIiIyA5RWISIiIiKSqHMsIiIiIpKoc7wbzGytmV1iZn8ws34z22ZmN5rZJ83s+Fy5djN7npl9zsx+Z2abzGzQzO4ysy/my+aOOdfMnEipAPismXnusmGG7qaIiIjIXsfcfbbbMK+Y2euBi4DmtGknUAKWpttXu/u6VPbpwLfSdge2AZ1AR9pWBs5398/n6j8H+ASwHGgFdgADuSbc4+4nTu29EhERERFQ5HhSzOx5wCeJjvHXgGPcfZG7LwNWAC8Grssd0pfKnw4scvfl7t4JHAJ8nBgQ+WkzO7h6gLtf5u77AT9Lm97o7vvlLuoYi4iIiEwTRY4bZGatwJ3AAcCX3f2FU1DnfwLnAxe6+3sL+64iUivOc/f1e3ouEREREZmYIseNeyLRMR4B3jpFdVZTLk6bovpEREREZA9onuPGPT5d/87d72v0IDNbDrwWeCrwCGAJWb5y1f5T0kIRERER2SPqHDduVbq+u9EDzOwY4Ie5YwF6iQF2DrQBy4DuKWqjiIiIiOwBpVVMr88SHePrgacAPe6+2N1XpUF3z0vlbLYaKCIiIiIZRY4btzFdH9JI4TQDxUlEjvIzx0jFWFVnm4iIiIjMEkWOG3dtuj7WzA5ooPyB6frhcXKUnzTO8ZV0raiyiIiIyAxR57hxPwDuIwbTfaSB8tvT9Soz27e408weDYw3HdyOdL10nDIiIiIiMoXUOW6Qu5eAt6SbLzCzr5rZ0dX9ZrbczF5hZp9Mm24F7iUiv5eZ2RGpXKuZPQf4P2KRkLHcnK6fY2ZLpvK+iIiIiEh9WgRkkszszUTkuPrFoo9YBrre8tHPJlbSq5btBdqJWSruBt4JfB64y93XFM5zNPC7VLYMPEQsU32vuz9hGu6aiIiIyF5PkeNJcvePAY8lZqLYALQS07LdAHwCuCBX9nLgz4kocW8qexfw0VTHveOc5zbgycB3iRSN/YjBgAeOdYyIiIiI7BlFjkVEREREEkWORUREREQSdY5FRERERBJ1jkVEREREEnWORUREREQSdY5FRERERBJ1jkVEREREEnWORUREREQSdY5FRERERBJ1jkVEREREkpbZboCIyEJkZncCi4ll5kVEZPLWADvc/dCZPOmC7Ry/9IffdoDH7ru6tm2RdQLwcHkEgHv6+mr7HtpZAmB7uu1NVtvnqfySRV1x3ZIF3Bdb7FvZHXUPl7KH9MFy1L96UQcA+7d11/Zt2NkLwM3bBmrblrbEsYvS9abhodq+YR8G4KiexQAM9Zdq+3704B0AlPuivI9kx/UO9wPQXIplwg9esSo7X2cPAP979tOzOysiU2VxZ2fn8rVr1y6f7YaIiMxHt956KwMDAxMXnGILtnP8YKkMwLXbtta2rWQbAC2VCgDbO7tq+4aj78mqndHxHWnPOsDbOtPfTXE9MFKu7bPmqKsyGJ3QppG22r6ezugwN3t0THeQdWi3WvzdZFld7c3x72hvawago6m1tq9SivO0tEedvTuHa/vKI7FvpDn6uE1ZlXS1RB0dbXFd8ZHavv6hfkTmCzO7CjjD3Rv+MmdmDlzt7uumq13j2LB27drl11133SycWkRk/jv++OO5/vrrN8z0eZVzLCIiIiKSLNjIsYgIsBaYtZ9IbrpvO2ve/u3ZOr2IzJANHzprtpsgU2jBdo7L2wYBuJvm2radFtv2/eP9sWH1gbV929vioVhiSwDobmqv7ettirSIUilSGQaHs/yXvpQW0d4av/S2N3XW9h3QHnXZQBzXP5jlAjd5pFUsb86C9z0W5+nwSJOwoay8l+M8W3ZEHvPW/p21fYODA6l9UaazlKVOtEaVdFbTRMpZOsb2XB0iC5G73zbbbRARkflFaRUiMuvM7Jlm9gMze8DMhszsfjO72sxeU6dsi5m9w8xuT2XvMbN/MrO2OmU95Srnt12Ytq8zs5eZ2W/MbMDMHjKzS81sv2m8qyIiMsct2Mjxoi0RIR3KzSxRbo1fV/d/cAcAW7beVdu34YgVsW1JzCyxmGzMT7k6ji6NAypXsshsxSNaO2RxnpbWbNDdkoE4374dUWd7a/Zw21BEtDf7YG3bstYUrU4D/8oDWeR4YCTNsNEf2/qHsui1j0R4uJLKVLKHgaY0WK87zYDR1pa1wXOD80Rmi5n9LfDvwIPAt4BNwL7AscB5wL8WDvkS8GfAFcAO4GnA36djzpvEqS8A/gK4DPgu8IR0/DozO9ndH97NuyQiIvPYgu0ci8i88UpgGHiMuz+U32Fm+9QpfzjwSHffksq8E/gd8FIz+wd3f7DB8z4VONndf5M730XAm4APAX/TSCVmNtZ0FEc32A4REZlDFm7neHvk5q5oziKsi9sjqnu4RYR2yY5snM4dW+Oh2NYd8wgPVDyry2Jfc3NEe8uVLDabZmmjumloOMvp3VmJCPBgV5yvOp0awDKPurYOZpHjkRSsHki5xpt6s3mYB1rjF+PhFMbu3Zntq6RcY2qR4yxa7qmBi9MUcJ2d2b+8yRQ5ljmjDLm5DhN331Sn7NuqHeNUZqeZfRF4N3AC8L8NnvPz+Y5xciERPX6hmb3G3Yd2PUxERBYy5RyLyGz7ItAF3GJmF5nZ2Wa2cpzyv66z7Z50vWwS5726uMHdtwO/BTqImS4m5O7oHuqDAAAgAElEQVTH17sAGgwoIjIPqXMsIrPK3T8GvAy4C3gDcDmw0cx+ZGYn1Cm/rU411aVvmuvsG8vGMbZX0zKWTKIuERFZIBZsWkV/S/xCu9+D2effmq5ILdhneQy+Y3M23mafzbGc88A+kRbR15lNydZeTbGwyJ3w3Ig3SwPxmqqLdnmWjlFKA/c2ViK1Y+tglnKxsimWku5vzsoPDsXUar1pIN7Dni11V6rYqDb0VXLL4JVjW1NqZyVXZ7V9bU3RZ8gP51/ZswiRucDdPwd8zsyWAqcCzwbOB75nZkdP0+C4VWNsr85WsX2M/SIisoAt2M6xiMw/KSr8HeA7Ft/szgdOB74+Dac7A/hcfoOZLQGOAwaBW/f0BI86YAnXaXEAEZF5ZcF2jgdaI7LavT37BXZNipt2H9QFwPBwV21f90PxS2rbtogg97f21PYNWURtPUVmm3LR4aY0Ei+tE0KzZVPADaXI75ZSRLGHBrNFN7Y1xbZt5SwCPDQUg/N2Dsa+ActC1OVyRJMtha3z07C1ECdvSW3wrAlYWlikXIrju7q6a/v26cnuo8hsMbMzgavccy+ssG+6nq4V7l5iZp8qDMq7kEin+KwG44mI7J0WbOdYROaNy4E+M7sW2AAYMY/xicB1wPen6bxXANeY2VeBB4h5jp+Q2vD2aTqniIjMcRqQJyKz7e3Ar4DHAa8hplJrBd4GnOnuu0zxNkUuSuc7jpjb+GhgPXBqcb5lERHZeyzYyHFLSiNY0ZLdxSXNaRW7lHbQ3ZWlVXSl+YM7t2wFoG9xNiNUqS1WuKMcB1p+MFz172pehWeD5QebY17jSn+kQAzkVtbbWolV+sqV7PtJaTilX6RrSnXOQ9TRNJIN7mtJqRNd6b6WcwPyWkbiuGr/oi23St+y1g5EZpu7XwJc0kC5dePsW090bIvbbZfCDRwnIiJ7L0WORURERESSBRs5XjkS/f4VS7JBZ8MdsW1HJQa+NXdlK9bt3x0D1TZti9mbtg/21vaNpJFubeU0bRtZBLhSiYisp68ZIyO51enScZWhtLJeUxbR7U+D9MqlbNtIOeotVwfplXeNHHstcpzta2uKQXrLO9JKfF3ZhG0jO2IlveZ0XH85izhvHsgGCIqIiIiIIsciIiIiIjULNnJ8xKKlALRuvq+27cHeyCceGI4oantrlh+8JGUm9myLqd+6N2XjcSrtsXPIonwLWRpjc1qAo7ptOJdXPJyKldIf5ebsuHKKHI+UclHokTR1W3XRkVxd1W8xI2mf5yLANhJ1LVocOdRH7rdPbV9fmlpu447IcX5wR20XvYOaqUr2Pu5+ITFlm4iIyC4UORYRERERSdQ5FhERERFJFmxaxf5pKraeTRtr2zYPxkJbw72RW9A32Ffb19YZg9kWpSnPmm++OduXVqMb2H8/AEpNWTpG2aur56WUCcsPsIvUh+qsa2XLvotUUygq5Sx1YmQk+ztVUPuzunaYV1MtcmVHSnGCytAAAB2549q7Yrq2u9IKgA/lVulrb1+EiIiIiGQUORYRERERSRZs5Lg6MG7VspW1bS0DnQAMbI0I6+DA1tq+wfRItBKR4+77HqjtKw9ElLebiC6XVmYLhGxuSgPx2uJ7RndugF1zJY4rjaTosmffRZrStkoqA2Dpb0uD+0ZGsn2kfZ6iwpYbFGgpkr1jZ9yvBzdmgwlXdi+ONqQIde/wYG3fwHAW5RYRERERRY5FRERERGoWbOT4zs2bAFjbleXVLl4W07vtWBK5xsPlbKGPob6Ywm04TXlWXWoaoHXrFgBKN94UZQ47IKtzRUSRrScitPkHdCDlH1taGKQpFwhuqS4znVvctilFoS1NvzZSyg6oVHON08Ig+ajyYNq1eSimZmsli4j3D0YkvC8tST0ykkWLvZRNByciIiIiihyLiIiIiNSocywiIiIikizYtIp7+yN14o5Klkbw0M5Ij7i9JVIMDlneVdvnD90PQHlHHNfW01nb194S3yE2b74LgN4td9f2tSyN1egWL46Bf6WDVmd1ro59g2naNatkORRNaXCek5uurToNnFWnh8tSJ7w6dVt1kF8u5aKcUiyqmRabBrJ0iXI50kQG00p+TbnvQ17Ozi0iIiIiihyLyBxiZmvMzM1sfYPlz03lz53CNqxLdV44VXWKiMj8sWAjx3enaO93y0O1bb0pSrvTI4q6sqW9tq+5P6LJ5aY4bvHSfWv7Sjtj4YyW0mYAlpayiGvLQCyusXhrWlBkx7bavr7BgwAY2D+iyn3tS2r7PA3SG8kt2DHUHBHf5hQ5LuUix8OVNIVbJdpZKecG06WoclNaZKSzo6e2q5wG3ZXLEZVuacqi1yOWGw0oIiIiIgu3cywie4XLgWuBByYqOBtuum87a97+7Vk594YPnTUr5xURme/UORaRecvdtwPbZ7sdIiKycCzYzvGO1lYAesvZinXW1gFAV8q07t++o7Zvccpg2GfVKgBaO7P5kbdv6QegvSkG6XV1ZIP8KiNpRb3m2NZRylags7vvA2BJGgw3sn/2cPe1pgF/uQGDRkqPqKZTlLK0B8dHnc88u1+VlJrR1NoW92VRllbRuy3mPB4ajvSK1o4slaRc0YA8mbvM7GjgQ8DpQDvwG+B97n5lrsy5wGeB89x9fW77hvTnscCFwHOAA4D3u/uFqcwq4APA04HFwO+Bi4C7pu1OiYjInLdgO8ciMq8dCvwcuBH4d2A1cA5whZm90N0va6CONuCHwHLgSmAHcCeAme0D/Aw4DPhpuqwGLkllG2Zm142x6+jJ1CMiInPDgu0cV2OuLc3N2cam+LvsEX1tXZJFhw885BAAulsiQtubW4GurSMeptahuG5rzepsJqLRngb5DbdlD2lbXwwGXHVnrNbX3JRFbQf2jRX1hi2bTq4j7W9Ng+0q5dx0bemUw2nwXX6at0pq67DHcfc//HBtX2lwIK5rZbOI82BJkWOZs04HPurub61uMLNPER3mS8zsCnffMebRYTVwC3CGu+8s7PsA0TH+uLtfUOccIiKyl9JUbiIyF20H3pff4O6/Br4ILAWe3WA9byl2jM2sFXgR0EukXNQ7R8Pc/fh6F+C2ydQjIiJzw8KNHKdpyiyX01ud6sxSBLnUkd391mVLAeguRbS3uSmLzA71R/S1ZWdL2pd9p+jujMhxa4omj7Rm0eFKmkatPS0sUro/G1C/T3tEcB9Y3FbbNjIS9bek4K5XcnnFKR+5uk6Ij+y6QEg55VdvGckCatV85JFaHnMWLS7losgic8z17t5bZ/tVwMuAxwL/NUEdg8ANdbYfDXQBP0kD+sY6h4iI7IUUORaRuWjjGNsfTNdLxtif95C7e53t1WMnOoeIiOyF1DkWkblo1Rjb90vXjUzfVq9jnD92onOIiMheaMGmVTTXVn/LfT6mFItySlHYOJSlFWxti6nf2lMqRM+ibKBc0+YtUWdzPFzt7a21fW3tbaPO1+XZQ2rdUc5SGsbQQH+27+H4fO7rzAJg2y3q6k/tHLbcoLs04K96ryx3tzyVt7R3xHMD+dL9r00Fl5varlI3qCYyJzzOzHrqpFasS9e/2YO6bwP6gePMbEmd1Ip1ux6yex51wBKu02IcIiLziiLHIjIXLQHend9gZicQA+m2Eyvj7RZ3LxGD7nooDMjLnUNERPZSCzZyTAqe5nv/Vo0ie0RYHxwYqu27pyWivM0pNNuRi6q2p+jw0qUxaK89N5VbdVEOqlOslbI6rTMW+mhdGlHoxTuzyHHb1vh7n6VZ0KpvcZTrt2hLxbPWN6f2jFQH4uXaV40iV++fe7Z4SC3W7NUBiuxynMgc9GPg5WZ2MnAN2TzHTcArG5jGbSLvAJ4IvCl1iKvzHJ8DfAd45h7WLyIi85QixyIyF90JnApsBV4FPB+4HnhagwuAjMvdNwGnEavrHQ28CTgOeDWxSp6IiOylFmzkuLpIRj5SWp3+zFN+cB9ZBPhPaeGNVUtjcY6d/Vmq40iKCi9ZEvnBnbmc461bYoGPaqx2cCSbKq2luhx0ephbLXu4fTgizis3ba5te6gl2tffFedpHcm+u1g5wrylOouA1CLGKfc4d5ezSHM6rmkkn6ys0LHMLe6+gezlBPCsCcqvB9bX2b6mgXM9CJw/xm4bY7uIiCxwihyLiIiIiCTqHIuIiIiIJAs2rcIqo1eUg2was0r6wbSS+26wNRXcNBzpFas9N+guDWZrbUnTto1kv7h2tsWgu/LwIAADTaXavlIptjUNxHlGcmkcIyn5oXPb1qyuzkjXaGrriQ3DuRXsSqXU5nS/8iv/eTWtolo+l1hRTS9J970pn1Ux5jSwIiIiInsnRY5FRERERJIFGzluSlHU5ty0Zp7Cpi1p20g+wNoUN7o7ugFYvbSntu/eoZiebWhnRJVHSrkD29NDmCLPbU3Z943tfTsBKJXSvq6sTmuJNvjgYG1b5/aBaF93nKevKYs0kwb6VaoR8UoWVbbqIMBKKpMdRSVFjltGdo2ki4iIiMhoihyLiIiIiCTqHIuIiIiIJAs2raIlzQvclJuttCnNb1yd59g8S0BYlEbprWiPVepy2RG1wXbb+mNRLstNgbq8O61q15YGzOVyNdpb2wEYLsfxI7k5kKtt6SKbM3nlQNSxaXsM0tvR01XbN5zaVylH/U25OYpr8zenQXqlXGJFqRzn9NLoMgBZa0REREQEFDkWEREREalZsJHj2kpwo0LHcVWd8qx5OIudHrgoorSruxcBsOOh+2r7hndExHjHQFo1r7O9tu+AShw30hoR4MFcZLanI0V+W9Jxlg2w60uD9doq2feTJTuj3FKPgXlbm1bV9lVaoq5Kul+Wm4atOjavOuVcNTIO4IXZ3TwXLnatkCciIiIyiiLHIiIiIiLJgo0cW5rWjHwUtbop5eEuyk3JdlTPAQCsSjnEf+rdUts3UIryW1JktjSYLfRxVArNrlixDIBNrdnUbG0tsUBIT4rQVvN/AXYORF07S9m28o44Z0d/lO/OTUPXsjSiyEO1Tbnc4WpecdpWLmfTvLWlu9hejSrn2qBvRiIiIiKjqX8kIiIiIpKocywic4qZbTCzDbPdDhER2Tst2LSKtnIMaqsOYANoTikWrWnTgU3ZNGqPWBZpETu3bwNg89attX1b06C+ezraAHDLvlP8oTcG1h1SXSmvLXtIq0kbbe3tqS1ZSkNLa9SxdSBL0ejr74tyad+ih7LUjqbeONa6os3WnLXBU8qENceAv2bfdcq41tSY4bTaH0D2l4iIiIjAAu4ci4jMtpvu286at397Sura8KGzpqQeEREZ34LtHHemAXUjlWxw2r5LlwOwPE2xtm8lm1qNrZsBuPHO2+K4chZx3pmmZ+tvjShsS24qtw2DEe0d3rwRgFWLl9T2dSzvAKCvN6aCG+rfWdtXHozIdmmwv7ZtR1pcpNweA/k6cwPrWrc+HH9si22eW6WkuS3OY83x72z17LhKJULGlgYFNuX2WUvu/ouIiIiIco5FZOZZeJ2Z3Wxmg2Z2n5l9ysyWjHPMC8zsR2a2LR1zq5m9y8zaxyh/tJmtN7N7zGzYzDaa2ZfM7BF1yq43Mzezw8zs9WZ2g5kNmNlVU3i3RURkHliwkeMlfdsBGMlNXXZwT3zurq5GWIezrNt7fn8rAHdvisU/Dl6+b21fR1+UW1kaBrLcXgDvSJHZwbiulLMc4h29EVXe9HBEfYcGsshxbaq5HX21bUMW7aqkCPfidD6A5k0RCfeUl0xT9q+r9gw8bSuVsjZ4ihyn1acZbMqmr+uwLOdaZIZ9HHgD8ADwaaAEPAs4GWgDhvOFzexS4DzgXuDrwDbg8cA/Ak80sye7Z8n2ZvYU4H+AVuBbwB+BA4HnAGeZ2Znufn2ddn0C+DPg28B3gJE6ZUREZAFbsJ1jEZmbzOxUomN8B3CSu29J298J/AhYDdyVK38u0TG+HHiRe1pCMvZdCLwHeC3RscXMlgFfBvqB0939llz5RwHXAp8BHleneY8DHuvud07i/lw3xq6jG61DRETmDqVViMhMOy9dv7/aMQZw90HgH+qUfyNQBs7Pd4yTfwQ2Ay/KbXspsBR4T75jnM5xE/AfwGPN7Jg65/rwZDrGIiKy8CzYyPHikWr6QNb/r2yPVIu+oUg76Mj9YLp9Rwya67ZImehoyVIO2lNKwupUl5ez1IRKSmVYsU8PAPt2ZSmTDz34EADDw/EL8VAu3aEpDZAbrmSr4LW3tY5qcWt71oa2pYvjPO0x+K6SWyGvtSO2ldPgw1Jumremprg/FYvynZWs7SWNx5PZUY3YXl1n30/JpTKYWRfwGGAT8CbLrXiZMwSszd0+JV0/JkWWi45K12uBWwr7fjlew+tx9+PrbU8R5XrRaRERmcMWbOdYROas6jfIjcUd7l42s025TcsAA1YS6RONWJGuXzFBuUV1tj3Y4DlERGSBWrCd444U0W3KD55LQafhFGHtSlFYgKY0rVmPR9R1oK83q2tRlOvsTIuA5M4zODgIwEiahm3RsixyXF1wY/PW+Kzv6M4+i6tt6WzN2tCW2tDSGuehNbfQR1Ns6+qKs1c8F71OgbZSOY1haslaWEpT0jWnaHKHZ/vaPH9PRGbM9nS9CvhTfoeZtQD7EAPv8mV/4+6NRmGrxzzG3W+YZNv0ohAR2cst2M6xiMxZ1xPpBmdQ6BwDTwBq32jdvc/MbgYeaWbL8znK47gW+Cti1onJdo6n1KMOWMJ1WrxDRGRe0YA8EZlp69P1O81seXWjmXUAH6xT/mPE9G6XmtnS4k4zW2Zm+ajyZ4mp3t5jZifVKd9kZut2v/kiIrKQLdjI8fJlywDwXOpAa2sMcOvp6o7bpWxfz+IY8FZdUa6rsys7rif+9pTm0Lczm6/Yq/Mop/M88FCWRtmRBtgdcMhBUXeuLZbSMLwpS/uoDqirjtFrbWvL9qXzjAzHoL5SKZujeXCoP22L9pWzwBv9/VGuOpBpZCQ3ClFpFTIL3P0aM7sYeD1wk5l9jWye463E3Mf58pea2fHAa4A7zOx7wN3AcuBQ4HSiQ/yqVH6zmT2XmPrtWjP7AXAzkTJxEDFgbwXQgYiISMGC7RyLyJz2RuAPxPzErySmY7sceAfwu2Jhd3+tmV1BdICfREzVtoXoJH8E+EKh/A/M7Fjg74C/JFIshoH7gR8SC4lMtzW33norxx9fdzILERGZwK233gqwZqbPa67ooYjIlDOzISJ/epfOvsgcUV2o5rZZbYXI2B4DjLh7+4Qlp5AixyIi0+MmGHseZJHZVl3dUc9RmavGWYF0WmlAnoiIiIhIos6xiIiIiEiizrGIiIiISKLOsYiIiIhIos6xiIiIiEiiqdxERERERBJFjkVEREREEnWORUREREQSdY5FRERERBJ1jkVEREREEnWORUREREQSdY5FRERERBJ1jkVEREREEnWORUREREQSdY5FRBpgZgea2aVmdr+ZDZnZBjP7uJktm2Q9y9NxG1I996d6D5yutsveYSqeo2Z2lZn5OJeO6bwPsnCZ2XPN7GIz+4mZ7UjPpy/sZl1T8n48lpapqEREZCEzs8OBnwH7At8EbgNOAt4IPMXMTnP3zQ3UsyLVcxTwQ+ArwNHAecBZZnaKu/9peu6FLGRT9RzNee8Y28t71FDZm70LeAzQB9xLvPdN2jQ813ehzrGIyMT+lXgjfoO7X1zdaGYfAy4A3g+8qoF6PkB0jD/m7m/J1fMG4BPpPE+ZwnbL3mOqnqMAuPuFU91A2etdQHSK/wicAfxoN+uZ0ud6Pebue3K8iMiClqIUfwQ2AIe7eyW3rwd4ADBgX3ffOU49i4CHgAqw2t17c/uagD8Bh6RzKHosDZuq52gqfxVwhrvbtDVY9npmto7oHH/R3V88ieOm7Lk+HuUci4iM78x0fWX+jRggdXCvAbqAx09Qz+OBTuCafMc41VMBvlc4n0ijpuo5WmNm55jZ283szWb2VDNrn7rmiuy2KX+u16POsYjI+B6Rrv8wxv7b0/VRM1SPSNF0PLe+AnwQ+GfgO8DdZvbc3WueyJSZkfdRdY5FRMa3JF1vH2N/dfvSGapHpGgqn1vfBJ4BHEj80nE00UleClxmZsqJl9k0I++jGpAnIiIiALj7RYVNvwfeYWb3AxcTHeXvznjDRGaQIsciIuOrRiKWjLG/un3bDNUjUjQTz63PENO4HZcGPonMhhl5H1XnWERkfL9P12PlsB2ZrsfKgZvqekSKpv255e6DQHUgaffu1iOyh2bkfVSdYxGR8VXn4vyLNOVaTYqgnQb0A9dOUM+1wABwWjHylur9i8L5RBo1Vc/RMZnZI4BlRAd50+7WI7KHpv25Duoci4iMy93vAK4E1gCvLex+LxFF+3x+Tk0zO9rMRq3+5O59wOdT+QsL9bwu1f89zXEskzVVz1EzO9TMlhfrN7OVwGfTza+4u1bJk2llZq3pOXp4fvvuPNd36/xaBEREZHx1liu9FTiZmHPzD8Cp+eVKzcwBigsp1Fk++pfAWuBZxAIhp6Y3f5FJmYrnqJmdC1wC/JRYlGYLcDDwNCKX89fAk91defEyaWZ2NnB2urkf8JfE8+wnadsmd/+7VHYNcCdwl7uvKdQzqef6brVVnWMRkYmZ2UHA+4jlnVcQKzFdDrzX3bcWytbtHKd9y4H3EB8Sq4HNwBXAu9393um8D7Kw7elz1MweDbwFOB7YH1hMpFHcDHwV+Hd3H57+eyILkZldSLz3jaXWER6vc5z2N/xc3622qnMsIiIiIhKUcywiIiIikqhzLCIiIiKSqHM8CWbm6bJmttsiIiIiIlNPnWMRERERkUSdYxERERGRRJ1jEREREZFEnWMRERERkUSd4xwzazKz15vZ78xswMweNrNvmdkpDRy70sw+aGY3mlmfme00s5vM7P31luMsHPsoM7vUzO40s0Ez22Zm15jZq8ystU75NdXBgen2483sa2b2gJmNmNnHd/9REBEREdl7tcx2A+YKM2sBvkYs4wpQJh6fpwNPMbNzxjn2CcQShtVO8DBQAR6ZLi8xsye7++/rHPs64BNkX1T6gEXAqelyjpmd5e79Y5z7HOALqa3bgZFG77OIiIiIjKbIceZtRMe4ArwVWOLuy4DDgO8Dl9Y7yMwOAb5FdIz/DTgS6AS6gUcDVwIHAf9jZs2FY88GLgZ2An8PrHT3HqCLWBLxdmAdcNE47f4M0TE/1N2XpmMVORYRERHZDVo+GjCzbmJd7h5iXe4LC/vbgeuBY9KmQ919Q9r3BeBFwIfc/R/q1N0G/Ao4Fnieu38tbW8G7gAOAZ7i7t+rc+zhwA1AG3Cwuz+Qtq8h1hwHuAY43d0ru3fvRURERKRKkePwF0THeIg6UVp3HwI+WtxuZl3A84ho88fqVezuw0S6BsCTc7vWER3jm+p1jNOxdwDXEikT68Zo+z+rYywiIiIyNZRzHB6Xrn/r7tvHKHN1nW3HE1FdB240s7Hq70zXB+W2nZqujzSzB8dp25I6x+b9fJxjRURERGQS1DkOK9P1/eOUua/OttXp2oBVDZynq86x7btxbN7DDRwrIiIiIg1Q53jPVNNStqfBcLtz7Dfd/ezdbYC7a3YKERERkSminONQjb7uP06Zevs2puvFZrakzv7xVI89eJLHiYiIiMg0Uec4XJ+ujzOzxWOUOaPOtl8T8yEbMfXaZFRzhY81swMmeayIiIiITAN1jsOVwA4i//eNxZ1pOra3FLe7ey/w9XTzfWbWM9YJzKzFzBblNv0AuAdoBj4yXuPMbNlEd0BERERE9pw6x4C77wQ+nG6+x8zebGadUJtT+HLGni3i7cAW4CjgZ2b2lOqSzxaONLM3A7cBJ+TOWQJeR8x08QIz+4aZHVfdb2atZnaCmX2YbE5jEREREZlGWgQkGWP56D5gafr7HLIocW0RkHTsicA3yPKSS0QkuoeY6q1qnbuPmhLOzM4DLsmVG0iXJURUGQB3t9wxa0gd5vx2EREREdkzihwn7l4G/gp4A7EqXRkYAb4NnOHu/zPOsb8CjiaWoP4ZWae6n8hL/mSqY5e5kt39s8AjiCWfb07nXAxsBq4C3pP2i4iIiMg0U+RYRERERCRR5FhEREREJFHnWEREREQkUedYRERERCRR51hEREREJFHnWEREREQkUedYRERERCRR51hEREREJFHnWEREREQkUedYRERERCRpme0GiIgsRGZ2J7EU/IZZboqIyHy1Btjh7ofO5EkXbOf48DX7O0C5PFjbVl0oe/V+SwE45xmn1PYduXpfAGwkSnV2dmfHeTMAQ4PDADzc21fbt3lwCICeRe0AHNizqLavvb09/dEadefaVxmOdpWbsuW779vYC8Ad924BoFTJ9jU3R5C/PBK3m8j2HbZ6BQAH7LO4cE+hqyP+xd1tTel2a23fYH9UdtI578o3TUSmxuLOzs7la9euXT7bDRERmY9uvfVWBgYGZvy8C7ZzTHP095pGsk1m0UE88pDVACzu7Kjt+/VtdwLgI2UAjjo0+5LS2hQPU7kUHeFK7jSlUty6f/N2AIZ3lmv7upujU728pzPqac06pr1DJQC2Dmad9029OwFoa4tOdXtTlvUyNBLlB3dGB3pkODvPnU1R741/2ghAZ1Optu+g/VfGfe2ONrS1ZHUOlqKzfxIiMg02rF27dvl111032+0QEZmXjj/+eK6//voNM31e5RyLyJxhZmvMzM1sfYPlz03lz53CNqxLdV44VXWKiMj8oc6xiIiIiEiyYNMqPKXdVlMpADpSDvCIRxrCr357d23fxo2bATjx5GMA6K/srO1rKkVlTR4P19BwlqsxsDPSIkopjePhgSxNYrAtyre3xnlbfai2b7gp0iIqrVmSRktXpGGUd8a24VKWHuEp59jSdamUpVXsHIj0iN507s6ludSJStTRuyWuK7k0k+GRrD0i89TlwLXAA7PdkFi2QsYAACAASURBVHpuum87a97+7dluxl5nw4fOmu0miMg8tmA7xyKy8Ln7dmD7bLdDREQWjgXbOa7GTkfyG1M0+fY77gWgNJxFeY84YBkAjzm8B4AV+zbX9u1Ig+x6t0QFQzuzyR1a94vyXSu64nbuhA/dvQOAwRTR7ejOBgB2pcF51VkoADwNshusTkmRG/rX0RLtsc7UruGsDYt64t+4cv994nZLNvBvaZpFY/HiKNOam8liy7aZHwEq0igzOxr4EHA60A78Bnifu1+ZK3Mu8FngPHdfn9u+If15LHAh8BzgAOD97n5hKrMK+ADwdGLKtd8DFwF3TdudEhGROW/Bdo5FZF47FPg5cCPw78Bq4BzgCjN7obtf1kAdbcAPgeXAlcAO4E4AM9sH+BlwGPDTdFkNXJLKNszMxpqO4ujJ1CMiInPDgu8cm+UirF0RRa1O9bttKIui7uiLKOpAb0yVRs+K2j4fikju8p6I2i5KUWKAZftEuUVL46Hc/PC22r6VbVF+pBz7hi2LBJfSNG0tTW21bc3dUW5JmmK5tTM3aVw69o4/xi/I3Suz6PAjj415m5vTv7MymP1bu9Mcy92dcb7KcBYtrpSy6LjIHHM68FF3f2t1g5l9iugwX2JmV7j7jgnqWA3cApzh7jsL+z5AdIw/7u4X1DmHiIjspTRbhYjMRduB9+U3uPuvgS8CS4FnN1jPW4odYzNrBV4E9BIpF/XO0TB3P77eBbhtMvWIiMjcoM6xiMxF17t7b53tV6XrxzZQxyBwQ53tRwNdwG/TgL6xziEiInuhBZtWkWZWY8Sz1IkDVkUKxDFrYoW8q6+/tbZv07Z+AK773X0AdDZlK74uWxrLMq9aGUtDm2ej7lrSinojW+O6vZSlcRy6XwzyG0hTrVVGsunXWlJuR9c+K2vbOpdH+0YqMcVa01C2TPXWzZGu8dBd0b4VK5bW9h22T7Srd3sc15pbInqkHOfssNi2LHdcV7umcpM5a+MY2x9M10saqOMh99wbQKZ67ETnEBGRvZAixyIyF60aY/t+6bqR6dvqdYzzx050DhER2Qst2MixpX5/axbIZb+eGJB32jFHANDfn03l9s2f/gqAn98Uszgdst+a2r7lPRFtHUqLc3R2ZJVac0SR29piYF2bZdO1WSXa0NkdA/hGSsO1fc3tsW/R0vbato5VcexwKSLVD96eRXZ/du0GADbcvQWAA5dkke3+jXHupjSFW2tzNpCvNU0V19Ua/YSe7uxfXvHcgyMytzzOzHrqpFasS9e/2YO6bwP6gePMbEmd1Ip1ux6yex51wBKu04IUIiLziiLHIjIXLQHend9gZicQA+m2Eyvj7RZ3LxGD7nooDMjLnUNERPZSCzZyLCLz2o+Bl5vZycA1ZPMcNwGvbGAat4m8A3gi8KbUIa7Oc3wO8B3gmXtYv4iIzFMLtnNcIVIGunOr0h2cBsh1tce+xxySDYarlI8D4K4HNgNw7e+ywXodaTW7RxwUKYrDbVk6Qk917uP2SG1obs1SGobT/MjDpeo5sofbPcoNbNxU29aU1vMbTqvhdTdlcxIvXRT3o7urM+oayeYo7tsS5VativSPxd3ZgLzmNGdy96Joc0duruXe3iytRGSOuRN4FbFC3quIFfKuJ1bI+96eVu7um8zsNGK+42cAJxAr5L0a2IA6xyIie60F2zkWkfnH3TcA+WT4Z01Qfj2wvs72NQ2c60Hg/DF2KyFfRGQvtXA7xx7h2kVdi2qb9l0SkdX25rjbaw87qLbvhEceCUDv9lgv4MY7Hqjtu/PemD6tdygitC25z81VSyOSe+LaqKu7PVvxrqkpBttVB8WVK9kUcM3DEbXtvy9bUW/jvfF314oYkNfdnA22rw6oK6cV7kpWqu078IC4j4vbIirc1Z1FlZu74r6axZRupZ3ZoMBSbza1nIiIiIhoQJ6IiIiISM2CjRxbyuld3JpFUfddElHeFSsif7drcZabW/3biCTdo47K8pEf7osFQu7dGvnIf7g9iyr/6g+xXsDD22LGqQOXL67t61kcaw0sXtwDQEsli9R2p0jw/8/encfJXVX5/3+d6n1LZyEhISEkIgiCsrnrCI6KC+PoODpu44j+ZnHf5ysuM8I47o7r12UcRX4uI86ojKOCGwIKiigoCAaQJUBCyNrp9N5dVef7x7lVn08q1Z1Op5NOqt/Px6Op7s/9fO7nVqfoPnX63Hs392V1v7+8Keqcn3bWIwG4bUtWj3zZL2Kjr96OyEyf8uA11bbFy48AYGIsVqQqFbMl4Mbvj3E1Ed+Hptz3o1zMnr+IiIiIKHMsIiIiIlKl4FhEREREJGnYsorKUxsYySagbd8WZQota6NkwkeypdLGLe101xElF6ViVgKxLC0Ht2rJagDOWL262jacur9zfUzau/ferdW22zZGycWWgZjkV8h9u1N1BA9syTYAW7Iiyi/uHIzyiEt/fku1bWd/jGfFSasAuOyXt1bbRtLkvtPWRnnFiauy3fPamqOUpNAa74MKln0/zLWUm4iIiEieMsciIiIiIknjZo7TvLPh3GplD+yM7PC9GyIz2+zZhhiVeWoldgBgpaytvT0m6bX1pIlult/MI26wLG3SsfS4tdW2neMxke/bv/o9AL+5Z3O1bXg0Nvha0J1N/CsQE/i+eWVkjHcNZku/9SxcAsC6bZFp7ijsqLY9ds3KOKcU49p4T5a97uruBKB7QTzBhd3ZEnAUs/5FRERERJljEREREZGqhs0ceznifh/Pamy39Q8CsHlH1AC3FrL3Bi1pi2j3tHFHS9Y23hwFwt2jKZtcymqVdw2nTTlSU3Nbdt3CJVFDvPyIyAg335stzbZk0bK4T3O2aci9990PwIrlkU1eeXRWO2yWtsNui3+yhy3OtsU+vjPuuWs0lofbNZRlhAvjkWle2BG1x0WyjUWGxrLsuIiIiIgocywiIiIiUqXgWEREREQkadiyCmuKuH+olC1X1jcaE+QKLW3pnGy3uJGJmFjX1tYNQGtnZ7WtpT2dZ1GG0NqclSMsOyLOK6RyiomJrIyjuyvaVh15ZHzdubHaNjwe92vKlXZ4Ocohhkei/GNROdttryONxyzKIobHsufl6T6FQpRetPdkz2vVg6OtLT2HHZuzti27cpPzRERERESZYxE5vJjZejNbP9fjEBGRxtSwmeMmS5te5LLDvT2RFe5Ik9pamluqba1pwtpAmrQHWWa2NW2kUbb0dVd3ta1rQXw+UY5M8OjgWLVt+3BM/Nu6NR5HR7J15crp/HIhmyDXnZaDa0kbkvRt3VRt60sT8sZTxvmO0ew+D6yNpdwefuzq9DyzrPfIWJy/azDuMzJk1TZyn4qIiIhIAwfHIiJz7eaN/aw57/tzPYzD1voPnDPXQxCReUhlFSIiIiIiScNmjiuT08htAjdSihKDgUJMRFvSk60VvDhNarNS7Fw3kZvwNpLmrQ2mOoSdpazTrrGYgNfVltYR9qxWYThNzts+GGsNF8km8jVXSjpyu/QNDUZJx9BAlGEULCsJ6ehIJRct8bipL7d+8667AThqeUz8W7L8qGrblv7YDXBkJJ5PSzkr7Sg0Z/2LHEosFvZ+DfAq4FhgO3AJ8M5Jzm8D3gS8JJ1fBG4EPuXu/zVJ/68H/gF4UE3/NwK4+5rZfE4iInJ4aNjgWEQOax8ngtdNwOeBCeDZwKOBVqD67tDMWoEfAmcCtwKfBjqB5wHfMLNT3f0dNf1/mgi870/9jwN/DjwKaEn3ExGReahhg2NPWdpyfke4Yvy+K3dFlne0u63aVpkgN94RO9ZNtGRZ1YnmyAaPlCpZ3ixruyAd6+uLnfJacpvOFT0yzLvGI2trTVlWuZLZbksZZ4Dx8ZhkNz6Rfi+Xs0l3S5csBODolUcDsGJZNoZFnfHPuHxRZJWHJ7Id/IrN0daUloJrzU3CGx3V73859JjZ44jA+E7gUe6+Ix1/J3AFsAK4J3fJW4jA+DLgz929mM6/ALgOeLuZfc/df5GO/wkRGN8OPNrdd6bj7wB+AhxV0//exnv9JE0nTLcPERE5dKjmWEQONS9Pj++tBMYA7j4KvL3O+a8AHHhzJTBO528B3pO+/Nvc+S/L9b8zd/74JP2LiMg80rCZ44piOasP3pFqerekTO7QePb0u1Mt70Rn1AKPTOSKldNpTURWubs5u87SsnAjg5EyLpayjPPoYGRwR9IacO2d2aYezamPSi0xwNLuWBaukH6/D+6sxgUsXrwIgJXLj4hx5sY3ONAHwM5UU91WyuqKR8Yjw2xpKbhCV26Zt9x5IoeQ09PjVXXariY3k8DMeoAHAxvd/dY65/80PZ6WO1b5/Oo6519L1CtPm7ufUe94yiifXq9NREQOXcoci8ihpjc9bq5tSJnhbXXO3VR7bs3xhdPsv0RMzhMRkXlKwbGIHGr60+ORtQ1m1gwcUefc5ZP0taLmPIBdU/TfBCyZ9khFRKThNGxZhacl1YyszKFvMJZI27IzyhBWdGVtxVRiYBYT+EZzk+6sHO8h2tLp3tJabRtK8/2ae6Ncoaejt9q2Y/0DAJSIiX+dXdl1Ta2pM8smDI6WYoJcIU3ya85N1mtpi/KLkbQ8XH53v7G0G2BfelzQlP2zekccG5+IUpKiZ0vUjbdrKTc5JN1AlCOcCdxV0/YEyP6ndvcBM7sTeJCZHefuf6w5/0m5Pit+S5RWPKFO/49hFn8unryyl+u1kYWIyGFFmWMROdRclB7faWaLKwfNrB14f53zLyQ2Q/9wyvxWzj8C+KfcORVfzvXfmzu/FXjffo9eREQOaw2bOS4VKxnZbO2ykeHIzPZtj7+qLujJMqdjaZJe54IeANyyDKuV47xCWu6tmFsPrStNsqvsOdI3NFBtW795a9w3Te8pNGeZY69uCJKt/TYwFBMGC8U4tqinp9rW2dWdrouxlMvZ2BcuWhZtKZvc2tFdbevoaEnPbxiAXcPZX5eHchudiBwq3P0aM/sU8DrgZjP7Jtk6x33sWV/8EeAZqf1GM7uUWOf4+cAy4EPufnWu/6vM7PPA3wO3mNm3Uv/PIsov7if/P6aIiMwryhyLyKHoDURw3E/sYvciYqOPp5BfaJzqEmxPJds973XEcm1/BF7s7m+r0/+rgDcDg8ArgRcTaxw/FVhAVpcsIiLzTMNmjrGU+MltzzwyHJtqbNsSNce9i7IMcGtbZFiL45FdLuW2WW5Py7VZSg+PjWebcxQKke1taY264g33ZJnZO+6MBNdYWgLOC1l9cXt73M9yme2WlFlubo73LE252mZrivNb2rvSudkScOVULz0+mH6fL82WayunJdyaWuM59DZny8lNjOfnKIkcOtzdgf+bPmqtqXP+KFESMa2yCHcvAx9LH1VmdhzQDazbtxGLiEijUOZYROYdM1tuZoWaY53EttUAlxz8UYmIyKGgcTPHIiKTeyPwIjO7kqhhXg48GVhFbEP933M3NBERmUsNGxxXlmQrlrKd5EqpUrFvR0yaa21ZWW1buiSWPB0djV3tSrnd4ybGojTD01JrI+NZn5Xd71rH45xt26q70TI2EuePprk93pQlqorFGExTbjW1QlOMuZxKQYrlrAxjaGQ0nR//ZAt6sqXcmjw91zSp0MnKPrxyy9TXgp5ssh7lhv3nF9mbHwOnAGcDi4ld8W4HPgl8PJV1iIjIPKToSETmHXe/HLh8rschIiKHnoYNjtM8NGI32FBJIg8NR4a1nNsgpJA25bCJSBi1tGTfmqaU3u3oiMlwZc8ywC0tkcFNe45QtGwC4FgpMrgla01jyq4bHa5kd7PzK2NtTRP/OnKZ5oH0eXPqo7sz22ykMnlwvBzLtbV0Zs+rvTPuXRwbT/fIMuIiIiIisjtNyBMRERERSRQci4iIiIgkDVtWUSlXKBSydYQrZRX9/UMA9KVHgMXLo+yguze+JW0t2YS3jvYOABYtjJ1svZS9p9iVSjR29Md6xyMT2a5z45UZgJXyiFI2lnIxBlMu5+f9pAl5aZ3j8YmsJGQs7fg3lvoYyq217EQ5xZErl8QYcm3NrfE8OlpjXeTcUsuMj2XniYiIiIgyxyIiIiIiVQ2bOa5kZM2ybG3l85GRyOjev2Frta2jK3a46+mOx9xcOHp64rqJ4tBufQMMDsdybTt2DKZzsmzvRDHaimmZt9bWLBs9nnbiK05kE+Q6O2Nnu/FynD80mu2S29Ie5zUNxlJzNGVj6OqNe/YPx+S71rHsPm0dY2kscV1T7p98OI1BRERERIIyxyIiIiIiScNmjqkkjHM1ts0tscTZRMr8btncX21buHgBAEPDUZs7OprVDre0xnkLFvQB2dJuAONpQ5Cx0bScWilbmq21Pc7btXUXAMOD2XuRUjovl9imstJbW2tkgCcmsprggYEYQ0tTXDDalrUNjUfWevuuuN/I+Ei1bfO23TPonW0Lqm0+3oWIiIiIZJQ5FhERERFJFByLiIiIiCSNW1aRyik8V1ZhhXgvUEhPu2/bQLVt5/YoTWhOE94mStnEukonA/2xZFq+rKJUTGUUade8Um75tda0615Xd0e6Pit3KBT2HOD4cOo/Db65pbXa1tnVA8ARy9JybcObqm192zfH82uLc0ZHs0l+Pd3taSwx2a8zV47R1MD//HL4MrP1AO6+Zm5HIiIi85EyxyIiIiIiSQOnDiP76p5NkKMcGdXmlEGeyGVYRwZimbaFbQsBGBvPllEbS5tljKVl25oK2VJpFW1tsQRce3tb9VhLWhbOy3F+NctMlh22UjaG1jSuzp6YKNexaFm1beXqB8X4uiMb3bfp1mrb0JbtAIy2xCTCgf7ObOy9vQD09KQDPbml7fZ4FiIym27e2M+a874/18M4ZKz/wDlzPQQRkb1S5lhEREREJGngzPGePNX3VnaUzm/cPJAyx0uOXJIac3lVb9rtglKuHrmyFFuxGBng/v78lsxxXUtL1P22t2dLp7Wn7amXLe6pHhsdjuXamprjvPaerK2zM/rY2R/1xXfdn21gMjSWnldTZI57yG020pG2nU4bkdhgVvfsxSw7LnIwWawt+BrgVcCxwHbgEuCdU1zzIuDvgdOAduBu4GvAh919j73QzewE4DzgycCRQB9wOXCBu99Wc+5FwMvSWM4B/g44DviVu58182cqIiKHm3kVHIvIIePjwOuBTcDngQng2cCjgVZgt3duZnYh8HJgA/AtYCfwGOA9wJPN7KnuXsyd/3Tg20AL8F3gDmAV8FzgHDN7krvfUGdcnwD+BPg+cClQqnOOiIg0MAXHInJQmdnjiMD4TuBR7r4jHX8ncAWwArgnd/65RGB8CfASdx/JtZ0PvJvIQn8iHVsEfB0YBp7o7n/InX8ycC3wBeD0OsM7HTjN3e/eh+dz/SRNJ0y3DxEROXTMq+C4skscVllGLSud6O9Lk+6GYtJdR3M2qc1SyUQhfbfyy7xNTKSd8caipGEitzRbpdSitS2SYF7OJuR1pmXaFi7JJt3dvnlbjGXgfgAesmhFtc1L0f+mBzYAMDI+UW0rl2Jgu3bGUnD58o1K3Ufl1hMj2djHRrIdAkUOopenx/dWAmMAdx81s7cTAXLeG4Ai8Ip8YJy8B3gt8BJScAz8DbAQeG0+ME73uNnM/gN4o5k9tLYd+NC+BMYiItJ45lVwLCKHhErG9qo6bVeTK2Uws07gFGAbEdDW628MODH39WPT4ykps1zr+PR4IlAbHF831cDrcfcz6h1PGeV62WkRETmENW5wXOeXaOVIwWKRjjJZJndsLDKx6+/aCMDqtUdW23oWxmS4sfHIBJdLWXa4RBwrWVrmzbMFQJqa06YjTXGfppZs85Cyx+//Um6pud6Fsexa366YHFicyLLDu/ojy9u3PRJtYyPZ/KOJNNmusgFJqZT12b+jLz5J5y9Z3F5tK3RpQp7Mid70uLm2wd2LZrYtd2gR8b/uUqJ8YjrSrFr+bi/nddc59sA07yEiIg1KS7mJyMFWqec5srbBzJqBI+qc+1t3t6k+6lxzyl6u+f/rjM3rHBMRkXmkcTPHInKouoEoNzgTuKum7QlU1kAE3H3QzG4BTjKzxfka5SlcC/wlserETbMz5Jk5eWUv12vjCxGRw0rDBseF6kS0LKFUTpPlSuVKuUKWJCqk3el27hqMA3dnpQkPP2kNAMtXLgCgfySbEzQ2FmsK9/fHdcVcycXizvirbXtzTL4bHctKIbbtiNKJrVuy3/WLFnQA0JN21msuZ5Pn+rbFX6A3bYy/+vb1DVbbWlvj/K6OmIg3ujO7TzHtmjfeEeeXm7KJhh09e+70J3IQXAT8LfBOM/tObrWKduD9dc7/KPBF4EIzO9fdd+Yb0+oUa3NLs32JWC/53Wb2a3e/rub8ArGKxZWz+JxERKRBNGxwLCKHJne/xsw+BbwOuNnMvkm2znEfsfZx/vwLzewM4NXAnWb2Q+BeYDGwFngiERC/Mp2/3cyeRyz9dq2ZXQ7cQrwbPpqYsLeE2EjkQFqzbt06zjij7nw9ERHZi3Xr1gGsOdj3NXeV2InIwZXbIe81wIPIdsh7B3AjgLuvqbnmz4gA+FHEUm07iCD5R8BX3f3WmvPXAG8FnkYExePA/cCvgW+5+//kzr2I2CFvrbuvn6XnOEaUiNw4G/2JHACVtbhvnfIskblzClBy97aDeVMFxyIiB0Blc5DJlnoTmWt6jcqhbq5eo1qtQkREREQkUXAsIiIiIpIoOBYRERERSRQci4iIiIgkCo5FRERERBKtViEiIiIikihzLCIiIiKSKDgWEREREUkUHIuIiIiIJAqORUREREQSBcciIiIiIomCYxERERGRRMGxiIiIiEii4FhEREREJFFwLCIyDWa2yswuNLP7zWzMzNab2cfNbNE+9rM4Xbc+9XN/6nfVgRq7zA+z8Ro1syvNzKf4aD+Qz0Eal5k9z8w+ZWY/N7Nd6fX01Rn2NSs/jyfTPBudiIg0MjM7FvgFsAz4DnAr8CjgDcDTzezx7r59Gv0sSf0cD/wUuBg4AXg5cI6ZPdbd7zowz0Ia2Wy9RnMumOR4cb8GKvPZu4BTgEFgA/Gzb58dgNf6HhQci4js3WeIH8Svd/dPVQ6a2UeBNwHvBV45jX7eRwTGH3X3t+T6eT3wiXSfp8/iuGX+mK3XKADufv5sD1DmvTcRQfEdwJnAFTPsZ1Zf6/WYu+/P9SIiDS1lKe4A1gPHuns519YDbAIMWObuQ1P00w1sAcrACncfyLUVgLuAY9I9lD2WaZut12g6/0rgTHe3AzZgmffM7CwiOP6au//1Plw3a6/1qajmWERkak9Kjz/K/yAGSAHuNUAn8Ji99PMYoAO4Jh8Yp37KwA9r7icyXbP1Gq0ysxeY2Xlm9mYze4aZtc3ecEVmbNZf6/UoOBYRmdpD0uPtk7T/MT0ef5D6Eal1IF5bFwPvB/4NuBS418yeN7Phicyag/JzVMGxiMjUetNj/yTtleMLD1I/IrVm87X1HeBZwCriLx0nEEHyQuAbZqaaeJlLB+XnqCbkiYiICADu/rGaQ7cB7zCz+4FPEYHyDw76wEQOImWORUSmVslE9E7SXjm+8yD1I1LrYLy2vkAs43ZqmvgkMhcOys9RBcciIlO7LT1OVsN2XHqcrAZutvsRqXXAX1vuPgpUJpJ2zbQfkf10UH6OKjgWEZlaZS3Os9OSa1Upg/Z4YBi4di/9XAuMAI+vzbylfs+uuZ/IdM3Wa3RSZvYQYBERIG+baT8i++mAv9ZBwbGIyJTc/U7gR8Aa4DU1zRcQWbSv5NfUNLMTzGy33Z/cfRD4Sjr//Jp+Xpv6/6HWOJZ9NVuvUTNba2aLa/s3s6XAl9KXF7u7dsmTA8rMWtJr9Nj88Zm81md0f20CIiIytTrbla4DHk2suXk78Lj8dqVm5gC1GynU2T76OuBE4NnEBiGPSz/8RfbJbLxGzexc4HPA1cSmNDuA1cAziVrO3wBPdXfVxcs+M7PnAM9JXy4Hnka8zn6ejm1z97emc9cAdwP3uPuamn726bU+o7EqOBYR2TszOxr4F2J75yXETkyXABe4e1/NuXWD49S2GHg38UtiBbAduAz4Z3ffcCCfgzS2/X2NmtnDgLcAZwBHAQuIMopbgP8C/t3dxw/8M5FGZGbnEz/7JlMNhKcKjlP7tF/rMxqrgmMRERERkaCaYxERERGRRMGxiIiIiEii4FhEREREJFFwfBgyszVm5pUJFSIiIiIyO5rnegBzKS1bswb4H3f/3dyORkRERETm2rwOjoFzgTOB9YCCYxEREZF5TmUVIiIiIiKJgmMRERERkWReBsdmdm6azHZmOvSlygS39LE+f56ZXZm+fomZXWVm29Px56TjF6Wvz5/inlemc86dpL3FzP7ezC43s61mNmZm95jZj9Lxrn14fqeY2eZ0v6+a2XwvnxERERGZlvkaNI0Am4HFQAuwKx2r2Fp7gZl9EngdUAb60+OsMLOVwPeAU9OhMrCT2Ht8NfBUYr/wK6fR1+OA7wMLgc8Cr3FtgygiIiIyLfMyc+zu33D35cAv0qE3uPvy3Mcjay45A3gtsSf4EndfDCzKXT9jZtYGfJcIjLcBLwMWuPsSoDPd++PsHrxP1tfZwI+JwPiD7v5qBcYiIiIi0zdfM8f7qht4v7v/S+WAu+8iMs776/8DTgPGgCe7+025e5SAG9LHlMzsucDXgVbg7e7+gVkYm4iIiMi8ouB4ekrARw9Q33+THr+UD4z3hZm9HPgP4i8Br3b3z87W4ERERETmk3lZVjEDd7j7ttnu1MxaiLIJgEtn2McbgS8CDvyNAmMRERGRmVPmeHr2mKA3SxaT/RvcO8M+PpYe/8Xdv7r/QxIRERGZv5Q5np7SXA9gChenx7ea2aPmdCQiIiIihzkFx7OjmB7bpzint86xHblrj5nhvV8KfBtYAPzQzE6bYT8iIiIi8958D44r4xIh0AAAIABJREFUaxXbfvazMz2uqteYNvA4sfa4u08A16cvnzmTG7t7EXghsRzcQuDHZvawmfQlIiIiMt/N9+C4shTbwv3s5/fp8Wwzq5c9fhPQNsm1X06P55rZw2dy8xRkPx/4AbAE+ImZ7RGMi4iIiMjU5ntwfEt6fK6Z1St7mK7vEpt0LAW+bGbLAMys18zeCZxP7KpXzxeB3xHB8+Vm9lIz60zXN5nZI8zsP8zs0VMNwN3HgL8ALgeWpb6O24/nJCIiIjLvzPfg+CvAOPAEYJuZbTSz9WZ29b504u47gPPSl88HNptZH1FT/K/AvxABcL1rx4A/B24GjiAyybvMbBswDPwa+FugYxrjGE19XQWsAH5qZmv35bmIiIiIzGfzOjh291uBpxLlCP3AcmJiXN3a4b309UngBcC1RFBbAK4B/iK/s94k194HPAJ4PXA1MEDsyrcJ+CERHF83zXEMA3+W7r0KuMLMVu/r8xERERGZj8zd53oMIiIiIiKHhHmdORYRERERyVNwLCIiIiKSKDgWEREREUkUHIuIiIiIJAqORUREREQSBcciIiIiIomCYxERERGRRMGxiIiIiEii4FhEREREJGme6wGIiDQiM7sbWACsn+OhiIgcrtYAu9x97cG8acMGx9+88GsO8GdnP7J6rLWjNT4pxNMeHdxRbbvnjpsBWLJkIQDtXV3VtnK5DEBXVzcATa2t1baxsXjs6Iy2e9ffVm17zz++AYAVq9cA8M8f+mi1rdDaGY9u2aAtPh8YHATgy5//TLXp97/51W7nlEvlrK9CW3yS+ioWi7mxe3qMtlKpVG1bvGgRAJ+45PLcIERklizo6OhYfOKJJy6e64GIiByO1q1bx8jIyEG/b8MGxyJyeDMzB65y97Omef5ZwBXABe5+fu74lcCZ7n6w3wSuP/HEExdff/31B/m2IiKN4YwzzuCGG25Yf7Dv27DB8SNOeggA7lmWt39XPHa3dQDQ1rmq2rbmpMiimkUqeHSkv9rW2toUn7TEY9m92lYoVH7f7vl7t1gqpjHsOb7K2Z5r9JSh7unpAeD4406ott3061+nk+LKfJellEW21Gu+z5RoplAo7NG2o69vz4HJYWtfg0kRERHZU8MGxyIy71wHnAhsm+uBVNy8sZ81531/roch0vDWf+CcuR6CNBAFxyLSENx9GLh1rschIiKHt4Zdym1g21YGtm1lx+Yd1Y8tm/rYsqmPDXfcy4Y77mX7AzuqH2ZdmHXR3LKQ5paFLOhdUf1o7VhIa8dC3Fpwa6G5pbX6sXXrNrZu3ca6detYt24dLW2t1Y/WlvjAAAMzq344URqRP1b5IH2USqXqx9joBGOjExQKTRQKTZgXqh+Vztx9t7KJvEqbFQrZh2VlF3Lgmdm5ZvYtM7vLzEbMbJeZXWNmf13n3PVmtn6Sfs43M081tpV+K//wZ6a2ysf5Ndf+lZn9zMz60xh+b2ZvN7O2ycZgZt1m9jEzuy9d8zsze046p9nM3mlmfzSzUTO708xeO8m4C2b2SjP7tZkNmtlQ+vxVZjbpzyIzO8rMvmJmW9L9rzezF9c576x6z3kqZvY0M7vUzLaZ2Vga/4fNbOF0+xARkcaizLHIwfNZ4BbgZ8AmYAnwTOArZvYQd/+nGfb7O+AC4N3APcBFubYrK5+Y2fuAtxNlB/8JDALPAN4HPM3Mznb38Zq+W4AfA4uB7wCtwIuAb5nZ2cCrgUcDlwFjwPOBT5nZVnf/Rk1fXwFeDNwHfIF4W/cXwGeAJwAvqfPcFgG/AHYCXwIWAn8FfM3MVrr7h/f63ZmEmb0bOB/YAXwP2AI8HHgr8Ewze6y775pp/yIicnhq2OD41lv+AMDa4bHqsfYFSwBYf99dAJRz09oedPzxAKw85hgArJC1NbXE41hat611UXu17ZZbYgm4zq6YRNfRfkS1bXw84oz+nTsBGM0tR9LZGpMCqZfoTencwcGh6qFN92+O57O2stRfPtHm6b/x2NSUtVUm6FeWdMsniiuT9OSgOdnd78wfMLNWIrA8z8w+5+4b97VTd/8d8LsU7K3Pr9SQu89jicD4PuBR7v5AOv524BLgz4ig8H01lx4F3ACc5e5j6ZqvEAH+fwN3pue1M7V9lChtOA+oBsdm9iIiMP4t8ER3H0zH3wVcBbzYzL7v7v9Zc/+Hp/u80N3L6ZoPANcD7zWzb7n7Xfv2HQMzexIRGP8SeGZl/KntXCIQvwB40zT6mmw5ihMmOS4iIocwRUciB0ltYJyOjQOfJt6oPvkA3v4V6fFfK4Fxun8ReAtQBv52kmvfWAmM0zU/B+4msrpvyweWKVC9BjjZzJrq3P+8SmCczh8C3pa+rHf/UrpHOXfN3cAniaz2Syd9xlN7fXr8u/z4U/8XEdn4eplsERFpcA2bOb7+xpsAuPuee6vHjjp6NQAthVhibWQ0y+T6xDAAY0OxhFtbd0+1rXdRbPAxOLwdgI7Oo6pt4yORHT75YccBMDq8tdpWJn6fj07ExhtjpSxv22GVb322KUc1r5uyvEceubzactxDov+mprhuZGgod1W6LmWh29s7sjGkviYm9lxEe4oyTzkAzGw1EQg+GVgNdNScsvIA3v709PjT2gZ3v93MNgBrzazX3ftzzTvrBfXA/cBaIoNbayPxs2V5+rxy/zK5Mo+cq4j/EU6r03ZvCoZrXUmUkdS7ZjoeC0wAzzez59dpbwWWmtkSd98+VUfufka94ymjfHq9NhEROXQ1bHAscigxswcRS40tAn4O/AjoJ4LCNcDLgD0mxc2i3vS4aZL2TUTAvjCNq6K//ukUAWoC6d3aiMxu/v476tQ04+5FM9sGLKvT1+ZJ7l/JfvdO0r43S4iff+/ey3ndwJTBsYiINBYFxyIHx5uJgOzl6c/2Vake92U155eJ7GU9M1lJoRLELifqhGutqDlvtvUDi82sxd0n8g1m1gwcAdSb/HbkJP1V/qwy0/H2AwV319bOIiKym4YNjtfddQcALS1Z8qrjtnUAPPjo+Ov12rWrq20jw/E79q47bwTgmAcfX21rSSFK2aJMorIjHUB7c5Qm9CyIBNbYSLWck6ZUvlFIZQ+FXAlmpaLBc31ZpQS8FKUQZzz6kdW2Bx+/BoCfXX4lAD/5wQ+qbQUv7Haf9txzHp+oxCGVmX9ZaYeWcTuoHpwev1Wn7cw6x/qAh9cLJoFHTHKPMtA0SdtviT/xn0VNcGxmDwZWAXfX1t/Oot8S5SRPBC6vaXsiMe4b6ly32szWuPv6muNn5fqdiWuBc8zsJHe/ZYZ97NXJK3u5XpsTiIgcVlR0KnJwrE+PZ+UPmtnTqD8R7TrizevLa84/F3j8JPfYDhw9SduF6fFdZrY0118T8BHiZ8EXJxv8LKjc//1m1pm7fyfwgfRlvfs3AR/Mr4NsZmuJCXVF4KszHM/H0uN/mNlRtY1m1mVmj5lh3yIichhr2MxxaXQUgJ6ObNm1ns74ndw/EJPl+/qzv+JWssKrj4ys8tJl2ZJsY6WYNDc6FpPavCkrmyy0RFKvqT2ytYWm7C/hNhp9tjWl6/qyyYHeOhCftC3JjTpKTt0j+dfenZVTdi5ZBEDLL64DYHi8WG3raot/xqa0NNt4cTgb+3iMr5BiC99tMbf6G4bIAfEZItD9bzP7JjGh7WTg6cB/AS+oOf9T6fzPmtmTiSXYTiUmkn2PWHqt1uXAC83su0QWdgL4mbv/zN1/YWYfAv4PcHMawxCxzvHJwNXAjNcM3ht3/08zezaxRvEtZvY/xAvwOcTEvm+4+9fqXHoTsY7y9Wb2I7J1jhcC/2eSyYLTGc/lZnYe8H7gj2Z2KbECRzdwDJHNv5r49xERkXmkYYNjkUOJu9+U1tb9V+Ac4v+9G4HnEhtcvKDm/D+Y2VOIdYefRWRJf04Ex8+lfnD8BiLgfDKxuUiBWKv3Z6nPt5nZb4HXAn9DTJi7E3gX8G/1JsvNshcRK1O8AviHdGwd8G/EBin19BEB/IeINwsLgD8AH6mzJvI+cfcPmtk1RBb6CcCziVrkjcDniY1SRERknmnY4Pj0Ux4GQCFXWHvCQ08CoLNnAQC7BrLySicyrAsWxV+cm1qyDPDwUJw3OBrnbN2exRA7dkaW99774piPZvN7Tn9CxDtdrZFVvuTib1fbTjk99gc440+flY0h/eG4XFnRrZzL7I7EMrPjxchiL1i4qNpUTsvQecp+j5WzEtVSWk6ukHYyye8uPclO03KAuPsvgD+dpHmPCnB3v5qox611E7GBRe35W4iNNqYaw8XAxXsbazp3zRRtZ03Rdi5wbp3jZSKD/plp3j//Pdlji+06519J/e/jWVNcczWRIRYREQFUcywiIiIiUqXgWEREREQkadiyiuUrYj+B+zZsqB67/Y7bADjmuBMBuGv9PdW2BQtisl7vltjhbnB8tNrWPxifjxdjct/3Lr2s2lYYjYlx24dj6biO1mxptmNOiyWcWpuj9OKy//1ytW31w1P5RVNuk7TKsm5pCTgvZmMYS5MBTz0pyjFay9mEvCuvugqA4ZG0C95utRNxb1VQiIiIiOydMsciIiIiIknDZo5PfsSpADz09IdXjw0ORWa1uS0m5C1Znu1W29vbBcCiRdFWzmVmB0djg5AdaX+PTfdnGd1FXZGZHRqLY9dd/4tqWzlt5jE4kDLBpWyu0Ka+mPA3PpH9E7Q0xXkjuyJ7ve2BLOvtE9FWHIrl55b2VpeKZeGCWA5u2/ZYKq6pkNtsJN2y4KXdDwCmGXkiIiIiu1HmWEREREQkadjM8RHLjwWgvTO3JNtIZIDLpXjaLS1ZhrV3cWy4sXnTfQD88upfVdvGRiNLu2xpbCm9dvWR1bYdOzYC0NwU7zNOPe3R1bbRkVhibWQg7nPXnX+otl33q5sAOPnkh1SPnXR8ZLIfuCfGcOuN2W66HW1R73z/A9sAGBjOlmvzlhjPgiNjebf7NtydXdcSS8y1WiwFV5woZdeZ3huJiIiI5Ck6EhERERFJFByLiIiIiCQNW1bxmc9+BYC2tiz+b+2IEoPmpii12L59W7WtkE5zj4lvd91+b7Wtp3MVAEuX3gnAxs33V9uWrVoOwOhglDm0dvZU27rTLnYLumO5NiMrhbjppp8B8OMf/7p6rDj6UAB2bI4d+W697YFq246tWwAYL0R5Rd9wNmFwrNQNwOIVDwZgoml7tW1iNMo+Wjzu3de3q9rmadc8EREREQnKHIuIiIiIJA2bOf7Jj38AQLE0Xj22fEXK5C6M7O7tt/2x2tbcElnUY1ZHlrirK8sAF9J36ba0icg9G+6rtvUsjqXfhodj8t2u4bFq28SWWN6ticgceznLHJdoA2DrluHqsetviizv0EiMeazt6Gx8vdHHqmNiouHOwZFq28jgIAC/X7cudZ4tNVeeiL6G0mYlE8VsEuJENhwRERERQZljEREREZGqhs0cLz4ilmYbG80yxz09RwBw1MqVACxavKratnTpUQC0t0Y98tDAzmrbSMrklstpw4/RLDtc2UfDKptrZLtHVz8vkeqDc5tzPPYJT437NXdXjxXa07Jzpeh/2TFZ5rijJY5t2R7jWnzkymrbrsJ6ACbGIxVsntUSt7ZGBnxkMK4bGcsGaC3ZMnciIiIiosyxiMxDZrbGzNzMLprrsYiIyKFFwbGIHBAKQEVE5HDUsGUVO/pi6bMCWYlBd9cSAJYvPw6AhQuXVdsKFhPe2ltiotz4eLbk2dZtsXTb6tVRAjGRK50ol2PHuda2uK6tqb3a1twak/WcKLm49vps2bbNO6L/Y1auqR4rbt8MQFMa82CTZ23FmHRnac25puasbXQizl97/OkAjI1nu+AN74zd8vr6fhPjLWTXNeU+F5HZd/PGftac9/25HsYhY/0HzpnrIYiI7JUyxyIiIiIiScNmjgcH+wHoaO+tHuvoWAjA1u0xcW3z1q3VtpamLgA62yKD3NycTbobGY1UcWfHgnQk+7YVizHZbnh4CADPbfTR1dMZ9+2Ox+GxrM/RHTG+xb0D1WPN5eiDcmR0hyeyDHBzZ/TR0hyT+u5Zny0n19wa4xkuxtiHR7MxlD2y3cWU4aaQ9VloVuZYDgwzOx94d/ryZWb2slzzy4H1wBXABcCl6dzHAouAte6+3swcuMrdz6rT/0XAyyrn1rQ9CngL8ATgCGAH8HvgC+7+X3sZdwH4GPB64BLgJe4+MtU1IiLSWBo2OBaROXUlsBB4A3Aj8D+5tt+lNoiA+O3A1cCFRDA7zgyZ2d8BnwVKwP8CfwSWAY8AXg1MGhybWTvwNeC5wKeB17t7ebLzc9ddP0nTCfs0eBEROSQ0bHDc3h41wAt7F1WPbdnWB0BpOLLJbT0d1bajVkSt8KIjVgCwq29HtW0s/X7s2xkbdlSyxQDNxHJoxXL8PrdC9i2dSLW/LcWUMfbsuva0qtuC1mx5t7aWGFdLIe43MJxt5jFUjvFt7Y9jzbl/uZEtMdbWzrjemrPYYtuO2Eq6WIq653IxyxZPeJbJFplN7n6lma0nguPfufv5+XYzOyt9ejbwSnf/9/29p5k9FPgMsAv4E3e/paZ9Vd0Lo20xEUw/DjjP3T+4v+MREZHDU8MGxyJyWPjdbATGyauIn2nvqQ2MAdx9Q72LzOwY4AfAscBL3f1r+3JTdz9jkn6vB07fl75ERGTuKTgWkbl03Sz29Zj0eNk+XPMQ4JdAF/AMd798FscjIiKHoYYNjlvTkmzNzdlSbniUORy5LJZ0O2rt8dUmI0ouhoZjCbiO7mxJtqNWR+lg80RMnuvbtqDaNjAcS6x5MdraOrMyiUIqjxgdiWXbdu18IBvfkphgt3WgmDs/Sh7aO2LM4yNZ2+h4TNYbL8Wx9XfcVG3buuFeABYfGUvTbXogS5CVR2J8C3ujz+JQVkJZHNU8I5lzD+z9lGmr1DFv3IdrjgcWE3XQN8ziWERE5DClpdxEZC5NtWSKM/kb+IV1jlX2fF9Zp20y3wXeAZwKXG5mS/bhWhERaUANmzkulSJDurO/r3psQU9kVo/oiAzyrk23VduuuvKSOLYtfr8+/PRHVNv+6oUviuu6euKcLUurbbsGI8P8+xt+DsBQbhm1I1fF/Vo6YtJeV3sWB/T2xNJxHd092aALMZGuLW0osqi3O2srx/O54851AOy4Z112n0XRx+9/H2M4Ymk2CXHJkdE2kSYVDg1n2eJCk94byQFVWTewacqzJtcHHF170MyaiGC21rXEqhTPAG6d7k3c/f1mNkIs4XalmT3F3TfPbMi7O3llL9dr4wsRkcOKoiMROVD6iOzv6hlefx2w2szOrjn+LuCYOud/FigC/5RWrtjNVKtVuPvHiQl9JwFXmdlRMxyziIgc5ho2cywic8vdB83sV8CfmNnXgNvJ1h+ejo8ATwO+Y2bfIDbzeBywllhH+aya+/3BzF4NfA74rZl9h1jneAnwSGKJtydNMd7Pmdko8EXgZ2b2p+5+7zTHKiIiDaJhg+PW1ihNGM2VOQwPR8nEpnujJGHdXeurbaMD8VfUR576MADu3XR7te2O22KN/4c/408BWP6kJ1TbKhPk7r7nTgCWLM3KJJ75rKcC0NQSf1W+6Q/Z/coTUVZx1JJsfM2tUVYxNBQT+O7bmO3gNzARbbff/jsAFvS0Vtue+CePjnFuiL8kn3jC2mpbb2fc53s//ikAI+PZ2skt+cmKIgfGS4lyhacDLwIM2EDskDcld7/czJ4D/DPwQmAI+DHwAmJnvXrX/IeZ3Qy8lQienwNsA24CvjCNe15kZmPAl8kC5Lv2dp2IiDSOhg2ORWTuufsdwLMmabZpXP+/1M80n5s+6l3zS+Av99Lv+snu7+5fB76+t7GJiEhjatjguLU1JsqZZZnZrs7IJq9YsRiAm2/PJrUtXhQZ1uf8+dMBuOLqq6ttG++9A4DxoVjrvziR7UA3Uow5R81tkR3uWdhVbetpjwl146WYBOcTg9W2O26Ne99/R6l67Ji1scPdxpQx/p/vX1FtKyyIvgbHoq+jl2YT8rcPxDJvAyMxrjvX35d9Hyx+/+8cjGy05+KBkXHtkCciIiKSpwl5IiIiIiJJw2aOFy85AoCx0azGlkLKmjbF44Tn6n3TKmslj0+OWrGi2nbFlVcB8MUvfQmAgcFsObQdg5EN3rItapabW7I63g3rIwM8Mtoffef+iNu/cxiAzo7s4KjF5iIbN8R1VsiWfit4ZIVbm+P9zPa+/mx8V10DQG9PZMQHB7KMcGtarm31ylgwYGQkG/vYmDLHIiIiInnKHIuIiIiIJAqORURERESShi2r6O+Pcod86cDQUHy+67e/AWDTtvurbYt6YsLbbXfEqk19fduqbZu3PBDX7Yrd9lpaO6ttg2nHuaGhmBTX2potsTY4cMduY+rqzibrtbbEt75QyMoqhgfTpL7u2IHvlIdlO9k2NcVkwlLa6a6traPatiD1Ozy85xgqBgZiQt5o7vsxPj6+x3kiIiIi85kyxyIiIiIiScNmjifGIis6uGugeqyUll0b3hSZ4PGxbLLernJkZC+99DIA2lqzb82SRZHBLTRFZre1NcvaLl6yDIByKfpuac0m5HV2Roa5va19t+sBWprj8462LMvb1hbZ4Uo2uVTKJuSVijG+iWJMImxuzsbXkibpGeV0JMtGl9K4KmNoacquK3dkGXARERERUeZYRERERKSqYTPHq446CoBd3d3VY2Mpm1xK7wmGStlSbq2FyOQuT1nipUuzet/WlsjurkjLu3UtWJC1pfrebdu3AzA4kGWqF6TzmlKWdzjVJQNMTMS20y3N7dVjVrNfV6mpmI3dY+m3QjnGXskIx+fxPArpOeTbyikjbqlzK2TvhwqeZaZFRERERJljEREREZEqBcciIiIiIknDllUs6ukFoKczK6toSmUH3hyT5vpHszKHtqY4dvTS5QB0dmbLrnkqPzjphJMBaO1oq7bt2LkDyCYAdrRlZRJNqYRholjc7WuAkqVJdLlaiqwEItqa85PnUmlHMU0qrJybRrhbX/k+a48VcmPwssoqRERERPKUORaRWWFma8zMzeyiuR6LiIjITDVs5rglTYLLL11WmTzn6VjRssxpWzrWVIjH8kSWmS2lLO1992yIc1qy9xSDwzEBrzLZr7k5W67NUrbX0+Q7n8gmylnazKPs2aTAcjnaPWWCK5PvAJpyy8CRzqp+5rtPuqunXlZZb41EREREdqfwSEREREQkadjMcVvLnk+tqSneC5RT8rQ7t81ya6pDLhQiI1vKZ3RTlnZoOLZgbsr1XUxZ4comIBO5WuBKSW8pZYRLuWxvOdUxezHbwrmyslolc1wq59tS1jmNq5J5BvDKPVMHlluirZIczx5zY9itbllEZtvNG/tZc973Z3z9+g+cM4ujERGR6VDmWERmXao/vtjMtpnZqJn9xsz+rM55bWZ2npn93syGzWyXmf3czP5qkj7dzC4ys+PN7BtmtsXMymZ2VjrnQWb2eTO7w8xGzGxH6vtzZrakTp8vMrMrzGxnGuc6M3uXmbXVnisiIvNDw2aORWTOHANcB9wFfAVYDLwA+I6ZPcXdrwAws1bgh8CZwK3Ap4FO4HnAN8zsVHd/R53+jwV+BdwOfA3oAHaZ2Qrg18AC4FLgW0A7sBZ4KfB/ge2VTszsQuDlwIZ07k7gMcB7gCeb2VPdPduJR0RE5oWGDY6bC6l2Ij//LOXJC5Vl1Lwpd346lsoqyuTLFqKkYXQidqlrJVuurZxqJyrLvZVz5Q7psmoJRSnXVv18t13qdp9QV7kvgJfGdus031b51EtpDMX8dZVBlCuDqbY1MfkEPpH9cBZwvrtfUDlgZv8J/AD4R+CKdPgtRGB8GfDnlUDUzC4gguu3m9n33P0XNf0/AXh/beBsZq8jAvE3uvsnatq6IPuf2szOJQLjS4CXuPtIru184N3Aa4Dd+qnHzK6fpOmEvV0rIiKHHpVViMhsuwf41/wBd/8hcC/wqNzhVxDLrrw5n6F19y1E9hbgb+v0vxm4oM7xipHaA+4+lA+AgTcAReAVNcdJ994OvGSKe4iISINq2MyxFfbc9KJQ2QQkvSfIt1WWSqtullFnc45SysIWLftLayXxWzlnt2010vmlmuvzn1tuObnKvStZ6N0yx7tlmGueazUD7Ls9l93OqbeUm8iB8TuvziDdzX3AYwHMrAd4MLDR3W+tc+5P0+NpddpudPexOsf/F3gf8GkzexpRsnEN8AfP/Q9kZp3AKcA24I2T/D8xBpxYr6GWu59R73jKKJ8+nT5EROTQ0bDBsYjMmZ2THC+S/bWqNz1umuTcyvGFddoeqHeBu99jZo8CzgeeDjw3Nd1nZh9x90+mrxcRNUxLifIJERGRqoYNjqfaSrlS2ztV5rheOW4l+VQsZZnjcqXOt7znRhyVDHWlDjm/dFpl4w4ntzFIta3a+x73rptBrgy5JvO82yl1vh9TZaNFDrD+9Lh8kvYVNeflTfrCdfd1wAvMrJnIDj8FeB3wCTMbcvcv5vr8rbsrsysiIrtRzbGIHHTuPgDcCaw0s+PqnPKk9HjDDPsvuvv17v5B4EXp8HNS2yBwC3CSmS2eSf8iItK4GjZzLCKHvAuB9wIfNrO/rNQpm9kRwD/lzpkWMzsDuMPda7PNR6bH4dyxjwJfBC40s3PdfbdSEDNbBKx19xkF5xUnr+zlem3kISJyWJmfwfFUk9Mqf7Cdoqxi9/KI+udA/XKKbAyV8/KT7nafWJcvq6gdzm4lEW6TttWWTmhCnhxCPgI8A3g2cKOZXUqsc/x8YBnwIXe/eh/6eynwD2Z2NZGV7iPWRH4WMcHu45UT3f3CFEy/GrjTzCqraSwm1kV+IvAl4JX79QxFROSwMz+DYxGZc+4+bmZPBd4MvJioDS4CNxJrFX99H7v8OtAGPA44g9gcZCNwMfBv7n5zzf1fY2aXEQHwU4gy4tK2AAAgAElEQVTJfzuIIPnDwFdn+NQq1qxbt44zzqi7mIWIiOzFunXrANYc7PuaJmWJiMw+MxsDmohgX+RQVNmopt5yiiKHglOAkru3HcybKnMsInJg3AyTr4MsMtcquzvqNSqHqil2ID2gtFqFiIiIiEii4FhEREREJFFwLCIiIiKSKDgWEREREUkUHIuIiIiIJFrKTUREREQkUeZYRERERCRRcCwiIiIikig4FhERERFJFByLiIiIiCQKjkVEREREEgXHIiIiIiKJgmMRERERkUTBsYiIiIhIouBYRGQazGyVmV1oZveb2ZiZrTezj5vZon3sZ3G6bn3q5/7U76oDNXaZH2bjNWpmV5qZT/HRfiCfgzQuM3uemX3KzH5uZrvS6+mrM+xrVn4eT6Z5NjoREWlkZnYs8AtgGfAd4FbgUcAbgKeb2ePdffs0+lmS+jke+ClwMXAC8HLgHDN7rLvfdWCehTSy2XqN5lwwyfHifg1U5rN3AacAg8AG4mffPjsAr/U9KDgWEdm7zxA/iF/v7p+qHDSzjwJvAt4LvHIa/byPCIw/6u5vyfXzeuAT6T5Pn8Vxy/wxW69RANz9/NkeoMx7byKC4juAM4ErZtjPrL7W6zF335/rRUQaWspS3AGsB45193KurQfYBBiwzN2HpuinG9gClIEV7j6QaysAdwHHpHsoeyzTNluv0XT+lcCZ7m4HbMAy75nZWURw/DV3/+t9uG7WXutTUc2xiMjUnpQef5T/QQyQAtxrgE7gMXvp5zFAB3BNPjBO/ZSBH9bcT2S6Zus1WmVmLzCz88zszWb2DDNrm73hiszYrL/W61FwLCIytYekx9snaf9jejz+IPUjUutAvLYuBt4P/BtwKXCvmT1vZsMTmTUH5eeogmMRkan1psf+SdorxxcepH5Eas3ma+s7wLOAVcRfOk4gguSFwDfMTDXxMpcOys9RTcgTERERANz9YzWHbgPeYWb3A58iAuUfHPSBiRxEyhyLiEytkononaS9cnznQepHpNbBeG19gVjG7dQ08UlkLhyUn6MKjkVEpnZbepyshu249DhZDdxs9yNS64C/ttx9FKhMJO2aaT8i++mg/BxVcCwiMrXKWpxnpyXXqlIG7fHAMHDtXvq5FhgBHl+beUv9nl1zP5Hpmq3X6KTM7CHAIiJA3jbTfkT20wF/rYOCYxGRKbn7ncCPgDXAa2qaLyCyaF/Jr6lpZieY2W67P7n7IPCVdP75Nf28NvX/Q61xLPtqtl6jZrbWzBbX9m9mS4EvpS8vdnftkicHlJm1pNfosfnjM3mtz+j+2gRERGRqdbYrXQc8mlhz83bgcfntSs3MAWo3UqizffR1wInAs4kNQh6XfviL7JPZeI2a2bnA54CriU1pdgCrgWcStZy/AZ7q7qqLl31mZs8BnpO+XA48jXid/Twd2+bub03nrgHuBu5x9zU1/ezTa31GY1VwLCKyd2Z2NPAvxPbOS4idmC4BLnD3vppz6wbHqW0x8G7il8QKYDtwGfDP7r7hQD4HaWz7+xo1s4cBbwHOAI4CFhBlFLcA/wX8u7uPH/hnIo3IzM4nfvZNphoITxUcp/Zpv9ZnNFYFxyIiIiIiQTXHIiIiIiKJgmMRERERkUTB8X4yM08fa+Z6LCIiIiKyfxQci4iIiIgkCo5FRERERBIFxyIiIiIiiYJjEREREZFEwfFemFnBzF5nZjea2YiZbTWz75rZY6dx7Wlm9lUzu8/Mxsxsm5n90Mz+ci/XNZnZG83sptw9v2dmj0/tmgQoIiIicgBoE5ApmFkz8E1ia1eAIjAILEyfvwD4Vmpb6+7rc9f+PfBZsjcgO4EeoCl9/VXgXHcv1dyzhdgO8RmT3POFaUx73FNERERE9o8yx1N7GxEYl4F/BHrdfRHwIOAnwIX1LjKzx5EFxt8Ejk7XLQTeBTjw18Db61z+LiIwLgFvBBaka9cAPwC+MEvPTURERERqKHM8CTPrIvbq7iH26j6/pr0NuAF4aDpUzeKa2eXAnwLXAGfWyQ6/jwiMB4GV7r4rHe9J9+wC3unu76u5rgX4NXBK7T1FREREZP8pczy5s4nAeAz4WG2ju48BH6k9bmaLgSelL99fGxgnHwRGgW7gmTX37Eptn6xzzwngo/v0LERERERk2hQcT+709Pg7d++f5Jyr6hw7DTCidKJeO6m/62vuU7m2cs/BSe7580lHLCIiIiL7RcHx5Jamx/unOGfjFNf1TxHgAmyoOR/giPS4aYrrphqPiIiIiOwHBccHTttcD0BERERE9o2C48ltTY9HTXFOvbbKdR1mtrROe8WqmvMBtqXHFVNcN1WbiIiIiOwHBceTuyE9nmpmCyY558w6x35L1BtDNjFvN2bWC5xRc5/KtZV7dk9yzz+Z5LiIiIiI7CcFx5P7EbCLKI94Q22jmbUCb6k97u47gCvSl28zs3rf47cB7cRSbpfW3HMotb2mzj2bgTft07MQERERkWlTcDwJdx8CPpS+fLeZvdnMOgDSts2XAEdPcvk/ERuHnA5cbGar0nXdZvYO4Lx03gcqaxynew6QLRv3r2nb6so9VxMbiqydnWcoIiIiIrW0CcgU9nP76H8APkO8AXFi++gFZNtHfw14WZ0NQlqB7xJrHtfecyLd89up7Sh3n2plCxERERHZB8ocT8Hdi8BfAq8HbiIC1RLwfWLnu29Pce2/A48E/pNYmq0b6Ad+DDzf3f+63gYh7j4OnEOUbNyc7lckAuYnkpVsQATcIiIiIjJLlDk+zJjZk4GfAPe4+5o5Ho6IiIhIQ1Hm+PDzj+nxx3M6ChEREZEGpOD4EGNmTWb2TTN7elryrXL8JDP7JvA0ovb4k3M2SBEREZEGpbKKQ0yaBDiRO7QLaAY609dl4FXu/vmDPTYRERGRRqfg+BBjZga8ksgQPwxYBrQADwA/Az7u7jdM3oOIiIiIzJSCYxERERGRRDXHIiIiIiKJgmMRERERkUTBsYiIiIhIouBYRERERCRRcCwiIiIikjTP9QBERBqRmd39/9q78+DIz/rO4++vulvdrdExI43H9szYHmx8FoRjCDcBh4VwJq5wBChS4FSygSTLvbscYdck4SiSTZwlHJtQWRZvCkgCFMsVyAIGGxZIbOMDBnyOD82tW2r1/ewf36d/T0dIMx5bM5Jan1fV1E96nqef3/OTujSPvvo+zwMMA/vXeCgiIhvVHmA2hPCI03nTnp0cX/nsJwWA33zxFVnZztExAAqh7dd22saur+ll/XN1/7ySgur1exYAKJf9y9U+p5rqwiEAFutz3meukNWVt2wDYGbBz/SoVetZ3fDgoN+vP30LCvkWAM2cj2Uu15/Vff5rNwDwpe/c7H3W0hh2Dfhz1Wre/3xzMasbDP4cO8s+lhDSc002vN0XZ+81RGS1DZfL5dFLL710dK0HIiKyEe3bt4/FxcUTN1xlPTs5vuCyvQDkRs/Nyioln5AW4mP3xUkygM37BHjbQhOA/Hwrq2tO+6SzMu+T3PZYmuTW2zXvMxQBaJD6rDfnASiWh/zzSiX1WfX7DQ5kJ0QT8HtW6z6GZqmU1c03vSzkfHJbLhTTfRo+nuFi2cdZT/fJbfE+6jmf/+bbaR68tTSMiJwy+y+99NLRG264Ya3HISKyIe3du5cbb7xx/+m+r3KORWTTM7NrzUwnIomISO9GjkVE1tpt4zPsefuX13oYcgrt/8AL13oIIrLKenZy/JQnPAOAYlfqQLXqKQ8LMffXys2sLh88h3dg1oNH8+NHsrrp/gPeZsxTEiyXAkxW9Y/Lbc8PboVGVlfMeepDaPrr+vu6vtxNbzd95GgqantZPe95y/cvzGV1P/7JHbEvT70oWS6rqzf8deXBrX6tpLznvpy3axDHme/Kie5PaRsiIiIiorQKEdlgzOyJZvYZMxs3s5qZHTSzr5vZy7vavNbMPmtmd5vZopnNmtl3zezVS/raE9Mpnhk/D13/rj29TyYiIutBz0aOWzGyulCvZWWluJNEaHv0dW5mOtW1fTVkJRa1KgtZXW2nR5Xnyx55zldSxLUY/OOJlkd5+/pSZHYI/3ji4GEAzto+lNUNFPz3kno1ja9pXlaN35aJeopC12JfuZaPZcdoWgB//zGPctcbHgkf6i9ndXOx/2bDXzc2uiWrOzNGmkU2CjP7HeCjQAv4P8AdwA7gCcDvAX8fm34U+DHwHeAgMAa8ALjGzC4OIbw7tpsG3gO8Fjgvftyx/0GOaaUVd5c8mNeLiMj60rOTYxHpLWZ2GfARYBZ4Rgjhx0vqd3d9+qgQwl1L6vuBrwJvN7OPhRDGQwjTwFVm9izgvBDCVafyGUREZP3r2cnx+H37ANheOjsrGymdBYA1PApbnU57520peKS4VpsFoN1KecX9OY+wVpqTAIRm2sqtNOi5xrmi97nYSFu51Rre56EYtb373tmsbmDAX7drNEWT+y32UfMc5Yn5NL56iFuwxej3hXvOSc81OABAI241V8ulb2stbkk3WPb855FCiioPtFPessgG8Hr8Z9YfL50YA4QQHuj6+K5l6utm9mHgl4FnA59cjUGFEPYuVx4jyo9fjXuIiMjp07OTYxHpOU+O16+eqKGZnQv8Z3wSfC5QXtJk1+oOTUREeoUmxyKyUXSS5MeP18jMzgd+CGwDrgO+Dszgecp7gNcAxZVeLyIim1vPTo7vv+FfANhij8zKBodjGkErLnRrTWZ1wxd5usLRrZ76UD+cFsMNL/jit/5Rf731pUV0Fk+eKzZ8MV2rlbaHs4KnZuzc5akdD0ymtIqpqp9iVwoptaEQj3aemfHFffffd29Wl4spGk/7xcsA+OW9aa1PPHWam2+9E4Dv3fKzrK6z+HDbsJ/EV+jayq3eSKcAimwAnRW0u4CfHqfdW/AFeFeGED7RXWFmr8QnxyIiIsvq2cmxiPSc7+O7Ujyf40+OO78Rf3aZumeu8JoWgJnlQgir9lvjo3aNcIMOiRAR2VB6dnJ8we49APT9KG3Xlm9OAWDxoI5SSNu1zVY9ojobt2srjqT/H6uVYwCM7hwEIMWGoR0P5egv+AI7a1mqi4vzrN+vF2wfzOoWmv5X3Sopkjs+OQFAI3hk+ulP/oWs7qmXPQKAnaN+qMloOS0YLBc9nXJ02KPJs/X5rO66H9wKwNFZj5K3ymnB4BkDI4hsIB8FXge828y+FkL4SXelme2Oi/L2x6JnAV/sqv8V4LdX6HsiXs8F7lnFMYuIyAbTs5NjEektIYSfmNnvAR8DbjKzL+D7HI8Bv4hv8XY5vt3blcA/mNk/AgeARwHPw/dB/o1luv8G8DLgc2b2FWARuDeEcM2pfSoREVlvNDkWkQ0jhPA3ZnYb8DY8MnwFcAy4Bfh4bHOLmV0O/AnwQvzn3M3Ar+N5y8tNjj+OHwLyCuA/xdd8G9DkWERkk+nZybGd5ekHR8dmsrKbcr7IfbHtaQcjpZQCsS34yXHlPi8bOCedJNes+H7DOfv5VMRKPMWuVfNrZ1EdQDOezpeLiRi5Ulp8t8X8Pu1G+hYsTsdxDXuaxOMeeV56nllfzFed91SQIqmvUPcUi9FBf+bLn/aErG5q1hf3/exnBwCYW0wpF+VCSukQ2ShCCP8PeMkJ2nwP3894Oba0IOYZvzP+ExGRTazvxE1ERERERDaHno0c/2z8DgAGzkjbmW7b5pFSa3rU9eDhg1ndlsYOAEbiSXLtUuqrnYu/Q/R7wCnX9TtFqPoCt74Yye0v9Wd1jXaMKre9TSmfziGYmvcI7kwlRXJD1SPNi/EEvvED+7O6oVzcRi5+y2pd27C1at5/biFu2zaYxvCif/dLXlf/IQDTR9MixKL9XABNREREZFNT5FhEREREJOrZyPFgw6Owxb4UHR2N0eDRoh+0NV3riqLm/feEmnn+7kK9ktUVYnpvI6boNutpM7fiFo8G1xY82rtYq2Z1fUV/QSW2P3BfOthrZtH7P7JYz8rKZc8ZbjQ94vydH92S1Z0Vt3AbLAwAkO9Loe1ciBHxuLtbud6VS9z28e0a3e5t59PXo9XUISAiIiIi3RQ5FhERERGJNDkWEREREYl6Nq3i/K2eRrBQqWVloZMyERewtXNdjx8X4pVKnoaw2J2ZYN6+1ef5FQ1L26jl8D7z+c6CuaQSD6P7yd33AXBkZipVxvZTi+kVQ8Ne1mp5WkU9bhMHMDHjJ9zlgp/Wl+9PCw0rMTWjVPJUi/JgqttRGvMxN2JfrXSyHn3ayk1ERESkmyLHIiIiIiJRz0aOSyFurTYylpUVS36wR23BF+JNt1NUuTzg7fritm25ZvrSFMseTZ6f80V0+VxaDFeKq/WaNT9so95K0d5b77gHgNvHjwKw2BVxrrX8YJF8IW27Vo6R6RDbVSqpr/mqR4eHBv3euZCiwzN1rwsNv/bV0utqW7z9UL8/gxW6FiH2pfGIiIiIiCLHIiIiIiKZno0cF+JBGn3FdPCGLfoRzMW6b7c22JVz3IcnCC8Gj7redPedWV0nd7ic923Uml2R2XO2j/p1bASAuenJrG7/Uf94Do8OT8QDQwBqTc81vujsM7Ky4kjsY86jyrO11L6/6PfuG/YI9+DwSFbXKPpzHT7q+cgL0+lgkamJQwCc2fbXbyX1WagvIiIiIiKJIsciIiIiIpEmxyIiIiIiUc+mVbT6PJ2i2kinwA3FlIKRov9OELoW3RHTMNr9vr1ZcXAwq7rpLt+Kba7682kLY2Vv/0t7LwNguCtVY6ru956K6RQLzbRtWz6mSfQPjaYh5L2vmdoMAJOL6ZS+rUVfgNeKiwGb+bQocL7paRUTC54usrCQTulrV/zjamsagHIhLeQbrqXT+UTWCzN7A/A64BFACXhzCOHqtR2ViIhsFj07ORaRjcfMXgH8JXATcDVQA76/poMSEZFNpWcnx8OXPg2Adtc5F9P33w5AZfYIACGfDsTI1z1KO9j2iPNl28/J6g7OeeT3pnFf3Nbu35LuExfk5cteVm+mSHUrbtNWj5HcXD5FbVvNJgATMyk6XImR4vkF3xZurprqbMG/VcVpjyo3LWXE1Fs+vmo8NKTRTM9Vrfp2daV4v8VG+oL057SVm6w7L+pcQwgH1nQkIiKyKfXs5FhENqSdAL0yMb5tfIY9b//yWg9jQ9j/gReu9RBERAAtyBORdcDMrjKzAFwePw+df12fX2tmZ5nZx81s3MxaZvbarj7ONrMPm9l+M6ub2VEz+5yZ7V3hniNmdrWZPWBmVTP7qZm9xczOj/f7xGl4dBERWWd6NnLc2uML5IrllEYwvM33FJ648zYA6hP3ZnXluOdvmPfFdsPl9KW5MKZO3HPUT7o70k77HJ+5I+5zvOtMAOZm5rK63bv8fjOLBwGYD+k0vBBP0jt06HBWVouLAusNr5uYTWkVzba/ti/n45ueT4vu+ktet9BZwFdPexm34qLASsuvh7tO6SvlunJORNbWtfH6WuA84D3LtBnF84/ngc8BbeAwgJk9Argejzx/E/gUcA7wMuCFZvaSEMKXOh2ZWSm2ezye3/x3wAjwLuAZq/pkIiKyofTs5FhENo4QwrXAtWb2LOC8EMJVyzR7NHAN8FshhOaSuo/hE+M/DCG8t1NoZh8BvgP8LzM7L4TQ2WrmP+IT408DrwohdCLU7wVuPJmxm9kNK1RdcjL9iIjI+tCzk+PSwBAAg6W0CG7obP94bLtHdCcPpMjxoX03AzA1tR+AZitFbY8c8S3c5id8y7QcaUu2zgK8g0cnACh21e0c2wbAnff4AsB2aSirW6j6/9HNZi0rq1Y9GjwVo8+F/oGsbi4u6mu1/D4jI6mv1lwcV59nyZS61tkV4tZyoe3R5IkUVKZRXzq/EFnX6sDblk6MzWw38FzgPuCD3XUhhO+Z2aeAVwO/DnwyVr0Gjzy/ozMxju3vN7OrgT85ZU8hIiLrWs9OjkWk5+wPIRxZpvxx8XpdCKGxTP038cnx44BPmtkwcAFwfwhh/zLtrz+ZQYUQVsppvgGPTouIyAbSs5Pj4XjYRV8lHXTRwANOuZHtAGx91O6sLjdyFgAHbvItVe+6Nf2ldGrCI7lPusTzmM86+4ysbm5+0vuueKR5x9iOdL8+P3gjH5c91rqixDOLHjmej1uzAfT1ecjX+vzbMrAlHUQyP7cAQLXufeQraS1lIZ+L9x7zfrr6bMeI8bFJf91MNY2hXUyRaZEN4NAK5SPxenCF+k751ngdjtfDy7Q9XrmIiGwC2q1CRDaKsEJ557fBs1aoP3tJu9l4PXOF9iuVi4jIJqDJsYhsdDfF69PNbLm/hl0erzcChBBmgbuBXWa2Z5n2T1/tAYqIyMbRs2kV9eAL5drtlFYRcv67QK3iaYnTjVRXKvuWbDsf81RvE9KqtsVbfgDAL8St2XafOZLV1RvxS1jwbdGmF1LKY3+8XyHmVUxPTWV1tYanNzS6TtQrxcWD5S2+NVs7pMV97bjQL3bJscnJrG7bcFycN+in9BWLacu4ekyjyMeUjcVWWss0VZlHZKMLITxgZv8MPAd4E/BnnTozexLwKmAK+HzXyz4JXAW838y6d6s4J/axKh61a4QbdLiFiMiG0rOTYxHZVF4HfBf4UzN7LvCvpH2O28CVIYS5rvYfBK4AXgFcbGZfx3OXX45v/XZFfJ2IiGwyPTs5nmz4ArZGX9fi9aZHTwvxYIz+doqiNiyGZON2axc+4znpdTH6fGz/LQCcWU5V+bjIr1CIi9uG0yK3wwfHvU0M95YL6dCNVtyNqlksZWWdbeEKfTG1smtLtma7Fdv4WFJMGZp1f8ZGzeu2DqVt3uZnPDpcKnpUut2VtVmrpoNERDayEMLdZvYE4A+BFwDPwnOL/wl4bwjhX5a0XzSzy4E/Al4KvBm4B3gfcB0+OZ5FREQ2nZ6dHIvIxhNCeNYK5bZc+ZI248DrT+Je08Ab4r+Mmf1O/HDfg+1LRER6R+9OjmOOLe30l9F8v0duCzGfuND1+PUYUu3Ekme7DsgY2nU+AHMH7gGglUvrGKtt72t4wPN9t5+9Lau77+j9AOT6/T5DXUdZVzrR62Lqqxgjy81WZ8wpzFuIB3xYycPW1hU77kSFc/GZu9KYqcey2ZjjPNyVj7yjkKLWIpuNme0MIRxYUnYu8G78R8EX12RgIiKypnp3ciwicnyfNbMCcAMwDewBXgQM4CfnHTjOa0VEpEdpciwim9U1wG8CL8EX480DPwD+KoTwubUcmIiIrJ2enRxX42Kzvq715oUtnn7QiAvxWo2UttBnnqbQjK+r1dI2b+3g6Q6NurevNbtSLs7wLeCGdvhpdguN6awuxK9uPqZLhFbX1nFx4V+ha4C5kqc8tEIsa6T8iHyI947pHhddcmlWt3uHn8r3wF23+7PPL2R1nTsutHzR3raQvuXnD29HZLMKIXwE+Mhaj0NERNYXHQIiIiIiIhL1bOR4bta3NO3vmv/3xUV3nahyrity3FngFs8CoFGrZXWtppfVW764bXIqbZd67p7z/HVzfjLt7Fw66CPUPALcbsSt1hqpzy1DHrW98JKLsrLBrcPe/7RHn+uVxfQ8076rVDVGtC++6OKsrhDX5j0QP691bVG3GLd+68/5t/qc0XQy7rn5dJiJiIiIiChyLCIiIiKS0eRYRERERCTq2bSKckyZCLV0CpwF/11gIOfpEfP1lLZAXJAXLzS7Ft31xZSEds4XzFUq6eCsw/f6bk+lvKdMDG1LqQojRV+kN1jyU/MKhdRnyPuNxraNZmVn7j4bgAsv8lSL1mJKw5g8NgHAQtXLCv3FrO6OfT8BoBZTQaxrH+bO3s652L7VTCcGVhtp4Z6IiIiIKHIsIiIiIpLp2cjxlrxHeetdW7ltGfEFb50T7ipdB9Ju2eLR3VY8Xi5UU1S5OusL5OJheGDppLvqdAWAgVI88W4g3bA/nsTX3+df5u3bU5Q4P+bbr+X6un4/iQsGy52ocF/69nQW1M3M+/2OTU5mdc045lyMiFszl14X+5iMz3PH5ExWd8H5j0ZEREREEkWORURERESino0cl8a2AdDXta1Ztd8jqu34K0F+sJzV1doe8bW8V+ZLpawuV40R4JJHdEeKKQKcs872cB7RnT1WyeqOTnpu8lyM9uZH0uvGtvrHjUYa30zcrq1U8nHlSKHtyqLnTs8t+DZyU1MTWV0+jqEcx9foypduLS7G+/iWbsXh4dRnuR8RERERSRQ5FhERERGJNDkWkQ3FzPab2f61HoeIiPSmnk2rqLQ8TaLV9YShHbcxa3YWzaXfDSzu4dZJZehs+wZQiF+mdlyRt3A0LWq7ffwe/yDuurbQlcYxtzjvZTFVo701LeSrV7zd4uJ0Vja74O37C96ukEuDP3DAt4w7Njv1b58FGIhDtbKnVdx3+GBWNz/naRiFotfNhVZW9807b0NEREREkp6dHIuIrLXbxmfY8/Yvr/Uw1tT+D7xwrYcgInJSenZyPBgjv3P17oM3/JqPh3nQl7Y8a9Y9Elurewg47qoGpEju0cO+CO7OH92Y1Q3FbeEKcfu0xVY6dGSx6ods9J8x8nN9dhYFdu0mx8KsR6QnDvpAtxTTgsFDd3uEuj3gYymNbEnPFQ8GacbFfVZJN9qeH/Kx1Bc6D5rVlftTJFtERERElHMsIuuQuT8wsx+bWdXMxs3sr8xsZIX2RTN7u5ndamYVM5s1s+vM7OXH6f+NZvaTpf0rp1lEZHPr2cjx5D37ASidsS0rGxjxKGqIvxM0uuK2IX547MghAPryKao8WPHt0KYOeF2opcjs1rJHd7cUfeu3gWbaHq0/pvdOzno0uTGTjmtujHi0t1xK0eFiHM/MA54zPD2fotCH7rgDgB2XPgIAGx3K6qotv1Gz6tHvoVzqcyBuSVcs+FHWO0rp2Omhfm3lJuvW1cAbgIPAXwMN4NeAJwH9QPYnEDPrB74GPBP4KfBhYAB4KQGlgH0AAAl+SURBVPAZM3tsCOGdS/r/MPB64EDsvw78KvBEoBDvJyIim1DPTo5FZGMys6fiE+O7gCeGECZj+buAbwFnA/d2veSt+MT4q8CvhhCasf17gB8C7zCzL4UQvhfLn4FPjG8HnhRCmI7l7wT+L7BzSf8nGu8NK1Rd8mD7EBGR9UNpFSKy3lwZr+/tTIwBQghV4B3LtP8tIABv6UyMY/sjwB/HT3+7q/1ruvqf7mpfX6F/ERHZRHo2cvw3H/kLAIbHxrKyvY99PABPfuJTABjamk6sazc8NWHyqP9fPDlxJKsbjykN0/fuB2DXYFfaY923hZte9NPtZhspFSLkPP1iJOcL3+ZmU12z5f+Hb+k6pa+46H8pPrTfF9+V59Nfdi8ueXpIsegL8dpb0oK8weD9T096/+ML92V18/G6I+/pFZPVxaxuoZpO8xNZRx4fr99epu56INuP0MyGgEcC4yGEny7T/pvx+riuss7H1y/T/vtAc5nyFYUQ9i5XHiPKj1+uTkRE1i9FjkVkven89nl4aUWMDB9bpu3BpW2XlG99kP23gIml5SIisnn0bOR4/OBdABwa35+Vzcbt0Jr3+oEal52fUgIXZ/yvq/MHxwGYvi+lHNbn/OCNsZwv0mt2RVz7+n2hWz1GgtuFtJAvFz8eyPuXuVhIUeKx83xh3dDOHVnZHD6u6UU/nGN3X2p/zs6dANhuv7bP25nVNec84nzbHT4PGKikCPUZ23xOYDHWdrAyn9Xlu8Yqso50Ttk5E7i7u8LM8sB24IElbc9aoa+zl7QDmD1O/zlgDBg/6VGLiEhP6NnJsYhsWDfi6QjPZMnkFXg6kP1WF0KYM7O7gPPN7MIQwh1L2l/e1WfHTXhqxdOX6f/JrOLPxUftGuEGHYIhIrKhKK1CRNabT8Tru8wsWxhgZiXg/cu0/1v8PJ0/jZHfTvvtwLu72nR8sqv/ka72/cD7HvboRURkQ+vZyHGhzxfKhVzay3iq4ovtrv3BtwC49Uc/zOpydc872BkX6ZXaqa98PCFvx6AviqtU0qK2ap8vujtz63YA2iHdb67i6RfNPi8rk06kO2Pc0xsq0ykFYvawp0Bui3snb2Ugq2su+j3L93vqxLZ6Su2YOuQpIYX7PG3kknLav3gk7qN8NJ6i1477HgOMDg4jst6EEL5rZh8C/gNwm5n9I2mf4yl+Pr/4z4Dnx/qbzewr+D7HLwN2AB8MIVzf1f+3zeyvgX8P/NjMPhv7fzGefnEAaCMiIptSz06ORWRDeyO+D/HvA7+LL5L7PPBO4ObuhiGEupk9B3gL8Cp8Ut2M7d4UQvjUMv2/Hj8w5HeB1y3p/wF8j+WHa8++ffvYu3fZzSxEROQE9u3bB7DndN/XQggnbiUisgmY2YX4pPzTIYRXPsy+anh+9M0naiuyRjqr0pfbBlFkPXgM0AohFE/YchUpciwim46ZnQUcCSG0u8oG8GOrwaPID9dtsPI+yCJrrXO6o96jsl4d5wTSU0qTYxHZjN4EvNLMrsVzmM8Cng3sxo+h/oe1G5qIiKwlTY5FZDP6Z/zPdc8FRvEc5duB/w5cHZRvJiKyaWlyLCKbTgjhG8A31nocIiKy/mifYxERERGRSJNjEREREZFIW7mJiIiIiESKHIuIiIiIRJoci4iIiIhEmhyLiIiIiESaHIuIiIiIRJoci4iIiIhEmhyLiIiIiESaHIuIiIiIRJoci4g8CGa228z+1swOmFnNzPab2dVmtu0k+xmNr9sf+zkQ+919qsYum8NqvEfN7FozC8f5VzqVzyC9y8xeamYfMrPrzGw2vp/+90Psa1V+Hq8kvxqdiIj0MjO7APgesAP4AvBT4InAG4HnmdnTQggTD6KfsdjPRcA3gU8DlwBXAi80s6eEEO4+NU8hvWy13qNd3rNCefNhDVQ2sz8EHgPMAw/gP/tO2il4r/8cTY5FRE7sI/gP4jeEED7UKTSzPwfeDLwXeN2D6Od9+MT4z0MIb+3q5w3AX8b7PG8Vxy2bx2q9RwEIIVy12gOUTe/N+KT4TuCZwLceYj+r+l5fjo6PFhE5jhiluBPYD1wQQmh31Q0BBwEDdoQQFo7TzyBwBGgDZ4cQ5rrq+oC7gfPiPRQ9lgdttd6jsf21wDNDCHbKBiybnpk9C58c/10I4dUn8bpVe68fj3KORUSO7/J4/Xr3D2KAOMH9LjAAPPkE/TwZKAPf7Z4Yx37awNeW3E/kwVqt92jGzH7DzN5uZm8xs+ebWXH1hivykK36e305mhyLiBzfxfF6+wr1d8TrRaepH5GlTsV769PA+4H/BnwFuM/MXvrQhieyak7Lz1FNjkVEjm8kXmdWqO+Ubz1N/YgstZrvrS8ALwZ243/puASfJG8FPmNmyomXtXRafo5qQZ6IiIgAEEL4iyVFPwPeaWYHgA/hE+V/Ou0DEzmNFDkWETm+TiRiZIX6Tvn0aepHZKnT8d76OL6N22PjwieRtXBafo5qciwicnw/i9eVctgujNeVcuBWux+RpU75eyuEUAU6C0m3PNR+RB6m0/JzVJNjEZHj6+zF+dy45VomRtCeBlSA75+gn+8Di8DTlkbeYr/PXXI/kQdrtd6jKzKzi4Ft+AT52EPtR+RhOuXvddDkWETkuEIIdwFfB/YAv7+k+j14FO2a7j01zewSM/s3pz+FEOaBa2L7q5b08wex/69pj2M5Wav1HjWzR5jZ6NL+zewM4H/GTz8dQtApeXJKmVkhvkcv6C5/KO/1h3R/HQIiInJ8yxxXug94Er7n5u3AU7uPKzWzALD0IIVljo/+IXAp8Gv4ASFPjT/8RU7KarxHzey1wMeA6/FDaSaBc4EX4Lmc/wo8J4SgvHg5aWZ2BXBF/PQs4Ffw99l1sexYCOFtse0e4B7g3hDCniX9nNR7/SGNVZNjEZETM7NzgD/Cj3cew09i+jzwnhDC1JK2y06OY90o8F/x/yTOBiaArwL/JYTwwKl8BultD/c9amaPBt4K7AV2AsN4GsWPgb8H/kcIoX7qn0R6kZldhf/sW0k2ET7e5DjWP+j3+kMaqybHIiIiIiJOOcciIiIiIpEmxyIiIiIikSbHIiIiIiKRJsciIiIiIpEmxyIiIiIikSbHIiIiIiKRJsciIiIiIpEmxyIiIiIikSbHIiIiIiKRJsciIiIiIpEmxyIiIiIikSbHIiIiIiKRJsciIiIiIpEmxyIiIiIikSbHIiIiIiKRJsciIiIiIpEmxyIiIiIi0f8HtZY4H4tWtRMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fab755a53c8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为何准确率只有50-80%？\n",
    "\n",
    "你可能想问，为何准确率不能更高了？首先，对于简单的 CNN 网络来说，50% 已经不低了。纯粹猜测的准确率为10%。但是，你可能注意到有人的准确率[远远超过 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)。这是因为我们还没有介绍所有的神经网络知识。我们还需要掌握一些其他技巧。\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。将 notebook 文件另存为“dlnd_image_classification.ipynb”，再在目录 \"File\" -> \"Download as\" 另存为 HTML 格式。请在提交的项目中包含 “helper.py” 和 “problem_unittests.py” 文件。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
